{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqdbGOQcT0dz",
    "outputId": "ac6e0df6-4dd0-40ad-8fa2-4e6e82693407"
   },
   "outputs": [],
   "source": [
    "#!pip install kapre==0.3.4\n",
    "#pip install git https://github.com/user/repo.git@branch\n",
    "#!pip install --upgrade tf_siren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMczZvA5Q29B",
    "outputId": "281e3de4-9833-491a-cb2a-86c57e58252f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in 1-thread CPU mode for fully reproducible results training a CNN and generating numpy randomness.  This mode may be slow...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:26:51.276908: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-10 10:26:51.310212: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 10:26:51.791451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "print('Running in 1-thread CPU mode for fully reproducible results training a CNN and generating numpy randomness.  This mode may be slow...')\n",
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 1\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "seed_value += 1\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "seed_value += 1\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "seed_value += 1\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YHgK9fvJADbY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded audio data shape: (831, 1, 220500)\n",
      "Labels shape: (831,)\n",
      "Patient IDs shape: (831,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "SAMPLING_RATE = 22050\n",
    "# Constants\n",
    "\n",
    "# Constants\n",
    "SAMPLE_RATE = 22050  # 22.05 kHz\n",
    "DURATION = 10  # 10 seconds\n",
    "TARGET_LENGTH = SAMPLE_RATE * DURATION  # Length of the audio vector (1, 220500)\n",
    "PARKINSONS_DIR = \"28 People with Parkinson's disease\"\n",
    "\n",
    "def load_and_preprocess_audio(file_path, target_length=TARGET_LENGTH, sample_rate=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Load an audio file, resample to 22,050 Hz, and ensure the shape is (1, 220500).\n",
    "    Short audios are zero-padded, long audios are truncated.\n",
    "    \"\"\"\n",
    "    # Load audio file with librosa\n",
    "    audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    \n",
    "    # Truncate or zero-pad the audio to ensure it's 10 seconds long\n",
    "    if len(audio) > target_length:\n",
    "        audio = audio[:target_length]\n",
    "    else:\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
    "    \n",
    "    # Reshape to (1, target_length)\n",
    "    return audio.reshape(1, -1)\n",
    "\n",
    "def get_class_from_directory(directory_name):\n",
    "    \"\"\"\n",
    "    Determine the class label based on the directory name.\n",
    "    Class 1 for Parkinson's, Class 0 for healthy controls.\n",
    "    \"\"\"\n",
    "    if PARKINSONS_DIR in directory_name:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_patient_id_from_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Extract the patient ID from the directory path. Assumes the patient ID is the immediate subfolder name.\n",
    "    \"\"\"\n",
    "    return os.path.basename(directory_path)\n",
    "\n",
    "def process_all_wav_files(base_directory):\n",
    "    \"\"\"\n",
    "    Load and process all wav files from the directory structure.\n",
    "    Returns three lists: \n",
    "    - audio_data: numpy arrays of the audio files\n",
    "    - labels: corresponding class labels (0 or 1)\n",
    "    - patientids: patient IDs based on the subfolder names\n",
    "    \"\"\"\n",
    "    audio_data = []\n",
    "    labels = []\n",
    "    patientids = []\n",
    "\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Load and preprocess the audio\n",
    "                audio = load_and_preprocess_audio(file_path)\n",
    "                \n",
    "                # Determine the class label based on the directory structure\n",
    "                label = get_class_from_directory(root)\n",
    "                \n",
    "                # Extract the patient ID from the subfolder name\n",
    "                patient_id = get_patient_id_from_directory(os.path.dirname(file_path))\n",
    "                \n",
    "                # Append audio, label, and patient_id to the respective lists\n",
    "                audio_data.append(audio)\n",
    "                labels.append(label)\n",
    "                patientids.append(patient_id)\n",
    "\n",
    "    return np.array(audio_data), np.array(labels), np.array(patientids)\n",
    "\n",
    "# Example usage\n",
    "base_directory = 'italian'  # Set this to the path containing the 3 main directories\n",
    "X, y, patientids = process_all_wav_files(base_directory)\n",
    "\n",
    "print(\"Loaded audio data shape:\", X.shape)  # Should be (num_files, 1, 220500)\n",
    "print(\"Labels shape:\", y.shape)  # Should be (num_files,)\n",
    "print(\"Patient IDs shape:\", patientids.shape)  # Should be (num_files,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "rand = random.Random(42)\n",
    "#Dentamaro et al.\n",
    "def inter_patient_scheme(X,lbls,filenames, test_size = 0.2):\n",
    "  people_index = {}\n",
    "  people_class = {}\n",
    "  X = np.asarray(X)\n",
    "  \n",
    "  for i in range(len(filenames)):\n",
    "        \n",
    "      usercode = filenames[i]\n",
    "      if not usercode in people_class:\n",
    "        people_class[usercode] = lbls[i]\n",
    "      #print(usercode)\n",
    "      if usercode in people_index:\n",
    "        people_index[usercode].append(i)\n",
    "      else:\n",
    "        people_index[usercode] = []\n",
    "        people_index[usercode].append(i)\n",
    "  #print(people_index)    \n",
    "  keys = list(people_index.keys())\n",
    "\n",
    "  rand.shuffle(keys)\n",
    "  #print(keys) \n",
    "  \n",
    "\n",
    "  peoples_in_train = math.floor(len(keys)*(1.-test_size))\n",
    "  people_in_test = len(keys)-peoples_in_train\n",
    "  temp_classes = []\n",
    "  j = 0\n",
    "  for k in keys:\n",
    "    if j < peoples_in_train:\n",
    "      temp_classes.append(people_class[k])\n",
    "    j += 1\n",
    "\n",
    "  unique, counts = np.unique(temp_classes, return_counts=True)\n",
    "  min_index = np.where(counts == np.min(counts))\n",
    "  min_people = np.min(counts)\n",
    "  min_class = unique[min_index]\n",
    "  print('minority class '+str(min_class))\n",
    "  print('minority people '+str(min_people))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #print(peoples_in_train)\n",
    "  training_items = []\n",
    "  testing_items = []\n",
    "\n",
    "  class_counter = {}\n",
    "\n",
    "  train_usercodes = []\n",
    "  test_usercodes = []\n",
    "  #per people balance \n",
    "  for j in range(peoples_in_train):\n",
    "    index = people_index[keys[j]]\n",
    "    \n",
    "    this_class = people_class[keys[j]]\n",
    "    #print(this_class)\n",
    "    #print(class_counter)\n",
    "    if not this_class in class_counter:\n",
    "      class_counter[this_class] = 0\n",
    "    \n",
    "    if this_class != min_class and class_counter[this_class] < min_people:      \n",
    "      for h in index:\n",
    "        training_items.append(h)\n",
    "        train_usercodes.append(keys[j])\n",
    "      class_counter[this_class] += 1\n",
    "    elif this_class != min_class and class_counter[this_class] >= min_people :\n",
    "       for h in index:\n",
    "          pass\n",
    "          #testing_items.append(h)\n",
    "       #class_counter[this_class] += 1\n",
    "    else:\n",
    "      for h in index:\n",
    "        training_items.append(h)\n",
    "        train_usercodes.append(keys[j])\n",
    "      class_counter[this_class] += 1\n",
    "  \n",
    "  temp_classes = []\n",
    "  j = 0\n",
    "  for k in keys:\n",
    "    if j >= peoples_in_train:\n",
    "      temp_classes.append(people_class[k])\n",
    "    j += 1\n",
    "\n",
    "  #print(temp_classes)\n",
    "  class_counter = {}\n",
    "  unique, counts = np.unique(temp_classes, return_counts=True)\n",
    "  min_index = np.where(counts == np.min(counts))\n",
    "  min_people = np.min(counts)\n",
    "  min_class = unique[min_index]\n",
    "  #print(min_people)\n",
    "  #print(min_class)\n",
    "  for j in range(peoples_in_train, len(keys)):\n",
    "    index = people_index[keys[j]]\n",
    "    \n",
    "    this_class = people_class[keys[j]]\n",
    "    #print(this_class)\n",
    "    #print(class_counter)\n",
    "    if not this_class in class_counter:\n",
    "      class_counter[this_class] = 0\n",
    "    \n",
    "    if this_class != min_class[0] and class_counter[this_class] < min_people:      \n",
    "      for h in index:\n",
    "        testing_items.append(h)\n",
    "        test_usercodes.append(keys[j])\n",
    "        #print('Negative index --> '+str(h))\n",
    "      \n",
    "      class_counter[this_class] += 1\n",
    "    elif this_class == min_class[0]:\n",
    "      for h in index:\n",
    "        testing_items.append(h)\n",
    "        test_usercodes.append(keys[j])\n",
    "        #print('Positive index --> '+str(h))\n",
    "    \n",
    "  \n",
    "\n",
    "  \n",
    "  testing_items = np.asarray(testing_items)\n",
    "  training_items = np.asarray(training_items)\n",
    "  #lbls = np.asarray(lbls)\n",
    "  yy = to_categorical(lbls)\n",
    "  X_train = X[training_items,:]\n",
    "  y_train = yy[training_items,:]\n",
    "  X_test = X[testing_items,:]\n",
    "  y_test = yy[testing_items,:]\n",
    "  #print(y_test)\n",
    "  ffn = np.asarray(filenames)[training_items]\n",
    "\n",
    "  #for j in range(len(lbls)):\n",
    "    #print(str(yy[j])+ ' --> '+str(lbls[j]))\n",
    "\n",
    "  return X_train, X_test, y_train, y_test,train_usercodes, test_usercodes\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUDIO TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Laptop GPU, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:26:49.043706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.077829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.077982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.078275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_size % num_heads == 0  # Ensure that embed_size is divisible by num_heads\n",
    "        self.projection_dim = embed_size // num_heads\n",
    "        self.query_dense = layers.Dense(embed_size)\n",
    "        self.key_dense = layers.Dense(embed_size)\n",
    "        self.value_dense = layers.Dense(embed_size)\n",
    "        self.combine_heads = layers.Dense(embed_size)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        \n",
    "        # Cast `dim_key` and `score` to the same dtype\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], query.dtype)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_size))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_size, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_size, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_size)]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)  # Pass training argument\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)  # Pass training argument\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class AudioTransformer(tf.keras.Model):\n",
    "    def __init__(self, num_classes, embed_size=64, num_heads=4, ff_dim=64, rate=0.25):\n",
    "        super(AudioTransformer, self).__init__()\n",
    "        self.conv1 = layers.Conv1D(embed_size, 5, activation='relu', padding='same')\n",
    "        self.conv2 = layers.Conv1D(embed_size, 3, activation='relu', padding='same')\n",
    "        self.transformer_block = TransformerBlock(embed_size, num_heads, ff_dim, rate)\n",
    "        self.global_avg_pool = layers.GlobalAveragePooling1D()\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.classifier = layers.Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.transformer_block(x, training=training)  # Pass training argument\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.dropout(x, training=training)  # Pass training argument\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:26:49.371522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.371746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.371824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.420137: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.420258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.420337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.420424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-06 18:26:49.421073: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.421182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.421252: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.421340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.421413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.421469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/tmp/ipykernel_3602718/4044527385.py:122: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
      "2024-09-06 18:26:49.473501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.473774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.473851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.473968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.474045: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-06 18:26:49.474108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n",
      "minority class [1.]\n",
      "minority people 19\n",
      "y size 0\n",
      "other size 714\n",
      "['VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'VITANTONIO D', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Davide M', 'Davide M', 'Davide M', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Vito L', 'Domenico T', 'Domenico T', 'Domenico T', 'Sara T', 'Sara T', 'Sara T', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R']\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 18:26:52.617518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2024-09-06 18:26:54.948135: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7d2cfed24370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-06 18:26:54.948154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "2024-09-06 18:26:54.967088: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-06 18:26:55.112944: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 - 12s - loss: 1.1867 - accuracy: 0.4906 - auc: 0.4814 - val_loss: 0.9116 - val_accuracy: 0.5339 - val_auc: 0.5316 - 12s/epoch - 318ms/step\n",
      "Epoch 2/100\n",
      "37/37 - 4s - loss: 0.6185 - accuracy: 0.7290 - auc: 0.7989 - val_loss: 0.8348 - val_accuracy: 0.6271 - val_auc: 0.5932 - 4s/epoch - 112ms/step\n",
      "Epoch 3/100\n",
      "37/37 - 3s - loss: 0.4570 - accuracy: 0.7667 - auc: 0.8715 - val_loss: 0.9069 - val_accuracy: 0.5847 - val_auc: 0.5719 - 3s/epoch - 87ms/step\n",
      "Epoch 4/100\n",
      "37/37 - 3s - loss: 0.3635 - accuracy: 0.8422 - auc: 0.9185 - val_loss: 0.9986 - val_accuracy: 0.5763 - val_auc: 0.5661 - 3s/epoch - 87ms/step\n",
      "Epoch 5/100\n",
      "37/37 - 3s - loss: 0.2538 - accuracy: 0.8919 - auc: 0.9604 - val_loss: 1.1085 - val_accuracy: 0.5593 - val_auc: 0.5519 - 3s/epoch - 87ms/step\n",
      "Epoch 6/100\n",
      "37/37 - 3s - loss: 0.1742 - accuracy: 0.9297 - auc: 0.9830 - val_loss: 1.2068 - val_accuracy: 0.5593 - val_auc: 0.5528 - 3s/epoch - 87ms/step\n",
      "Epoch 7/100\n",
      "37/37 - 3s - loss: 0.1364 - accuracy: 0.9468 - auc: 0.9903 - val_loss: 1.3198 - val_accuracy: 0.5254 - val_auc: 0.5532 - 3s/epoch - 87ms/step\n",
      "Epoch 8/100\n",
      "37/37 - 3s - loss: 0.0965 - accuracy: 0.9708 - auc: 0.9953 - val_loss: 1.4109 - val_accuracy: 0.5254 - val_auc: 0.5545 - 3s/epoch - 87ms/step\n",
      "Epoch 9/100\n",
      "37/37 - 3s - loss: 0.0823 - accuracy: 0.9674 - auc: 0.9968 - val_loss: 1.5395 - val_accuracy: 0.5339 - val_auc: 0.5443 - 3s/epoch - 87ms/step\n",
      "Epoch 10/100\n",
      "37/37 - 3s - loss: 0.0646 - accuracy: 0.9811 - auc: 0.9978 - val_loss: 1.5815 - val_accuracy: 0.5169 - val_auc: 0.5605 - 3s/epoch - 87ms/step\n",
      "Epoch 11/100\n",
      "37/37 - 3s - loss: 0.0505 - accuracy: 0.9863 - auc: 0.9987 - val_loss: 1.6671 - val_accuracy: 0.5254 - val_auc: 0.5584 - 3s/epoch - 88ms/step\n",
      "Epoch 12/100\n",
      "37/37 - 3s - loss: 0.0409 - accuracy: 0.9914 - auc: 0.9994 - val_loss: 1.7324 - val_accuracy: 0.5169 - val_auc: 0.5632 - 3s/epoch - 89ms/step\n",
      "Epoch 13/100\n",
      "37/37 - 3s - loss: 0.0386 - accuracy: 0.9897 - auc: 0.9993 - val_loss: 1.7928 - val_accuracy: 0.5169 - val_auc: 0.5632 - 3s/epoch - 89ms/step\n",
      "Epoch 14/100\n",
      "37/37 - 3s - loss: 0.0190 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.8573 - val_accuracy: 0.5085 - val_auc: 0.5573 - 3s/epoch - 90ms/step\n",
      "Epoch 15/100\n",
      "37/37 - 3s - loss: 0.0195 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 1.8974 - val_accuracy: 0.5085 - val_auc: 0.5550 - 3s/epoch - 89ms/step\n",
      "Epoch 16/100\n",
      "37/37 - 3s - loss: 0.0152 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 1.9436 - val_accuracy: 0.5169 - val_auc: 0.5562 - 3s/epoch - 89ms/step\n",
      "Epoch 17/100\n",
      "37/37 - 3s - loss: 0.0169 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.9507 - val_accuracy: 0.5169 - val_auc: 0.5683 - 3s/epoch - 88ms/step\n",
      "Epoch 18/100\n",
      "37/37 - 3s - loss: 0.0126 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.9883 - val_accuracy: 0.5339 - val_auc: 0.5696 - 3s/epoch - 88ms/step\n",
      "Epoch 19/100\n",
      "37/37 - 3s - loss: 0.0140 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 2.0346 - val_accuracy: 0.5254 - val_auc: 0.5668 - 3s/epoch - 88ms/step\n",
      "Epoch 20/100\n",
      "37/37 - 3s - loss: 0.0123 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.0913 - val_accuracy: 0.5254 - val_auc: 0.5601 - 3s/epoch - 88ms/step\n",
      "Epoch 21/100\n",
      "37/37 - 3s - loss: 0.0098 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.1400 - val_accuracy: 0.5339 - val_auc: 0.5547 - 3s/epoch - 88ms/step\n",
      "Epoch 22/100\n",
      "37/37 - 3s - loss: 0.0083 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1918 - val_accuracy: 0.5424 - val_auc: 0.5536 - 3s/epoch - 88ms/step\n",
      "Epoch 23/100\n",
      "37/37 - 3s - loss: 0.0072 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2150 - val_accuracy: 0.5508 - val_auc: 0.5539 - 3s/epoch - 88ms/step\n",
      "Epoch 24/100\n",
      "37/37 - 3s - loss: 0.0082 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2675 - val_accuracy: 0.5424 - val_auc: 0.5513 - 3s/epoch - 88ms/step\n",
      "Epoch 25/100\n",
      "37/37 - 3s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2970 - val_accuracy: 0.5424 - val_auc: 0.5516 - 3s/epoch - 88ms/step\n",
      "Epoch 26/100\n",
      "37/37 - 3s - loss: 0.0058 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3345 - val_accuracy: 0.5424 - val_auc: 0.5502 - 3s/epoch - 88ms/step\n",
      "Epoch 27/100\n",
      "37/37 - 3s - loss: 0.0047 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3612 - val_accuracy: 0.5424 - val_auc: 0.5493 - 3s/epoch - 88ms/step\n",
      "Epoch 28/100\n",
      "37/37 - 3s - loss: 0.0053 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3800 - val_accuracy: 0.5424 - val_auc: 0.5496 - 3s/epoch - 88ms/step\n",
      "Epoch 29/100\n",
      "37/37 - 3s - loss: 0.0046 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4048 - val_accuracy: 0.5424 - val_auc: 0.5470 - 3s/epoch - 88ms/step\n",
      "Epoch 30/100\n",
      "37/37 - 3s - loss: 0.0042 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4277 - val_accuracy: 0.5508 - val_auc: 0.5470 - 3s/epoch - 88ms/step\n",
      "Epoch 31/100\n",
      "37/37 - 3s - loss: 0.0040 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4515 - val_accuracy: 0.5424 - val_auc: 0.5492 - 3s/epoch - 88ms/step\n",
      "Epoch 32/100\n",
      "37/37 - 3s - loss: 0.0041 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4797 - val_accuracy: 0.5508 - val_auc: 0.5487 - 3s/epoch - 88ms/step\n",
      "Epoch 33/100\n",
      "37/37 - 3s - loss: 0.0033 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5038 - val_accuracy: 0.5508 - val_auc: 0.5483 - 3s/epoch - 88ms/step\n",
      "Epoch 34/100\n",
      "37/37 - 3s - loss: 0.0061 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.5310 - val_accuracy: 0.5508 - val_auc: 0.5445 - 3s/epoch - 88ms/step\n",
      "Epoch 35/100\n",
      "37/37 - 3s - loss: 0.0033 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5588 - val_accuracy: 0.5508 - val_auc: 0.5456 - 3s/epoch - 88ms/step\n",
      "Epoch 36/100\n",
      "37/37 - 3s - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5803 - val_accuracy: 0.5508 - val_auc: 0.5463 - 3s/epoch - 88ms/step\n",
      "Epoch 37/100\n",
      "37/37 - 3s - loss: 0.0036 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5967 - val_accuracy: 0.5508 - val_auc: 0.5497 - 3s/epoch - 88ms/step\n",
      "Epoch 38/100\n",
      "37/37 - 3s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6184 - val_accuracy: 0.5508 - val_auc: 0.5465 - 3s/epoch - 88ms/step\n",
      "Epoch 39/100\n",
      "37/37 - 3s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6361 - val_accuracy: 0.5508 - val_auc: 0.5468 - 3s/epoch - 88ms/step\n",
      "Epoch 40/100\n",
      "37/37 - 3s - loss: 0.0025 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6563 - val_accuracy: 0.5508 - val_auc: 0.5412 - 3s/epoch - 88ms/step\n",
      "Epoch 41/100\n",
      "37/37 - 3s - loss: 0.0035 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6847 - val_accuracy: 0.5508 - val_auc: 0.5411 - 3s/epoch - 88ms/step\n",
      "Epoch 42/100\n",
      "37/37 - 3s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7048 - val_accuracy: 0.5508 - val_auc: 0.5428 - 3s/epoch - 88ms/step\n",
      "Epoch 43/100\n",
      "37/37 - 3s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7258 - val_accuracy: 0.5508 - val_auc: 0.5429 - 3s/epoch - 88ms/step\n",
      "Epoch 44/100\n",
      "37/37 - 3s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7410 - val_accuracy: 0.5508 - val_auc: 0.5453 - 3s/epoch - 88ms/step\n",
      "Epoch 45/100\n",
      "37/37 - 3s - loss: 0.0025 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7713 - val_accuracy: 0.5508 - val_auc: 0.5444 - 3s/epoch - 88ms/step\n",
      "Epoch 46/100\n",
      "37/37 - 3s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8058 - val_accuracy: 0.5508 - val_auc: 0.5404 - 3s/epoch - 88ms/step\n",
      "Epoch 47/100\n",
      "37/37 - 3s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8210 - val_accuracy: 0.5508 - val_auc: 0.5416 - 3s/epoch - 88ms/step\n",
      "Epoch 48/100\n",
      "37/37 - 3s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8427 - val_accuracy: 0.5508 - val_auc: 0.5433 - 3s/epoch - 88ms/step\n",
      "Epoch 49/100\n",
      "37/37 - 3s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8588 - val_accuracy: 0.5508 - val_auc: 0.5431 - 3s/epoch - 88ms/step\n",
      "Epoch 50/100\n",
      "37/37 - 3s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8780 - val_accuracy: 0.5508 - val_auc: 0.5445 - 3s/epoch - 89ms/step\n",
      "Epoch 51/100\n",
      "37/37 - 3s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9044 - val_accuracy: 0.5508 - val_auc: 0.5458 - 3s/epoch - 89ms/step\n",
      "Epoch 52/100\n",
      "37/37 - 3s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9186 - val_accuracy: 0.5508 - val_auc: 0.5456 - 3s/epoch - 88ms/step\n",
      "Epoch 53/100\n",
      "37/37 - 3s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9326 - val_accuracy: 0.5508 - val_auc: 0.5460 - 3s/epoch - 88ms/step\n",
      "Epoch 54/100\n",
      "37/37 - 3s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9455 - val_accuracy: 0.5508 - val_auc: 0.5427 - 3s/epoch - 88ms/step\n",
      "Epoch 55/100\n",
      "37/37 - 3s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9531 - val_accuracy: 0.5508 - val_auc: 0.5462 - 3s/epoch - 88ms/step\n",
      "Epoch 56/100\n",
      "37/37 - 3s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9647 - val_accuracy: 0.5508 - val_auc: 0.5498 - 3s/epoch - 89ms/step\n",
      "Epoch 57/100\n",
      "37/37 - 3s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9760 - val_accuracy: 0.5508 - val_auc: 0.5496 - 3s/epoch - 88ms/step\n",
      "Epoch 58/100\n",
      "37/37 - 3s - loss: 9.6926e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9890 - val_accuracy: 0.5508 - val_auc: 0.5482 - 3s/epoch - 89ms/step\n",
      "Epoch 59/100\n",
      "37/37 - 3s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0023 - val_accuracy: 0.5508 - val_auc: 0.5437 - 3s/epoch - 89ms/step\n",
      "Epoch 60/100\n",
      "37/37 - 3s - loss: 9.4784e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0130 - val_accuracy: 0.5508 - val_auc: 0.5439 - 3s/epoch - 89ms/step\n",
      "Epoch 61/100\n",
      "37/37 - 3s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0324 - val_accuracy: 0.5508 - val_auc: 0.5375 - 3s/epoch - 89ms/step\n",
      "Epoch 62/100\n",
      "37/37 - 3s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0449 - val_accuracy: 0.5508 - val_auc: 0.5381 - 3s/epoch - 89ms/step\n",
      "Epoch 63/100\n",
      "37/37 - 3s - loss: 9.2099e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0705 - val_accuracy: 0.5424 - val_auc: 0.5435 - 3s/epoch - 89ms/step\n",
      "Epoch 64/100\n",
      "37/37 - 3s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0873 - val_accuracy: 0.5339 - val_auc: 0.5448 - 3s/epoch - 89ms/step\n",
      "Epoch 65/100\n",
      "37/37 - 3s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1198 - val_accuracy: 0.5424 - val_auc: 0.5377 - 3s/epoch - 88ms/step\n",
      "Epoch 66/100\n",
      "37/37 - 3s - loss: 9.3943e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1354 - val_accuracy: 0.5339 - val_auc: 0.5346 - 3s/epoch - 89ms/step\n",
      "Epoch 67/100\n",
      "37/37 - 3s - loss: 9.5203e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1460 - val_accuracy: 0.5339 - val_auc: 0.5349 - 3s/epoch - 89ms/step\n",
      "Epoch 68/100\n",
      "37/37 - 3s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1742 - val_accuracy: 0.5424 - val_auc: 0.5342 - 3s/epoch - 88ms/step\n",
      "Epoch 69/100\n",
      "37/37 - 3s - loss: 5.5982e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1866 - val_accuracy: 0.5424 - val_auc: 0.5339 - 3s/epoch - 89ms/step\n",
      "Epoch 70/100\n",
      "37/37 - 3s - loss: 8.9951e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2027 - val_accuracy: 0.5424 - val_auc: 0.5340 - 3s/epoch - 89ms/step\n",
      "Epoch 71/100\n",
      "37/37 - 3s - loss: 6.2414e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2137 - val_accuracy: 0.5424 - val_auc: 0.5340 - 3s/epoch - 89ms/step\n",
      "Epoch 72/100\n",
      "37/37 - 3s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2284 - val_accuracy: 0.5424 - val_auc: 0.5344 - 3s/epoch - 89ms/step\n",
      "Epoch 73/100\n",
      "37/37 - 3s - loss: 7.9372e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2365 - val_accuracy: 0.5424 - val_auc: 0.5352 - 3s/epoch - 89ms/step\n",
      "Epoch 74/100\n",
      "37/37 - 3s - loss: 6.7135e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2488 - val_accuracy: 0.5424 - val_auc: 0.5351 - 3s/epoch - 89ms/step\n",
      "Epoch 75/100\n",
      "37/37 - 3s - loss: 7.7772e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2631 - val_accuracy: 0.5424 - val_auc: 0.5353 - 3s/epoch - 89ms/step\n",
      "Epoch 76/100\n",
      "37/37 - 3s - loss: 7.1305e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2751 - val_accuracy: 0.5424 - val_auc: 0.5354 - 3s/epoch - 89ms/step\n",
      "Epoch 77/100\n",
      "37/37 - 3s - loss: 5.0315e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2879 - val_accuracy: 0.5424 - val_auc: 0.5354 - 3s/epoch - 89ms/step\n",
      "Epoch 78/100\n",
      "37/37 - 3s - loss: 6.8698e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2950 - val_accuracy: 0.5424 - val_auc: 0.5354 - 3s/epoch - 89ms/step\n",
      "Epoch 79/100\n",
      "37/37 - 3s - loss: 8.1732e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3095 - val_accuracy: 0.5424 - val_auc: 0.5353 - 3s/epoch - 89ms/step\n",
      "Epoch 80/100\n",
      "37/37 - 3s - loss: 3.8532e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3157 - val_accuracy: 0.5424 - val_auc: 0.5356 - 3s/epoch - 89ms/step\n",
      "Epoch 81/100\n",
      "37/37 - 3s - loss: 4.7401e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3225 - val_accuracy: 0.5424 - val_auc: 0.5358 - 3s/epoch - 89ms/step\n",
      "Epoch 82/100\n",
      "37/37 - 3s - loss: 6.3910e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3368 - val_accuracy: 0.5424 - val_auc: 0.5344 - 3s/epoch - 89ms/step\n",
      "Epoch 83/100\n",
      "37/37 - 3s - loss: 6.8059e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3469 - val_accuracy: 0.5424 - val_auc: 0.5325 - 3s/epoch - 89ms/step\n",
      "Epoch 84/100\n",
      "37/37 - 3s - loss: 4.5322e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3586 - val_accuracy: 0.5424 - val_auc: 0.5326 - 3s/epoch - 89ms/step\n",
      "Epoch 85/100\n",
      "37/37 - 3s - loss: 6.6874e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3662 - val_accuracy: 0.5424 - val_auc: 0.5330 - 3s/epoch - 89ms/step\n",
      "Epoch 86/100\n",
      "37/37 - 3s - loss: 3.8721e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3740 - val_accuracy: 0.5424 - val_auc: 0.5330 - 3s/epoch - 89ms/step\n",
      "Epoch 87/100\n",
      "37/37 - 3s - loss: 3.8715e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3816 - val_accuracy: 0.5424 - val_auc: 0.5382 - 3s/epoch - 89ms/step\n",
      "Epoch 88/100\n",
      "37/37 - 3s - loss: 5.7101e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3942 - val_accuracy: 0.5424 - val_auc: 0.5364 - 3s/epoch - 89ms/step\n",
      "Epoch 89/100\n",
      "37/37 - 3s - loss: 5.1775e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4036 - val_accuracy: 0.5424 - val_auc: 0.5363 - 3s/epoch - 89ms/step\n",
      "Epoch 90/100\n",
      "37/37 - 3s - loss: 7.5538e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4237 - val_accuracy: 0.5424 - val_auc: 0.5363 - 3s/epoch - 89ms/step\n",
      "Epoch 91/100\n",
      "37/37 - 3s - loss: 9.2467e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4515 - val_accuracy: 0.5424 - val_auc: 0.5335 - 3s/epoch - 89ms/step\n",
      "Epoch 92/100\n",
      "37/37 - 3s - loss: 4.2183e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4607 - val_accuracy: 0.5424 - val_auc: 0.5317 - 3s/epoch - 89ms/step\n",
      "Epoch 93/100\n",
      "37/37 - 3s - loss: 3.8447e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4703 - val_accuracy: 0.5424 - val_auc: 0.5317 - 3s/epoch - 89ms/step\n",
      "Epoch 94/100\n",
      "37/37 - 3s - loss: 3.4164e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4834 - val_accuracy: 0.5424 - val_auc: 0.5298 - 3s/epoch - 89ms/step\n",
      "Epoch 95/100\n",
      "37/37 - 3s - loss: 4.8070e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.4922 - val_accuracy: 0.5424 - val_auc: 0.5317 - 3s/epoch - 89ms/step\n",
      "Epoch 96/100\n",
      "37/37 - 3s - loss: 4.3158e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.5050 - val_accuracy: 0.5424 - val_auc: 0.5313 - 3s/epoch - 89ms/step\n",
      "Epoch 97/100\n",
      "37/37 - 3s - loss: 5.9870e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.5310 - val_accuracy: 0.5424 - val_auc: 0.5340 - 3s/epoch - 89ms/step\n",
      "Epoch 98/100\n",
      "37/37 - 3s - loss: 4.2297e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.5462 - val_accuracy: 0.5424 - val_auc: 0.5368 - 3s/epoch - 89ms/step\n",
      "Epoch 99/100\n",
      "37/37 - 3s - loss: 2.2747e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.5560 - val_accuracy: 0.5424 - val_auc: 0.5368 - 3s/epoch - 89ms/step\n",
      "Epoch 100/100\n",
      "37/37 - 3s - loss: 4.6442e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.5699 - val_accuracy: 0.5424 - val_auc: 0.5371 - 3s/epoch - 89ms/step\n",
      "4/4 [==============================] - 2s 243ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.58      0.50        38\n",
      "           1       0.76      0.65      0.70        80\n",
      "\n",
      "    accuracy                           0.63       118\n",
      "   macro avg       0.60      0.61      0.60       118\n",
      "weighted avg       0.66      0.63      0.64       118\n",
      "\n",
      "Roc 0.5671052631578947\n",
      "Confusion Matrix\n",
      "[[22 16]\n",
      " [28 52]]\n",
      "minority class [1.]\n",
      "minority people 17\n",
      "y size 0\n",
      "other size 670\n",
      "['Sara T', 'Sara T', 'Sara T', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Anna B', 'Alessandro P', 'Alessandro P', 'Alessandro P', 'Biagio P', 'Biagio P', 'Biagio P', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Luca S', 'Luca S', 'Luca S', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4044527385.py:122: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 - 11s - loss: 1.1586 - accuracy: 0.5554 - auc: 0.5634 - val_loss: 0.9752 - val_accuracy: 0.5147 - val_auc: 0.5463 - 11s/epoch - 314ms/step\n",
      "Epoch 2/100\n",
      "34/34 - 4s - loss: 0.7363 - accuracy: 0.6863 - auc: 0.7565 - val_loss: 0.9888 - val_accuracy: 0.5294 - val_auc: 0.5556 - 4s/epoch - 117ms/step\n",
      "Epoch 3/100\n",
      "34/34 - 4s - loss: 0.5360 - accuracy: 0.7675 - auc: 0.8509 - val_loss: 0.9963 - val_accuracy: 0.5588 - val_auc: 0.5796 - 4s/epoch - 118ms/step\n",
      "Epoch 4/100\n",
      "34/34 - 4s - loss: 0.4780 - accuracy: 0.8081 - auc: 0.8839 - val_loss: 1.1133 - val_accuracy: 0.5809 - val_auc: 0.5865 - 4s/epoch - 117ms/step\n",
      "Epoch 5/100\n",
      "34/34 - 3s - loss: 0.3406 - accuracy: 0.8561 - auc: 0.9309 - val_loss: 1.2483 - val_accuracy: 0.5735 - val_auc: 0.5823 - 3s/epoch - 91ms/step\n",
      "Epoch 6/100\n",
      "34/34 - 3s - loss: 0.2368 - accuracy: 0.8930 - auc: 0.9660 - val_loss: 1.3806 - val_accuracy: 0.5662 - val_auc: 0.5790 - 3s/epoch - 91ms/step\n",
      "Epoch 7/100\n",
      "34/34 - 6s - loss: 0.2260 - accuracy: 0.9077 - auc: 0.9688 - val_loss: 1.4482 - val_accuracy: 0.5735 - val_auc: 0.5893 - 6s/epoch - 174ms/step\n",
      "Epoch 8/100\n",
      "34/34 - 4s - loss: 0.1616 - accuracy: 0.9280 - auc: 0.9848 - val_loss: 1.5509 - val_accuracy: 0.5809 - val_auc: 0.5956 - 4s/epoch - 117ms/step\n",
      "Epoch 9/100\n",
      "34/34 - 4s - loss: 0.0911 - accuracy: 0.9742 - auc: 0.9965 - val_loss: 1.6217 - val_accuracy: 0.6103 - val_auc: 0.6054 - 4s/epoch - 117ms/step\n",
      "Epoch 10/100\n",
      "34/34 - 3s - loss: 0.1008 - accuracy: 0.9613 - auc: 0.9941 - val_loss: 1.7516 - val_accuracy: 0.5735 - val_auc: 0.5992 - 3s/epoch - 91ms/step\n",
      "Epoch 11/100\n",
      "34/34 - 3s - loss: 0.0846 - accuracy: 0.9723 - auc: 0.9959 - val_loss: 1.8752 - val_accuracy: 0.5588 - val_auc: 0.5820 - 3s/epoch - 92ms/step\n",
      "Epoch 12/100\n",
      "34/34 - 3s - loss: 0.0548 - accuracy: 0.9834 - auc: 0.9987 - val_loss: 1.8867 - val_accuracy: 0.5956 - val_auc: 0.5929 - 3s/epoch - 92ms/step\n",
      "Epoch 13/100\n",
      "34/34 - 3s - loss: 0.0538 - accuracy: 0.9852 - auc: 0.9987 - val_loss: 1.9373 - val_accuracy: 0.5956 - val_auc: 0.5966 - 3s/epoch - 91ms/step\n",
      "Epoch 14/100\n",
      "34/34 - 3s - loss: 0.0550 - accuracy: 0.9797 - auc: 0.9983 - val_loss: 2.0537 - val_accuracy: 0.5882 - val_auc: 0.5801 - 3s/epoch - 91ms/step\n",
      "Epoch 15/100\n",
      "34/34 - 3s - loss: 0.0178 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0735 - val_accuracy: 0.6103 - val_auc: 0.5806 - 3s/epoch - 91ms/step\n",
      "Epoch 16/100\n",
      "34/34 - 3s - loss: 0.0226 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 2.1317 - val_accuracy: 0.6029 - val_auc: 0.5789 - 3s/epoch - 92ms/step\n",
      "Epoch 17/100\n",
      "34/34 - 3s - loss: 0.0242 - accuracy: 0.9963 - auc: 0.9998 - val_loss: 2.1457 - val_accuracy: 0.6029 - val_auc: 0.5860 - 3s/epoch - 92ms/step\n",
      "Epoch 18/100\n",
      "34/34 - 3s - loss: 0.0158 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1781 - val_accuracy: 0.6029 - val_auc: 0.5894 - 3s/epoch - 92ms/step\n",
      "Epoch 19/100\n",
      "34/34 - 3s - loss: 0.0210 - accuracy: 0.9945 - auc: 0.9999 - val_loss: 2.2212 - val_accuracy: 0.6103 - val_auc: 0.5932 - 3s/epoch - 91ms/step\n",
      "Epoch 20/100\n",
      "34/34 - 3s - loss: 0.0156 - accuracy: 0.9963 - auc: 0.9999 - val_loss: 2.2462 - val_accuracy: 0.6103 - val_auc: 0.5970 - 3s/epoch - 92ms/step\n",
      "Epoch 21/100\n",
      "34/34 - 3s - loss: 0.0168 - accuracy: 0.9945 - auc: 1.0000 - val_loss: 2.3025 - val_accuracy: 0.6176 - val_auc: 0.5920 - 3s/epoch - 92ms/step\n",
      "Epoch 22/100\n",
      "34/34 - 3s - loss: 0.0118 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.3243 - val_accuracy: 0.6176 - val_auc: 0.5930 - 3s/epoch - 92ms/step\n",
      "Epoch 23/100\n",
      "34/34 - 3s - loss: 0.0093 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.3803 - val_accuracy: 0.6176 - val_auc: 0.5934 - 3s/epoch - 92ms/step\n",
      "Epoch 24/100\n",
      "34/34 - 3s - loss: 0.0113 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 2.3869 - val_accuracy: 0.6176 - val_auc: 0.5953 - 3s/epoch - 92ms/step\n",
      "Epoch 25/100\n",
      "34/34 - 3s - loss: 0.0126 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4142 - val_accuracy: 0.6176 - val_auc: 0.5979 - 3s/epoch - 92ms/step\n",
      "Epoch 26/100\n",
      "34/34 - 3s - loss: 0.0088 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 2.4523 - val_accuracy: 0.6176 - val_auc: 0.5983 - 3s/epoch - 92ms/step\n",
      "Epoch 27/100\n",
      "34/34 - 3s - loss: 0.0063 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.4933 - val_accuracy: 0.6176 - val_auc: 0.5985 - 3s/epoch - 92ms/step\n",
      "Epoch 28/100\n",
      "34/34 - 3s - loss: 0.0070 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5339 - val_accuracy: 0.6176 - val_auc: 0.5957 - 3s/epoch - 92ms/step\n",
      "Epoch 29/100\n",
      "34/34 - 3s - loss: 0.0059 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5546 - val_accuracy: 0.6176 - val_auc: 0.5988 - 3s/epoch - 92ms/step\n",
      "Epoch 30/100\n",
      "34/34 - 3s - loss: 0.0069 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5628 - val_accuracy: 0.6250 - val_auc: 0.5995 - 3s/epoch - 92ms/step\n",
      "Epoch 31/100\n",
      "34/34 - 3s - loss: 0.0052 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5780 - val_accuracy: 0.6250 - val_auc: 0.6026 - 3s/epoch - 92ms/step\n",
      "Epoch 32/100\n",
      "34/34 - 3s - loss: 0.0069 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5884 - val_accuracy: 0.6176 - val_auc: 0.6040 - 3s/epoch - 92ms/step\n",
      "Epoch 33/100\n",
      "34/34 - 3s - loss: 0.0034 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6108 - val_accuracy: 0.6176 - val_auc: 0.6040 - 3s/epoch - 92ms/step\n",
      "Epoch 34/100\n",
      "34/34 - 3s - loss: 0.0046 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6490 - val_accuracy: 0.6029 - val_auc: 0.6022 - 3s/epoch - 92ms/step\n",
      "Epoch 35/100\n",
      "34/34 - 3s - loss: 0.0042 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.6759 - val_accuracy: 0.6029 - val_auc: 0.6034 - 3s/epoch - 92ms/step\n",
      "Epoch 36/100\n",
      "34/34 - 3s - loss: 0.0045 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6923 - val_accuracy: 0.5956 - val_auc: 0.6010 - 3s/epoch - 92ms/step\n",
      "Epoch 37/100\n",
      "34/34 - 3s - loss: 0.0036 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7258 - val_accuracy: 0.6029 - val_auc: 0.5989 - 3s/epoch - 92ms/step\n",
      "Epoch 38/100\n",
      "34/34 - 3s - loss: 0.0030 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7406 - val_accuracy: 0.6029 - val_auc: 0.6002 - 3s/epoch - 97ms/step\n",
      "Epoch 39/100\n",
      "34/34 - 3s - loss: 0.0033 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7497 - val_accuracy: 0.5956 - val_auc: 0.5993 - 3s/epoch - 94ms/step\n",
      "Epoch 40/100\n",
      "34/34 - 3s - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7669 - val_accuracy: 0.6029 - val_auc: 0.6003 - 3s/epoch - 96ms/step\n",
      "Epoch 41/100\n",
      "34/34 - 3s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7744 - val_accuracy: 0.6029 - val_auc: 0.6005 - 3s/epoch - 97ms/step\n",
      "Epoch 42/100\n",
      "34/34 - 3s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7835 - val_accuracy: 0.6029 - val_auc: 0.5975 - 3s/epoch - 100ms/step\n",
      "Epoch 43/100\n",
      "34/34 - 3s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7995 - val_accuracy: 0.6029 - val_auc: 0.5969 - 3s/epoch - 98ms/step\n",
      "Epoch 44/100\n",
      "34/34 - 3s - loss: 0.0043 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.8288 - val_accuracy: 0.6103 - val_auc: 0.5992 - 3s/epoch - 100ms/step\n",
      "Epoch 45/100\n",
      "34/34 - 3s - loss: 0.0050 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8746 - val_accuracy: 0.6103 - val_auc: 0.5896 - 3s/epoch - 99ms/step\n",
      "Epoch 46/100\n",
      "34/34 - 3s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8894 - val_accuracy: 0.6029 - val_auc: 0.5904 - 3s/epoch - 100ms/step\n",
      "Epoch 47/100\n",
      "34/34 - 4s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8931 - val_accuracy: 0.6029 - val_auc: 0.5917 - 4s/epoch - 103ms/step\n",
      "Epoch 48/100\n",
      "34/34 - 4s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9162 - val_accuracy: 0.6029 - val_auc: 0.5870 - 4s/epoch - 105ms/step\n",
      "Epoch 49/100\n",
      "34/34 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9239 - val_accuracy: 0.6029 - val_auc: 0.5889 - 4s/epoch - 104ms/step\n",
      "Epoch 50/100\n",
      "34/34 - 4s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9269 - val_accuracy: 0.6029 - val_auc: 0.5894 - 4s/epoch - 107ms/step\n",
      "Epoch 51/100\n",
      "34/34 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9589 - val_accuracy: 0.5882 - val_auc: 0.5867 - 4s/epoch - 107ms/step\n",
      "Epoch 52/100\n",
      "34/34 - 4s - loss: 0.0038 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9730 - val_accuracy: 0.6029 - val_auc: 0.5882 - 4s/epoch - 107ms/step\n",
      "Epoch 53/100\n",
      "34/34 - 4s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9890 - val_accuracy: 0.5956 - val_auc: 0.5889 - 4s/epoch - 107ms/step\n",
      "Epoch 54/100\n",
      "34/34 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9866 - val_accuracy: 0.5956 - val_auc: 0.5889 - 4s/epoch - 127ms/step\n",
      "Epoch 55/100\n",
      "34/34 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9921 - val_accuracy: 0.5956 - val_auc: 0.5893 - 4s/epoch - 108ms/step\n",
      "Epoch 56/100\n",
      "34/34 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0024 - val_accuracy: 0.5956 - val_auc: 0.5894 - 4s/epoch - 107ms/step\n",
      "Epoch 57/100\n",
      "34/34 - 4s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0069 - val_accuracy: 0.5956 - val_auc: 0.5897 - 4s/epoch - 107ms/step\n",
      "Epoch 58/100\n",
      "34/34 - 4s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0029 - val_accuracy: 0.6029 - val_auc: 0.5933 - 4s/epoch - 107ms/step\n",
      "Epoch 59/100\n",
      "34/34 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0130 - val_accuracy: 0.6029 - val_auc: 0.5934 - 4s/epoch - 105ms/step\n",
      "Epoch 60/100\n",
      "34/34 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0009 - val_accuracy: 0.6103 - val_auc: 0.5952 - 4s/epoch - 107ms/step\n",
      "Epoch 61/100\n",
      "34/34 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0090 - val_accuracy: 0.6103 - val_auc: 0.5956 - 4s/epoch - 107ms/step\n",
      "Epoch 62/100\n",
      "34/34 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0173 - val_accuracy: 0.6103 - val_auc: 0.5979 - 4s/epoch - 106ms/step\n",
      "Epoch 63/100\n",
      "34/34 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0254 - val_accuracy: 0.6176 - val_auc: 0.5982 - 4s/epoch - 104ms/step\n",
      "Epoch 64/100\n",
      "34/34 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0265 - val_accuracy: 0.6176 - val_auc: 0.5987 - 4s/epoch - 106ms/step\n",
      "Epoch 65/100\n",
      "34/34 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0257 - val_accuracy: 0.6250 - val_auc: 0.5992 - 4s/epoch - 104ms/step\n",
      "Epoch 66/100\n",
      "34/34 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0344 - val_accuracy: 0.6250 - val_auc: 0.6001 - 4s/epoch - 106ms/step\n",
      "Epoch 67/100\n",
      "34/34 - 4s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0619 - val_accuracy: 0.6250 - val_auc: 0.5989 - 4s/epoch - 104ms/step\n",
      "Epoch 68/100\n",
      "34/34 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0658 - val_accuracy: 0.6250 - val_auc: 0.6018 - 4s/epoch - 105ms/step\n",
      "Epoch 69/100\n",
      "34/34 - 4s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0522 - val_accuracy: 0.6397 - val_auc: 0.6028 - 4s/epoch - 104ms/step\n",
      "Epoch 70/100\n",
      "34/34 - 4s - loss: 8.4846e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0551 - val_accuracy: 0.6397 - val_auc: 0.6029 - 4s/epoch - 105ms/step\n",
      "Epoch 71/100\n",
      "34/34 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0628 - val_accuracy: 0.6397 - val_auc: 0.6032 - 4s/epoch - 104ms/step\n",
      "Epoch 72/100\n",
      "34/34 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0600 - val_accuracy: 0.6397 - val_auc: 0.6068 - 4s/epoch - 130ms/step\n",
      "Epoch 73/100\n",
      "34/34 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0740 - val_accuracy: 0.6397 - val_auc: 0.6067 - 4s/epoch - 104ms/step\n",
      "Epoch 74/100\n",
      "34/34 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0826 - val_accuracy: 0.6397 - val_auc: 0.6077 - 4s/epoch - 129ms/step\n",
      "Epoch 75/100\n",
      "34/34 - 4s - loss: 8.6431e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0862 - val_accuracy: 0.6397 - val_auc: 0.6089 - 4s/epoch - 129ms/step\n",
      "Epoch 76/100\n",
      "34/34 - 4s - loss: 7.3496e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0904 - val_accuracy: 0.6397 - val_auc: 0.6091 - 4s/epoch - 129ms/step\n",
      "Epoch 77/100\n",
      "34/34 - 4s - loss: 8.7719e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1050 - val_accuracy: 0.6397 - val_auc: 0.6071 - 4s/epoch - 104ms/step\n",
      "Epoch 78/100\n",
      "34/34 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1204 - val_accuracy: 0.6397 - val_auc: 0.6049 - 4s/epoch - 104ms/step\n",
      "Epoch 79/100\n",
      "34/34 - 4s - loss: 9.6389e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1396 - val_accuracy: 0.6397 - val_auc: 0.6046 - 4s/epoch - 104ms/step\n",
      "Epoch 80/100\n",
      "34/34 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1504 - val_accuracy: 0.6324 - val_auc: 0.6045 - 4s/epoch - 104ms/step\n",
      "Epoch 81/100\n",
      "34/34 - 4s - loss: 9.2789e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1533 - val_accuracy: 0.6324 - val_auc: 0.6067 - 4s/epoch - 104ms/step\n",
      "Epoch 82/100\n",
      "34/34 - 3s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1625 - val_accuracy: 0.6324 - val_auc: 0.6071 - 3s/epoch - 102ms/step\n",
      "Epoch 83/100\n",
      "34/34 - 3s - loss: 4.7484e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1690 - val_accuracy: 0.6324 - val_auc: 0.6072 - 3s/epoch - 102ms/step\n",
      "Epoch 84/100\n",
      "34/34 - 3s - loss: 8.9761e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1768 - val_accuracy: 0.6324 - val_auc: 0.6072 - 3s/epoch - 102ms/step\n",
      "Epoch 85/100\n",
      "34/34 - 3s - loss: 6.7605e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1868 - val_accuracy: 0.6324 - val_auc: 0.6073 - 3s/epoch - 102ms/step\n",
      "Epoch 86/100\n",
      "34/34 - 3s - loss: 6.8781e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1962 - val_accuracy: 0.6250 - val_auc: 0.6073 - 3s/epoch - 103ms/step\n",
      "Epoch 87/100\n",
      "34/34 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2114 - val_accuracy: 0.6250 - val_auc: 0.6068 - 4s/epoch - 105ms/step\n",
      "Epoch 88/100\n",
      "34/34 - 3s - loss: 5.6298e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2281 - val_accuracy: 0.6250 - val_auc: 0.6064 - 3s/epoch - 102ms/step\n",
      "Epoch 89/100\n",
      "34/34 - 4s - loss: 5.8071e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2379 - val_accuracy: 0.6250 - val_auc: 0.6064 - 4s/epoch - 106ms/step\n",
      "Epoch 90/100\n",
      "34/34 - 4s - loss: 5.1055e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2424 - val_accuracy: 0.6250 - val_auc: 0.6065 - 4s/epoch - 103ms/step\n",
      "Epoch 91/100\n",
      "34/34 - 3s - loss: 8.4580e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2489 - val_accuracy: 0.6176 - val_auc: 0.6061 - 3s/epoch - 102ms/step\n",
      "Epoch 92/100\n",
      "34/34 - 3s - loss: 7.1562e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2560 - val_accuracy: 0.6029 - val_auc: 0.6058 - 3s/epoch - 102ms/step\n",
      "Epoch 93/100\n",
      "34/34 - 3s - loss: 6.1506e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2665 - val_accuracy: 0.6029 - val_auc: 0.6056 - 3s/epoch - 102ms/step\n",
      "Epoch 94/100\n",
      "34/34 - 4s - loss: 4.6759e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2707 - val_accuracy: 0.6029 - val_auc: 0.6058 - 4s/epoch - 103ms/step\n",
      "Epoch 95/100\n",
      "34/34 - 4s - loss: 5.6463e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2718 - val_accuracy: 0.6029 - val_auc: 0.6062 - 4s/epoch - 104ms/step\n",
      "Epoch 96/100\n",
      "34/34 - 4s - loss: 6.6950e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2868 - val_accuracy: 0.6029 - val_auc: 0.6060 - 4s/epoch - 105ms/step\n",
      "Epoch 97/100\n",
      "34/34 - 4s - loss: 5.9095e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2962 - val_accuracy: 0.6029 - val_auc: 0.6059 - 4s/epoch - 106ms/step\n",
      "Epoch 98/100\n",
      "34/34 - 3s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3077 - val_accuracy: 0.6029 - val_auc: 0.6056 - 3s/epoch - 103ms/step\n",
      "Epoch 99/100\n",
      "34/34 - 4s - loss: 5.3194e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3164 - val_accuracy: 0.6029 - val_auc: 0.6055 - 4s/epoch - 104ms/step\n",
      "Epoch 100/100\n",
      "34/34 - 4s - loss: 6.2720e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.3308 - val_accuracy: 0.6103 - val_auc: 0.6019 - 4s/epoch - 104ms/step\n",
      "5/5 [==============================] - 0s 49ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.77      0.58        44\n",
      "           1       0.84      0.58      0.68        92\n",
      "\n",
      "    accuracy                           0.64       136\n",
      "   macro avg       0.65      0.67      0.63       136\n",
      "weighted avg       0.72      0.64      0.65       136\n",
      "\n",
      "Roc 0.6794749767495931\n",
      "Confusion Matrix\n",
      "[[34 10]\n",
      " [39 53]]\n",
      "minority class [1.]\n",
      "minority people 20\n",
      "y size 0\n",
      "other size 750\n",
      "['SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'Domenico T', 'Domenico T', 'Domenico T', 'Sara T', 'Sara T', 'Sara T', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'GIOVANNI B', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4044527385.py:122: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 - 9s - loss: 1.1507 - accuracy: 0.6026 - auc: 0.6140 - val_loss: 0.7684 - val_accuracy: 0.6200 - val_auc: 0.7105 - 9s/epoch - 238ms/step\n",
      "Epoch 2/100\n",
      "38/38 - 4s - loss: 0.6543 - accuracy: 0.7136 - auc: 0.7975 - val_loss: 0.7370 - val_accuracy: 0.6200 - val_auc: 0.7050 - 4s/epoch - 98ms/step\n",
      "Epoch 3/100\n",
      "38/38 - 4s - loss: 0.3990 - accuracy: 0.8212 - auc: 0.9041 - val_loss: 0.7757 - val_accuracy: 0.6200 - val_auc: 0.7078 - 4s/epoch - 98ms/step\n",
      "Epoch 4/100\n",
      "38/38 - 4s - loss: 0.3061 - accuracy: 0.8725 - auc: 0.9435 - val_loss: 0.8240 - val_accuracy: 0.6600 - val_auc: 0.7066 - 4s/epoch - 98ms/step\n",
      "Epoch 5/100\n",
      "38/38 - 4s - loss: 0.2357 - accuracy: 0.9073 - auc: 0.9661 - val_loss: 0.9163 - val_accuracy: 0.6600 - val_auc: 0.6896 - 4s/epoch - 99ms/step\n",
      "Epoch 6/100\n",
      "38/38 - 4s - loss: 0.1688 - accuracy: 0.9321 - auc: 0.9839 - val_loss: 1.0043 - val_accuracy: 0.6600 - val_auc: 0.6868 - 4s/epoch - 99ms/step\n",
      "Epoch 7/100\n",
      "38/38 - 4s - loss: 0.1323 - accuracy: 0.9536 - auc: 0.9898 - val_loss: 1.0682 - val_accuracy: 0.6400 - val_auc: 0.6877 - 4s/epoch - 99ms/step\n",
      "Epoch 8/100\n",
      "38/38 - 4s - loss: 0.0793 - accuracy: 0.9868 - auc: 0.9974 - val_loss: 1.1265 - val_accuracy: 0.6400 - val_auc: 0.6943 - 4s/epoch - 98ms/step\n",
      "Epoch 9/100\n",
      "38/38 - 4s - loss: 0.0752 - accuracy: 0.9719 - auc: 0.9976 - val_loss: 1.2357 - val_accuracy: 0.6500 - val_auc: 0.6804 - 4s/epoch - 99ms/step\n",
      "Epoch 10/100\n",
      "38/38 - 4s - loss: 0.0476 - accuracy: 0.9917 - auc: 0.9996 - val_loss: 1.3285 - val_accuracy: 0.6500 - val_auc: 0.6836 - 4s/epoch - 99ms/step\n",
      "Epoch 11/100\n",
      "38/38 - 4s - loss: 0.0321 - accuracy: 0.9983 - auc: 0.9999 - val_loss: 1.3675 - val_accuracy: 0.6500 - val_auc: 0.6829 - 4s/epoch - 97ms/step\n",
      "Epoch 12/100\n",
      "38/38 - 4s - loss: 0.0294 - accuracy: 0.9950 - auc: 0.9998 - val_loss: 1.4188 - val_accuracy: 0.6500 - val_auc: 0.6832 - 4s/epoch - 98ms/step\n",
      "Epoch 13/100\n",
      "38/38 - 4s - loss: 0.0327 - accuracy: 0.9934 - auc: 0.9998 - val_loss: 1.4935 - val_accuracy: 0.6400 - val_auc: 0.6718 - 4s/epoch - 97ms/step\n",
      "Epoch 14/100\n",
      "38/38 - 4s - loss: 0.0279 - accuracy: 0.9934 - auc: 0.9998 - val_loss: 1.5661 - val_accuracy: 0.6400 - val_auc: 0.6750 - 4s/epoch - 99ms/step\n",
      "Epoch 15/100\n",
      "38/38 - 4s - loss: 0.0183 - accuracy: 0.9950 - auc: 1.0000 - val_loss: 1.6071 - val_accuracy: 0.6400 - val_auc: 0.6752 - 4s/epoch - 97ms/step\n",
      "Epoch 16/100\n",
      "38/38 - 4s - loss: 0.0139 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.6369 - val_accuracy: 0.6300 - val_auc: 0.6759 - 4s/epoch - 97ms/step\n",
      "Epoch 17/100\n",
      "38/38 - 4s - loss: 0.0117 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.6300 - val_auc: 0.6792 - 4s/epoch - 97ms/step\n",
      "Epoch 18/100\n",
      "38/38 - 4s - loss: 0.0146 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.6871 - val_accuracy: 0.6300 - val_auc: 0.6758 - 4s/epoch - 97ms/step\n",
      "Epoch 19/100\n",
      "38/38 - 4s - loss: 0.0097 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.7168 - val_accuracy: 0.6300 - val_auc: 0.6772 - 4s/epoch - 101ms/step\n",
      "Epoch 20/100\n",
      "38/38 - 4s - loss: 0.0089 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.6300 - val_auc: 0.6758 - 4s/epoch - 99ms/step\n",
      "Epoch 21/100\n",
      "38/38 - 4s - loss: 0.0108 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.7710 - val_accuracy: 0.6300 - val_auc: 0.6741 - 4s/epoch - 97ms/step\n",
      "Epoch 22/100\n",
      "38/38 - 4s - loss: 0.0087 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 1.8186 - val_accuracy: 0.6300 - val_auc: 0.6716 - 4s/epoch - 97ms/step\n",
      "Epoch 23/100\n",
      "38/38 - 4s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.8401 - val_accuracy: 0.6300 - val_auc: 0.6737 - 4s/epoch - 97ms/step\n",
      "Epoch 24/100\n",
      "38/38 - 4s - loss: 0.0102 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.8775 - val_accuracy: 0.6300 - val_auc: 0.6685 - 4s/epoch - 98ms/step\n",
      "Epoch 25/100\n",
      "38/38 - 4s - loss: 0.0047 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.9179 - val_accuracy: 0.6300 - val_auc: 0.6674 - 4s/epoch - 97ms/step\n",
      "Epoch 26/100\n",
      "38/38 - 4s - loss: 0.0070 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.9378 - val_accuracy: 0.6300 - val_auc: 0.6680 - 4s/epoch - 98ms/step\n",
      "Epoch 27/100\n",
      "38/38 - 4s - loss: 0.0034 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.9623 - val_accuracy: 0.6300 - val_auc: 0.6684 - 4s/epoch - 98ms/step\n",
      "Epoch 28/100\n",
      "38/38 - 4s - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.9884 - val_accuracy: 0.6300 - val_auc: 0.6671 - 4s/epoch - 98ms/step\n",
      "Epoch 29/100\n",
      "38/38 - 4s - loss: 0.0035 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0139 - val_accuracy: 0.6300 - val_auc: 0.6610 - 4s/epoch - 100ms/step\n",
      "Epoch 30/100\n",
      "38/38 - 4s - loss: 0.0058 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.0278 - val_accuracy: 0.6300 - val_auc: 0.6621 - 4s/epoch - 98ms/step\n",
      "Epoch 31/100\n",
      "38/38 - 4s - loss: 0.0038 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0386 - val_accuracy: 0.6300 - val_auc: 0.6634 - 4s/epoch - 100ms/step\n",
      "Epoch 32/100\n",
      "38/38 - 4s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.6300 - val_auc: 0.6653 - 4s/epoch - 100ms/step\n",
      "Epoch 33/100\n",
      "38/38 - 4s - loss: 0.0036 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0718 - val_accuracy: 0.6300 - val_auc: 0.6691 - 4s/epoch - 102ms/step\n",
      "Epoch 34/100\n",
      "38/38 - 4s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0958 - val_accuracy: 0.6300 - val_auc: 0.6686 - 4s/epoch - 101ms/step\n",
      "Epoch 35/100\n",
      "38/38 - 4s - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1164 - val_accuracy: 0.6300 - val_auc: 0.6700 - 4s/epoch - 101ms/step\n",
      "Epoch 36/100\n",
      "38/38 - 4s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1348 - val_accuracy: 0.6300 - val_auc: 0.6705 - 4s/epoch - 100ms/step\n",
      "Epoch 37/100\n",
      "38/38 - 4s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1431 - val_accuracy: 0.6300 - val_auc: 0.6635 - 4s/epoch - 100ms/step\n",
      "Epoch 38/100\n",
      "38/38 - 4s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1588 - val_accuracy: 0.6400 - val_auc: 0.6666 - 4s/epoch - 100ms/step\n",
      "Epoch 39/100\n",
      "38/38 - 4s - loss: 0.0043 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.1843 - val_accuracy: 0.6400 - val_auc: 0.6618 - 4s/epoch - 99ms/step\n",
      "Epoch 40/100\n",
      "38/38 - 4s - loss: 0.0030 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2199 - val_accuracy: 0.6400 - val_auc: 0.6582 - 4s/epoch - 99ms/step\n",
      "Epoch 41/100\n",
      "38/38 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2337 - val_accuracy: 0.6400 - val_auc: 0.6559 - 4s/epoch - 102ms/step\n",
      "Epoch 42/100\n",
      "38/38 - 4s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2417 - val_accuracy: 0.6400 - val_auc: 0.6564 - 4s/epoch - 99ms/step\n",
      "Epoch 43/100\n",
      "38/38 - 4s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2578 - val_accuracy: 0.6400 - val_auc: 0.6513 - 4s/epoch - 100ms/step\n",
      "Epoch 44/100\n",
      "38/38 - 4s - loss: 0.0030 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2727 - val_accuracy: 0.6400 - val_auc: 0.6514 - 4s/epoch - 99ms/step\n",
      "Epoch 45/100\n",
      "38/38 - 4s - loss: 0.0034 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.3058 - val_accuracy: 0.6400 - val_auc: 0.6589 - 4s/epoch - 99ms/step\n",
      "Epoch 46/100\n",
      "38/38 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3152 - val_accuracy: 0.6400 - val_auc: 0.6639 - 4s/epoch - 99ms/step\n",
      "Epoch 47/100\n",
      "38/38 - 4s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3467 - val_accuracy: 0.6300 - val_auc: 0.6562 - 4s/epoch - 100ms/step\n",
      "Epoch 48/100\n",
      "38/38 - 4s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3635 - val_accuracy: 0.6300 - val_auc: 0.6566 - 4s/epoch - 100ms/step\n",
      "Epoch 49/100\n",
      "38/38 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3759 - val_accuracy: 0.6300 - val_auc: 0.6566 - 4s/epoch - 100ms/step\n",
      "Epoch 50/100\n",
      "38/38 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3926 - val_accuracy: 0.6300 - val_auc: 0.6565 - 4s/epoch - 100ms/step\n",
      "Epoch 51/100\n",
      "38/38 - 4s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4056 - val_accuracy: 0.6300 - val_auc: 0.6565 - 4s/epoch - 99ms/step\n",
      "Epoch 52/100\n",
      "38/38 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4202 - val_accuracy: 0.6300 - val_auc: 0.6565 - 4s/epoch - 99ms/step\n",
      "Epoch 53/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4332 - val_accuracy: 0.6300 - val_auc: 0.6566 - 4s/epoch - 99ms/step\n",
      "Epoch 54/100\n",
      "38/38 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4451 - val_accuracy: 0.6300 - val_auc: 0.6562 - 4s/epoch - 101ms/step\n",
      "Epoch 55/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4599 - val_accuracy: 0.6300 - val_auc: 0.6567 - 4s/epoch - 101ms/step\n",
      "Epoch 56/100\n",
      "38/38 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4787 - val_accuracy: 0.6300 - val_auc: 0.6538 - 4s/epoch - 100ms/step\n",
      "Epoch 57/100\n",
      "38/38 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4893 - val_accuracy: 0.6300 - val_auc: 0.6541 - 4s/epoch - 100ms/step\n",
      "Epoch 58/100\n",
      "38/38 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5022 - val_accuracy: 0.6300 - val_auc: 0.6540 - 4s/epoch - 100ms/step\n",
      "Epoch 59/100\n",
      "38/38 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5247 - val_accuracy: 0.6400 - val_auc: 0.6508 - 4s/epoch - 100ms/step\n",
      "Epoch 60/100\n",
      "38/38 - 4s - loss: 9.2097e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5398 - val_accuracy: 0.6400 - val_auc: 0.6506 - 4s/epoch - 100ms/step\n",
      "Epoch 61/100\n",
      "38/38 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5535 - val_accuracy: 0.6400 - val_auc: 0.6504 - 4s/epoch - 100ms/step\n",
      "Epoch 62/100\n",
      "38/38 - 4s - loss: 9.7902e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5631 - val_accuracy: 0.6300 - val_auc: 0.6503 - 4s/epoch - 100ms/step\n",
      "Epoch 63/100\n",
      "38/38 - 4s - loss: 9.6625e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5746 - val_accuracy: 0.6300 - val_auc: 0.6515 - 4s/epoch - 100ms/step\n",
      "Epoch 64/100\n",
      "38/38 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5849 - val_accuracy: 0.6300 - val_auc: 0.6528 - 4s/epoch - 100ms/step\n",
      "Epoch 65/100\n",
      "38/38 - 4s - loss: 6.9966e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5888 - val_accuracy: 0.6300 - val_auc: 0.6527 - 4s/epoch - 100ms/step\n",
      "Epoch 66/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6039 - val_accuracy: 0.6400 - val_auc: 0.6529 - 4s/epoch - 100ms/step\n",
      "Epoch 67/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6155 - val_accuracy: 0.6400 - val_auc: 0.6553 - 4s/epoch - 100ms/step\n",
      "Epoch 68/100\n",
      "38/38 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6317 - val_accuracy: 0.6400 - val_auc: 0.6559 - 4s/epoch - 100ms/step\n",
      "Epoch 69/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6537 - val_accuracy: 0.6300 - val_auc: 0.6556 - 4s/epoch - 100ms/step\n",
      "Epoch 70/100\n",
      "38/38 - 4s - loss: 7.3955e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6660 - val_accuracy: 0.6400 - val_auc: 0.6557 - 4s/epoch - 100ms/step\n",
      "Epoch 71/100\n",
      "38/38 - 4s - loss: 9.4223e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6770 - val_accuracy: 0.6400 - val_auc: 0.6558 - 4s/epoch - 100ms/step\n",
      "Epoch 72/100\n",
      "38/38 - 4s - loss: 7.9839e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6892 - val_accuracy: 0.6300 - val_auc: 0.6504 - 4s/epoch - 100ms/step\n",
      "Epoch 73/100\n",
      "38/38 - 4s - loss: 5.5494e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6986 - val_accuracy: 0.6200 - val_auc: 0.6501 - 4s/epoch - 100ms/step\n",
      "Epoch 74/100\n",
      "38/38 - 4s - loss: 5.3103e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7035 - val_accuracy: 0.6400 - val_auc: 0.6504 - 4s/epoch - 100ms/step\n",
      "Epoch 75/100\n",
      "38/38 - 4s - loss: 6.7402e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7125 - val_accuracy: 0.6300 - val_auc: 0.6501 - 4s/epoch - 100ms/step\n",
      "Epoch 76/100\n",
      "38/38 - 4s - loss: 4.7445e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7200 - val_accuracy: 0.6300 - val_auc: 0.6501 - 4s/epoch - 100ms/step\n",
      "Epoch 77/100\n",
      "38/38 - 4s - loss: 7.8788e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7294 - val_accuracy: 0.6300 - val_auc: 0.6526 - 4s/epoch - 100ms/step\n",
      "Epoch 78/100\n",
      "38/38 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7426 - val_accuracy: 0.6400 - val_auc: 0.6502 - 4s/epoch - 100ms/step\n",
      "Epoch 79/100\n",
      "38/38 - 4s - loss: 6.8249e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7541 - val_accuracy: 0.6400 - val_auc: 0.6504 - 4s/epoch - 100ms/step\n",
      "Epoch 80/100\n",
      "38/38 - 4s - loss: 5.7531e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.6400 - val_auc: 0.6504 - 4s/epoch - 100ms/step\n",
      "Epoch 81/100\n",
      "38/38 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7849 - val_accuracy: 0.6300 - val_auc: 0.6447 - 4s/epoch - 100ms/step\n",
      "Epoch 82/100\n",
      "38/38 - 4s - loss: 7.7663e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8022 - val_accuracy: 0.6200 - val_auc: 0.6445 - 4s/epoch - 100ms/step\n",
      "Epoch 83/100\n",
      "38/38 - 4s - loss: 7.0883e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8113 - val_accuracy: 0.6300 - val_auc: 0.6445 - 4s/epoch - 100ms/step\n",
      "Epoch 84/100\n",
      "38/38 - 4s - loss: 5.6120e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8205 - val_accuracy: 0.6300 - val_auc: 0.6449 - 4s/epoch - 101ms/step\n",
      "Epoch 85/100\n",
      "38/38 - 4s - loss: 3.7769e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.6400 - val_auc: 0.6448 - 4s/epoch - 102ms/step\n",
      "Epoch 86/100\n",
      "38/38 - 4s - loss: 5.7384e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8374 - val_accuracy: 0.6400 - val_auc: 0.6447 - 4s/epoch - 101ms/step\n",
      "Epoch 87/100\n",
      "38/38 - 4s - loss: 7.2245e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8512 - val_accuracy: 0.6300 - val_auc: 0.6445 - 4s/epoch - 103ms/step\n",
      "Epoch 88/100\n",
      "38/38 - 4s - loss: 4.4447e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8581 - val_accuracy: 0.6300 - val_auc: 0.6449 - 4s/epoch - 102ms/step\n",
      "Epoch 89/100\n",
      "38/38 - 4s - loss: 7.5329e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8639 - val_accuracy: 0.6400 - val_auc: 0.6402 - 4s/epoch - 101ms/step\n",
      "Epoch 90/100\n",
      "38/38 - 4s - loss: 5.9590e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8739 - val_accuracy: 0.6400 - val_auc: 0.6402 - 4s/epoch - 101ms/step\n",
      "Epoch 91/100\n",
      "38/38 - 4s - loss: 4.3921e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8820 - val_accuracy: 0.6400 - val_auc: 0.6405 - 4s/epoch - 102ms/step\n",
      "Epoch 92/100\n",
      "38/38 - 4s - loss: 5.0994e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8870 - val_accuracy: 0.6400 - val_auc: 0.6401 - 4s/epoch - 100ms/step\n",
      "Epoch 93/100\n",
      "38/38 - 4s - loss: 4.5687e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8909 - val_accuracy: 0.6400 - val_auc: 0.6401 - 4s/epoch - 101ms/step\n",
      "Epoch 94/100\n",
      "38/38 - 4s - loss: 3.2729e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8967 - val_accuracy: 0.6400 - val_auc: 0.6404 - 4s/epoch - 100ms/step\n",
      "Epoch 95/100\n",
      "38/38 - 4s - loss: 7.8474e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9091 - val_accuracy: 0.6400 - val_auc: 0.6400 - 4s/epoch - 100ms/step\n",
      "Epoch 96/100\n",
      "38/38 - 4s - loss: 5.7254e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9173 - val_accuracy: 0.6400 - val_auc: 0.6404 - 4s/epoch - 100ms/step\n",
      "Epoch 97/100\n",
      "38/38 - 4s - loss: 2.9019e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9234 - val_accuracy: 0.6400 - val_auc: 0.6404 - 4s/epoch - 100ms/step\n",
      "Epoch 98/100\n",
      "38/38 - 4s - loss: 4.6942e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9316 - val_accuracy: 0.6400 - val_auc: 0.6379 - 4s/epoch - 99ms/step\n",
      "Epoch 99/100\n",
      "38/38 - 4s - loss: 2.8270e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9391 - val_accuracy: 0.6400 - val_auc: 0.6379 - 4s/epoch - 100ms/step\n",
      "Epoch 100/100\n",
      "38/38 - 4s - loss: 4.7461e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9447 - val_accuracy: 0.6400 - val_auc: 0.6367 - 4s/epoch - 100ms/step\n",
      "4/4 [==============================] - 0s 50ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.34      0.41        38\n",
      "           1       0.66      0.79      0.72        62\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.58      0.57      0.56       100\n",
      "weighted avg       0.60      0.62      0.60       100\n",
      "\n",
      "Roc 0.6641298811544992\n",
      "Confusion Matrix\n",
      "[[13 25]\n",
      " [13 49]]\n",
      "minority class [1.]\n",
      "minority people 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4044527385.py:122: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y size 0\n",
      "other size 762\n",
      "['Daniele R', 'Daniele R', 'Daniele R', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Arianna P', 'Arianna P', 'Arianna P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C']\n",
      "Epoch 1/100\n",
      "38/38 - 9s - loss: 1.2062 - accuracy: 0.5126 - auc: 0.5221 - val_loss: 0.7931 - val_accuracy: 0.6277 - val_auc: 0.6285 - 9s/epoch - 230ms/step\n",
      "Epoch 2/100\n",
      "38/38 - 5s - loss: 0.5858 - accuracy: 0.7454 - auc: 0.8241 - val_loss: 0.7759 - val_accuracy: 0.6064 - val_auc: 0.6490 - 5s/epoch - 122ms/step\n",
      "Epoch 3/100\n",
      "38/38 - 5s - loss: 0.4633 - accuracy: 0.8007 - auc: 0.8791 - val_loss: 0.8246 - val_accuracy: 0.5957 - val_auc: 0.6605 - 5s/epoch - 122ms/step\n",
      "Epoch 4/100\n",
      "38/38 - 4s - loss: 0.3170 - accuracy: 0.8677 - auc: 0.9410 - val_loss: 0.9520 - val_accuracy: 0.5851 - val_auc: 0.6431 - 4s/epoch - 100ms/step\n",
      "Epoch 5/100\n",
      "38/38 - 4s - loss: 0.2084 - accuracy: 0.9146 - auc: 0.9743 - val_loss: 0.9990 - val_accuracy: 0.6064 - val_auc: 0.6567 - 4s/epoch - 98ms/step\n",
      "Epoch 6/100\n",
      "38/38 - 4s - loss: 0.2057 - accuracy: 0.9146 - auc: 0.9742 - val_loss: 1.1423 - val_accuracy: 0.5957 - val_auc: 0.6444 - 4s/epoch - 100ms/step\n",
      "Epoch 7/100\n",
      "38/38 - 4s - loss: 0.1140 - accuracy: 0.9581 - auc: 0.9926 - val_loss: 1.2464 - val_accuracy: 0.6170 - val_auc: 0.6424 - 4s/epoch - 99ms/step\n",
      "Epoch 8/100\n",
      "38/38 - 4s - loss: 0.0851 - accuracy: 0.9682 - auc: 0.9969 - val_loss: 1.3293 - val_accuracy: 0.6277 - val_auc: 0.6467 - 4s/epoch - 99ms/step\n",
      "Epoch 9/100\n",
      "38/38 - 4s - loss: 0.0531 - accuracy: 0.9832 - auc: 0.9990 - val_loss: 1.3970 - val_accuracy: 0.6277 - val_auc: 0.6534 - 4s/epoch - 98ms/step\n",
      "Epoch 10/100\n",
      "38/38 - 4s - loss: 0.0494 - accuracy: 0.9816 - auc: 0.9990 - val_loss: 1.4591 - val_accuracy: 0.6277 - val_auc: 0.6575 - 4s/epoch - 99ms/step\n",
      "Epoch 11/100\n",
      "38/38 - 4s - loss: 0.0352 - accuracy: 0.9899 - auc: 0.9998 - val_loss: 1.5020 - val_accuracy: 0.6277 - val_auc: 0.6587 - 4s/epoch - 99ms/step\n",
      "Epoch 12/100\n",
      "38/38 - 5s - loss: 0.0248 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.6170 - val_auc: 0.6605 - 5s/epoch - 122ms/step\n",
      "Epoch 13/100\n",
      "38/38 - 4s - loss: 0.0326 - accuracy: 0.9899 - auc: 0.9997 - val_loss: 1.6127 - val_accuracy: 0.6277 - val_auc: 0.6552 - 4s/epoch - 99ms/step\n",
      "Epoch 14/100\n",
      "38/38 - 4s - loss: 0.0157 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.6616 - val_accuracy: 0.6277 - val_auc: 0.6510 - 4s/epoch - 98ms/step\n",
      "Epoch 15/100\n",
      "38/38 - 4s - loss: 0.0124 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.5957 - val_auc: 0.6437 - 4s/epoch - 98ms/step\n",
      "Epoch 16/100\n",
      "38/38 - 4s - loss: 0.0140 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.7554 - val_accuracy: 0.5851 - val_auc: 0.6347 - 4s/epoch - 97ms/step\n",
      "Epoch 17/100\n",
      "38/38 - 4s - loss: 0.0155 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 1.7961 - val_accuracy: 0.5957 - val_auc: 0.6340 - 4s/epoch - 102ms/step\n",
      "Epoch 18/100\n",
      "38/38 - 4s - loss: 0.0193 - accuracy: 0.9933 - auc: 0.9999 - val_loss: 1.8501 - val_accuracy: 0.5957 - val_auc: 0.6272 - 4s/epoch - 98ms/step\n",
      "Epoch 19/100\n",
      "38/38 - 4s - loss: 0.0150 - accuracy: 0.9966 - auc: 0.9999 - val_loss: 1.8764 - val_accuracy: 0.5957 - val_auc: 0.6315 - 4s/epoch - 100ms/step\n",
      "Epoch 20/100\n",
      "38/38 - 4s - loss: 0.0084 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.9075 - val_accuracy: 0.6170 - val_auc: 0.6291 - 4s/epoch - 100ms/step\n",
      "Epoch 21/100\n",
      "38/38 - 4s - loss: 0.0072 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.9239 - val_accuracy: 0.6277 - val_auc: 0.6225 - 4s/epoch - 100ms/step\n",
      "Epoch 22/100\n",
      "38/38 - 4s - loss: 0.0077 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 1.9534 - val_accuracy: 0.6170 - val_auc: 0.6184 - 4s/epoch - 100ms/step\n",
      "Epoch 23/100\n",
      "38/38 - 4s - loss: 0.0057 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.9776 - val_accuracy: 0.6064 - val_auc: 0.6163 - 4s/epoch - 100ms/step\n",
      "Epoch 24/100\n",
      "38/38 - 4s - loss: 0.0080 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.0067 - val_accuracy: 0.6170 - val_auc: 0.6125 - 4s/epoch - 100ms/step\n",
      "Epoch 25/100\n",
      "38/38 - 4s - loss: 0.0080 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0148 - val_accuracy: 0.6170 - val_auc: 0.6255 - 4s/epoch - 99ms/step\n",
      "Epoch 26/100\n",
      "38/38 - 4s - loss: 0.0064 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.0494 - val_accuracy: 0.6064 - val_auc: 0.6271 - 4s/epoch - 99ms/step\n",
      "Epoch 27/100\n",
      "38/38 - 4s - loss: 0.0035 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1146 - val_accuracy: 0.5957 - val_auc: 0.6208 - 4s/epoch - 99ms/step\n",
      "Epoch 28/100\n",
      "38/38 - 4s - loss: 0.0030 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1231 - val_accuracy: 0.5957 - val_auc: 0.6191 - 4s/epoch - 99ms/step\n",
      "Epoch 29/100\n",
      "38/38 - 4s - loss: 0.0044 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1607 - val_accuracy: 0.5957 - val_auc: 0.6175 - 4s/epoch - 98ms/step\n",
      "Epoch 30/100\n",
      "38/38 - 4s - loss: 0.0030 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1873 - val_accuracy: 0.5957 - val_auc: 0.6142 - 4s/epoch - 100ms/step\n",
      "Epoch 31/100\n",
      "38/38 - 4s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2119 - val_accuracy: 0.5957 - val_auc: 0.6136 - 4s/epoch - 98ms/step\n",
      "Epoch 32/100\n",
      "38/38 - 4s - loss: 0.0056 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.2239 - val_accuracy: 0.5957 - val_auc: 0.6147 - 4s/epoch - 99ms/step\n",
      "Epoch 33/100\n",
      "38/38 - 4s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2472 - val_accuracy: 0.5957 - val_auc: 0.6144 - 4s/epoch - 101ms/step\n",
      "Epoch 34/100\n",
      "38/38 - 4s - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2689 - val_accuracy: 0.5851 - val_auc: 0.6114 - 4s/epoch - 100ms/step\n",
      "Epoch 35/100\n",
      "38/38 - 4s - loss: 0.0033 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2874 - val_accuracy: 0.5957 - val_auc: 0.6079 - 4s/epoch - 103ms/step\n",
      "Epoch 36/100\n",
      "38/38 - 4s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3069 - val_accuracy: 0.5957 - val_auc: 0.6104 - 4s/epoch - 98ms/step\n",
      "Epoch 37/100\n",
      "38/38 - 4s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3296 - val_accuracy: 0.5957 - val_auc: 0.6128 - 4s/epoch - 98ms/step\n",
      "Epoch 38/100\n",
      "38/38 - 4s - loss: 0.0022 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3390 - val_accuracy: 0.5957 - val_auc: 0.6134 - 4s/epoch - 100ms/step\n",
      "Epoch 39/100\n",
      "38/38 - 4s - loss: 0.0022 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3514 - val_accuracy: 0.5957 - val_auc: 0.6107 - 4s/epoch - 99ms/step\n",
      "Epoch 40/100\n",
      "38/38 - 4s - loss: 0.0041 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.3341 - val_accuracy: 0.5957 - val_auc: 0.6158 - 4s/epoch - 99ms/step\n",
      "Epoch 41/100\n",
      "38/38 - 4s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3454 - val_accuracy: 0.5957 - val_auc: 0.6162 - 4s/epoch - 100ms/step\n",
      "Epoch 42/100\n",
      "38/38 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3654 - val_accuracy: 0.6064 - val_auc: 0.6178 - 4s/epoch - 99ms/step\n",
      "Epoch 43/100\n",
      "38/38 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3801 - val_accuracy: 0.6064 - val_auc: 0.6179 - 4s/epoch - 99ms/step\n",
      "Epoch 44/100\n",
      "38/38 - 4s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3931 - val_accuracy: 0.6064 - val_auc: 0.6171 - 4s/epoch - 99ms/step\n",
      "Epoch 45/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4002 - val_accuracy: 0.6064 - val_auc: 0.6172 - 4s/epoch - 99ms/step\n",
      "Epoch 46/100\n",
      "38/38 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4139 - val_accuracy: 0.6064 - val_auc: 0.6203 - 4s/epoch - 99ms/step\n",
      "Epoch 47/100\n",
      "38/38 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4264 - val_accuracy: 0.6064 - val_auc: 0.6204 - 4s/epoch - 99ms/step\n",
      "Epoch 48/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4359 - val_accuracy: 0.5957 - val_auc: 0.6203 - 4s/epoch - 99ms/step\n",
      "Epoch 49/100\n",
      "38/38 - 4s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4603 - val_accuracy: 0.6064 - val_auc: 0.6162 - 4s/epoch - 99ms/step\n",
      "Epoch 50/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4781 - val_accuracy: 0.6064 - val_auc: 0.6176 - 4s/epoch - 99ms/step\n",
      "Epoch 51/100\n",
      "38/38 - 4s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4855 - val_accuracy: 0.6064 - val_auc: 0.6158 - 4s/epoch - 99ms/step\n",
      "Epoch 52/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4987 - val_accuracy: 0.6064 - val_auc: 0.6157 - 4s/epoch - 99ms/step\n",
      "Epoch 53/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5060 - val_accuracy: 0.6064 - val_auc: 0.6159 - 4s/epoch - 99ms/step\n",
      "Epoch 54/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5170 - val_accuracy: 0.6064 - val_auc: 0.6152 - 4s/epoch - 99ms/step\n",
      "Epoch 55/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5322 - val_accuracy: 0.6064 - val_auc: 0.6145 - 4s/epoch - 99ms/step\n",
      "Epoch 56/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5451 - val_accuracy: 0.6064 - val_auc: 0.6125 - 4s/epoch - 99ms/step\n",
      "Epoch 57/100\n",
      "38/38 - 4s - loss: 8.4255e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5480 - val_accuracy: 0.6064 - val_auc: 0.6124 - 4s/epoch - 99ms/step\n",
      "Epoch 58/100\n",
      "38/38 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5820 - val_accuracy: 0.6064 - val_auc: 0.6007 - 4s/epoch - 99ms/step\n",
      "Epoch 59/100\n",
      "38/38 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5917 - val_accuracy: 0.6064 - val_auc: 0.6037 - 4s/epoch - 100ms/step\n",
      "Epoch 60/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5973 - val_accuracy: 0.6064 - val_auc: 0.6045 - 4s/epoch - 99ms/step\n",
      "Epoch 61/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6059 - val_accuracy: 0.6064 - val_auc: 0.6042 - 4s/epoch - 99ms/step\n",
      "Epoch 62/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6113 - val_accuracy: 0.6064 - val_auc: 0.6041 - 4s/epoch - 99ms/step\n",
      "Epoch 63/100\n",
      "38/38 - 4s - loss: 6.5255e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6169 - val_accuracy: 0.6064 - val_auc: 0.6042 - 4s/epoch - 99ms/step\n",
      "Epoch 64/100\n",
      "38/38 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6226 - val_accuracy: 0.6064 - val_auc: 0.6093 - 4s/epoch - 99ms/step\n",
      "Epoch 65/100\n",
      "38/38 - 4s - loss: 8.9286e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6378 - val_accuracy: 0.6064 - val_auc: 0.6043 - 4s/epoch - 99ms/step\n",
      "Epoch 66/100\n",
      "38/38 - 4s - loss: 0.0033 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 2.6965 - val_accuracy: 0.6064 - val_auc: 0.6059 - 4s/epoch - 98ms/step\n",
      "Epoch 67/100\n",
      "38/38 - 4s - loss: 5.5170e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7027 - val_accuracy: 0.6064 - val_auc: 0.6060 - 4s/epoch - 99ms/step\n",
      "Epoch 68/100\n",
      "38/38 - 4s - loss: 9.6353e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7117 - val_accuracy: 0.6064 - val_auc: 0.6060 - 4s/epoch - 99ms/step\n",
      "Epoch 69/100\n",
      "38/38 - 4s - loss: 8.1331e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7211 - val_accuracy: 0.6064 - val_auc: 0.6066 - 4s/epoch - 98ms/step\n",
      "Epoch 70/100\n",
      "38/38 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7348 - val_accuracy: 0.6064 - val_auc: 0.6063 - 4s/epoch - 97ms/step\n",
      "Epoch 71/100\n",
      "38/38 - 4s - loss: 5.1675e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7446 - val_accuracy: 0.6064 - val_auc: 0.6063 - 4s/epoch - 97ms/step\n",
      "Epoch 72/100\n",
      "38/38 - 4s - loss: 6.5607e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7548 - val_accuracy: 0.6064 - val_auc: 0.6064 - 4s/epoch - 97ms/step\n",
      "Epoch 73/100\n",
      "38/38 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7789 - val_accuracy: 0.6064 - val_auc: 0.6065 - 4s/epoch - 99ms/step\n",
      "Epoch 74/100\n",
      "38/38 - 4s - loss: 5.2211e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7838 - val_accuracy: 0.6064 - val_auc: 0.6066 - 4s/epoch - 97ms/step\n",
      "Epoch 75/100\n",
      "38/38 - 4s - loss: 6.8738e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7936 - val_accuracy: 0.6064 - val_auc: 0.6063 - 4s/epoch - 98ms/step\n",
      "Epoch 76/100\n",
      "38/38 - 4s - loss: 7.3891e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8023 - val_accuracy: 0.6064 - val_auc: 0.6065 - 4s/epoch - 97ms/step\n",
      "Epoch 77/100\n",
      "38/38 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8267 - val_accuracy: 0.6064 - val_auc: 0.6054 - 4s/epoch - 98ms/step\n",
      "Epoch 78/100\n",
      "38/38 - 4s - loss: 6.3882e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8405 - val_accuracy: 0.6064 - val_auc: 0.6002 - 4s/epoch - 99ms/step\n",
      "Epoch 79/100\n",
      "38/38 - 4s - loss: 5.2573e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8474 - val_accuracy: 0.6064 - val_auc: 0.6003 - 4s/epoch - 97ms/step\n",
      "Epoch 80/100\n",
      "38/38 - 4s - loss: 4.4149e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8589 - val_accuracy: 0.6064 - val_auc: 0.6002 - 4s/epoch - 98ms/step\n",
      "Epoch 81/100\n",
      "38/38 - 4s - loss: 4.9152e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8667 - val_accuracy: 0.6064 - val_auc: 0.5999 - 4s/epoch - 99ms/step\n",
      "Epoch 82/100\n",
      "38/38 - 4s - loss: 5.8322e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8558 - val_accuracy: 0.6064 - val_auc: 0.6057 - 4s/epoch - 97ms/step\n",
      "Epoch 83/100\n",
      "38/38 - 4s - loss: 4.6222e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8653 - val_accuracy: 0.6064 - val_auc: 0.6001 - 4s/epoch - 97ms/step\n",
      "Epoch 84/100\n",
      "38/38 - 4s - loss: 4.2460e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8726 - val_accuracy: 0.6064 - val_auc: 0.6000 - 4s/epoch - 97ms/step\n",
      "Epoch 85/100\n",
      "38/38 - 4s - loss: 3.2765e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8793 - val_accuracy: 0.6064 - val_auc: 0.6002 - 4s/epoch - 97ms/step\n",
      "Epoch 86/100\n",
      "38/38 - 4s - loss: 5.5960e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8856 - val_accuracy: 0.6064 - val_auc: 0.6005 - 4s/epoch - 99ms/step\n",
      "Epoch 87/100\n",
      "38/38 - 4s - loss: 5.4377e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8790 - val_accuracy: 0.6064 - val_auc: 0.6115 - 4s/epoch - 97ms/step\n",
      "Epoch 88/100\n",
      "38/38 - 4s - loss: 3.8060e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8846 - val_accuracy: 0.6064 - val_auc: 0.6149 - 4s/epoch - 97ms/step\n",
      "Epoch 89/100\n",
      "38/38 - 4s - loss: 7.3426e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9107 - val_accuracy: 0.6064 - val_auc: 0.6042 - 4s/epoch - 97ms/step\n",
      "Epoch 90/100\n",
      "38/38 - 4s - loss: 4.9287e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9224 - val_accuracy: 0.6064 - val_auc: 0.6073 - 4s/epoch - 98ms/step\n",
      "Epoch 91/100\n",
      "38/38 - 4s - loss: 2.8230e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9290 - val_accuracy: 0.6064 - val_auc: 0.6105 - 4s/epoch - 98ms/step\n",
      "Epoch 92/100\n",
      "38/38 - 4s - loss: 5.4059e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9416 - val_accuracy: 0.6064 - val_auc: 0.6105 - 4s/epoch - 97ms/step\n",
      "Epoch 93/100\n",
      "38/38 - 4s - loss: 4.6752e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9553 - val_accuracy: 0.6064 - val_auc: 0.6101 - 4s/epoch - 97ms/step\n",
      "Epoch 94/100\n",
      "38/38 - 4s - loss: 2.9262e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9622 - val_accuracy: 0.6064 - val_auc: 0.6102 - 4s/epoch - 97ms/step\n",
      "Epoch 95/100\n",
      "38/38 - 4s - loss: 4.2245e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9653 - val_accuracy: 0.6064 - val_auc: 0.6102 - 4s/epoch - 97ms/step\n",
      "Epoch 96/100\n",
      "38/38 - 4s - loss: 6.7685e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9632 - val_accuracy: 0.6170 - val_auc: 0.6236 - 4s/epoch - 97ms/step\n",
      "Epoch 97/100\n",
      "38/38 - 4s - loss: 4.7866e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9681 - val_accuracy: 0.6170 - val_auc: 0.6238 - 4s/epoch - 97ms/step\n",
      "Epoch 98/100\n",
      "38/38 - 4s - loss: 2.7888e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9780 - val_accuracy: 0.6170 - val_auc: 0.6239 - 4s/epoch - 97ms/step\n",
      "Epoch 99/100\n",
      "38/38 - 4s - loss: 4.9128e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9778 - val_accuracy: 0.6170 - val_auc: 0.6246 - 4s/epoch - 97ms/step\n",
      "Epoch 100/100\n",
      "38/38 - 4s - loss: 6.5952e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9954 - val_accuracy: 0.6170 - val_auc: 0.6243 - 4s/epoch - 97ms/step\n",
      "3/3 [==============================] - 1s 367ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59        38\n",
      "           1       0.73      0.57      0.64        56\n",
      "\n",
      "    accuracy                           0.62        94\n",
      "   macro avg       0.62      0.63      0.62        94\n",
      "weighted avg       0.64      0.62      0.62        94\n",
      "\n",
      "Roc 0.6804961206207008\n",
      "Confusion Matrix\n",
      "[[26 12]\n",
      " [24 32]]\n",
      "minority class [1.]\n",
      "minority people 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4044527385.py:122: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y size 0\n",
      "other size 670\n",
      "['Luca S', 'Luca S', 'Luca S', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giustina M', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'AGNESE P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Nicolò C', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S', 'Vito S']\n",
      "Epoch 1/100\n",
      "33/33 - 10s - loss: 1.2201 - accuracy: 0.5134 - auc: 0.5045 - val_loss: 0.9202 - val_accuracy: 0.5740 - val_auc: 0.5870 - 10s/epoch - 291ms/step\n",
      "Epoch 2/100\n",
      "33/33 - 5s - loss: 0.6112 - accuracy: 0.7184 - auc: 0.8018 - val_loss: 0.9054 - val_accuracy: 0.5858 - val_auc: 0.6030 - 5s/epoch - 142ms/step\n",
      "Epoch 3/100\n",
      "33/33 - 4s - loss: 0.4060 - accuracy: 0.8199 - auc: 0.9021 - val_loss: 0.9316 - val_accuracy: 0.5621 - val_auc: 0.5980 - 4s/epoch - 109ms/step\n",
      "Epoch 4/100\n",
      "33/33 - 4s - loss: 0.2837 - accuracy: 0.8678 - auc: 0.9504 - val_loss: 1.0105 - val_accuracy: 0.5680 - val_auc: 0.5939 - 4s/epoch - 108ms/step\n",
      "Epoch 5/100\n",
      "33/33 - 4s - loss: 0.2360 - accuracy: 0.9157 - auc: 0.9657 - val_loss: 1.0795 - val_accuracy: 0.5503 - val_auc: 0.6003 - 4s/epoch - 108ms/step\n",
      "Epoch 6/100\n",
      "33/33 - 5s - loss: 0.1784 - accuracy: 0.9464 - auc: 0.9805 - val_loss: 1.1481 - val_accuracy: 0.5562 - val_auc: 0.6044 - 5s/epoch - 139ms/step\n",
      "Epoch 7/100\n",
      "33/33 - 5s - loss: 0.1550 - accuracy: 0.9368 - auc: 0.9869 - val_loss: 1.2224 - val_accuracy: 0.5621 - val_auc: 0.6104 - 5s/epoch - 137ms/step\n",
      "Epoch 8/100\n",
      "33/33 - 4s - loss: 0.0988 - accuracy: 0.9674 - auc: 0.9951 - val_loss: 1.3207 - val_accuracy: 0.5562 - val_auc: 0.6075 - 4s/epoch - 107ms/step\n",
      "Epoch 9/100\n",
      "33/33 - 4s - loss: 0.0725 - accuracy: 0.9789 - auc: 0.9978 - val_loss: 1.3909 - val_accuracy: 0.5621 - val_auc: 0.6095 - 4s/epoch - 109ms/step\n",
      "Epoch 10/100\n",
      "33/33 - 5s - loss: 0.0686 - accuracy: 0.9828 - auc: 0.9981 - val_loss: 1.4497 - val_accuracy: 0.5799 - val_auc: 0.6107 - 5s/epoch - 137ms/step\n",
      "Epoch 11/100\n",
      "33/33 - 5s - loss: 0.0432 - accuracy: 0.9962 - auc: 0.9995 - val_loss: 1.5024 - val_accuracy: 0.5799 - val_auc: 0.6133 - 5s/epoch - 138ms/step\n",
      "Epoch 12/100\n",
      "33/33 - 5s - loss: 0.0477 - accuracy: 0.9904 - auc: 0.9990 - val_loss: 1.5602 - val_accuracy: 0.5799 - val_auc: 0.6139 - 5s/epoch - 139ms/step\n",
      "Epoch 13/100\n",
      "33/33 - 5s - loss: 0.0331 - accuracy: 0.9923 - auc: 0.9997 - val_loss: 1.6164 - val_accuracy: 0.5799 - val_auc: 0.6158 - 5s/epoch - 140ms/step\n",
      "Epoch 14/100\n",
      "33/33 - 5s - loss: 0.0298 - accuracy: 0.9923 - auc: 0.9998 - val_loss: 1.6607 - val_accuracy: 0.5858 - val_auc: 0.6178 - 5s/epoch - 137ms/step\n",
      "Epoch 15/100\n",
      "33/33 - 4s - loss: 0.0206 - accuracy: 0.9943 - auc: 1.0000 - val_loss: 1.7090 - val_accuracy: 0.5799 - val_auc: 0.6168 - 4s/epoch - 108ms/step\n",
      "Epoch 16/100\n",
      "33/33 - 5s - loss: 0.0187 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.7465 - val_accuracy: 0.5799 - val_auc: 0.6205 - 5s/epoch - 138ms/step\n",
      "Epoch 17/100\n",
      "33/33 - 5s - loss: 0.0171 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 1.7849 - val_accuracy: 0.5858 - val_auc: 0.6229 - 5s/epoch - 139ms/step\n",
      "Epoch 18/100\n",
      "33/33 - 5s - loss: 0.0193 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.8319 - val_accuracy: 0.5858 - val_auc: 0.6238 - 5s/epoch - 137ms/step\n",
      "Epoch 19/100\n",
      "33/33 - 5s - loss: 0.0143 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 1.8756 - val_accuracy: 0.5799 - val_auc: 0.6276 - 5s/epoch - 144ms/step\n",
      "Epoch 20/100\n",
      "33/33 - 4s - loss: 0.0156 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 1.9210 - val_accuracy: 0.5740 - val_auc: 0.6275 - 4s/epoch - 108ms/step\n",
      "Epoch 21/100\n",
      "33/33 - 5s - loss: 0.0099 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 1.9464 - val_accuracy: 0.5799 - val_auc: 0.6281 - 5s/epoch - 138ms/step\n",
      "Epoch 22/100\n",
      "33/33 - 5s - loss: 0.0083 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.9715 - val_accuracy: 0.5799 - val_auc: 0.6292 - 5s/epoch - 138ms/step\n",
      "Epoch 23/100\n",
      "33/33 - 5s - loss: 0.0090 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 1.9963 - val_accuracy: 0.5799 - val_auc: 0.6307 - 5s/epoch - 139ms/step\n",
      "Epoch 24/100\n",
      "33/33 - 5s - loss: 0.0092 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0237 - val_accuracy: 0.5799 - val_auc: 0.6323 - 5s/epoch - 138ms/step\n",
      "Epoch 25/100\n",
      "33/33 - 4s - loss: 0.0084 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.5799 - val_auc: 0.6313 - 4s/epoch - 108ms/step\n",
      "Epoch 26/100\n",
      "33/33 - 4s - loss: 0.0051 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0882 - val_accuracy: 0.5799 - val_auc: 0.6270 - 4s/epoch - 108ms/step\n",
      "Epoch 27/100\n",
      "33/33 - 4s - loss: 0.0073 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 2.1072 - val_accuracy: 0.5799 - val_auc: 0.6268 - 4s/epoch - 108ms/step\n",
      "Epoch 28/100\n",
      "33/33 - 4s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1394 - val_accuracy: 0.5799 - val_auc: 0.6253 - 4s/epoch - 109ms/step\n",
      "Epoch 29/100\n",
      "33/33 - 4s - loss: 0.0054 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1625 - val_accuracy: 0.5799 - val_auc: 0.6238 - 4s/epoch - 108ms/step\n",
      "Epoch 30/100\n",
      "33/33 - 4s - loss: 0.0061 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1830 - val_accuracy: 0.5858 - val_auc: 0.6258 - 4s/epoch - 108ms/step\n",
      "Epoch 31/100\n",
      "33/33 - 4s - loss: 0.0074 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 2.2054 - val_accuracy: 0.5976 - val_auc: 0.6261 - 4s/epoch - 108ms/step\n",
      "Epoch 32/100\n",
      "33/33 - 4s - loss: 0.0045 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2236 - val_accuracy: 0.5976 - val_auc: 0.6254 - 4s/epoch - 108ms/step\n",
      "Epoch 33/100\n",
      "33/33 - 4s - loss: 0.0054 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2491 - val_accuracy: 0.5976 - val_auc: 0.6233 - 4s/epoch - 108ms/step\n",
      "Epoch 34/100\n",
      "33/33 - 4s - loss: 0.0068 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 2.2662 - val_accuracy: 0.5976 - val_auc: 0.6243 - 4s/epoch - 108ms/step\n",
      "Epoch 35/100\n",
      "33/33 - 4s - loss: 0.0054 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2856 - val_accuracy: 0.5917 - val_auc: 0.6243 - 4s/epoch - 107ms/step\n",
      "Epoch 36/100\n",
      "33/33 - 4s - loss: 0.0050 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3084 - val_accuracy: 0.5976 - val_auc: 0.6259 - 4s/epoch - 110ms/step\n",
      "Epoch 37/100\n",
      "33/33 - 4s - loss: 0.0035 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3266 - val_accuracy: 0.5976 - val_auc: 0.6255 - 4s/epoch - 108ms/step\n",
      "Epoch 38/100\n",
      "33/33 - 4s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3371 - val_accuracy: 0.5976 - val_auc: 0.6208 - 4s/epoch - 109ms/step\n",
      "Epoch 39/100\n",
      "33/33 - 4s - loss: 0.0054 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3621 - val_accuracy: 0.5976 - val_auc: 0.6194 - 4s/epoch - 109ms/step\n",
      "Epoch 40/100\n",
      "33/33 - 4s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3766 - val_accuracy: 0.5976 - val_auc: 0.6211 - 4s/epoch - 109ms/step\n",
      "Epoch 41/100\n",
      "33/33 - 4s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3937 - val_accuracy: 0.5976 - val_auc: 0.6183 - 4s/epoch - 109ms/step\n",
      "Epoch 42/100\n",
      "33/33 - 4s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4069 - val_accuracy: 0.5976 - val_auc: 0.6212 - 4s/epoch - 109ms/step\n",
      "Epoch 43/100\n",
      "33/33 - 4s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4215 - val_accuracy: 0.5976 - val_auc: 0.6214 - 4s/epoch - 109ms/step\n",
      "Epoch 44/100\n",
      "33/33 - 4s - loss: 0.0037 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4331 - val_accuracy: 0.5976 - val_auc: 0.6215 - 4s/epoch - 109ms/step\n",
      "Epoch 45/100\n",
      "33/33 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4440 - val_accuracy: 0.5976 - val_auc: 0.6213 - 4s/epoch - 109ms/step\n",
      "Epoch 46/100\n",
      "33/33 - 4s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4582 - val_accuracy: 0.5976 - val_auc: 0.6213 - 4s/epoch - 109ms/step\n",
      "Epoch 47/100\n",
      "33/33 - 4s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4771 - val_accuracy: 0.5976 - val_auc: 0.6183 - 4s/epoch - 110ms/step\n",
      "Epoch 48/100\n",
      "33/33 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4873 - val_accuracy: 0.5976 - val_auc: 0.6181 - 4s/epoch - 109ms/step\n",
      "Epoch 49/100\n",
      "33/33 - 4s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5004 - val_accuracy: 0.5976 - val_auc: 0.6142 - 4s/epoch - 109ms/step\n",
      "Epoch 50/100\n",
      "33/33 - 4s - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5141 - val_accuracy: 0.5976 - val_auc: 0.6149 - 4s/epoch - 110ms/step\n",
      "Epoch 51/100\n",
      "33/33 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5307 - val_accuracy: 0.5917 - val_auc: 0.6148 - 4s/epoch - 110ms/step\n",
      "Epoch 52/100\n",
      "33/33 - 4s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5439 - val_accuracy: 0.5917 - val_auc: 0.6146 - 4s/epoch - 110ms/step\n",
      "Epoch 53/100\n",
      "33/33 - 4s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5580 - val_accuracy: 0.5917 - val_auc: 0.6142 - 4s/epoch - 110ms/step\n",
      "Epoch 54/100\n",
      "33/33 - 4s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5718 - val_accuracy: 0.5917 - val_auc: 0.6142 - 4s/epoch - 109ms/step\n",
      "Epoch 55/100\n",
      "33/33 - 4s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5912 - val_accuracy: 0.5858 - val_auc: 0.6159 - 4s/epoch - 109ms/step\n",
      "Epoch 56/100\n",
      "33/33 - 4s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6071 - val_accuracy: 0.5858 - val_auc: 0.6172 - 4s/epoch - 110ms/step\n",
      "Epoch 57/100\n",
      "33/33 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6171 - val_accuracy: 0.5917 - val_auc: 0.6171 - 4s/epoch - 110ms/step\n",
      "Epoch 58/100\n",
      "33/33 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6284 - val_accuracy: 0.5917 - val_auc: 0.6172 - 4s/epoch - 110ms/step\n",
      "Epoch 59/100\n",
      "33/33 - 4s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6398 - val_accuracy: 0.5917 - val_auc: 0.6160 - 4s/epoch - 110ms/step\n",
      "Epoch 60/100\n",
      "33/33 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6498 - val_accuracy: 0.5976 - val_auc: 0.6158 - 4s/epoch - 109ms/step\n",
      "Epoch 61/100\n",
      "33/33 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6593 - val_accuracy: 0.5976 - val_auc: 0.6176 - 4s/epoch - 109ms/step\n",
      "Epoch 62/100\n",
      "33/33 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6709 - val_accuracy: 0.5976 - val_auc: 0.6172 - 4s/epoch - 110ms/step\n",
      "Epoch 63/100\n",
      "33/33 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6827 - val_accuracy: 0.5976 - val_auc: 0.6165 - 4s/epoch - 109ms/step\n",
      "Epoch 64/100\n",
      "33/33 - 4s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6982 - val_accuracy: 0.5976 - val_auc: 0.6149 - 4s/epoch - 109ms/step\n",
      "Epoch 65/100\n",
      "33/33 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7106 - val_accuracy: 0.5976 - val_auc: 0.6147 - 4s/epoch - 109ms/step\n",
      "Epoch 66/100\n",
      "33/33 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7213 - val_accuracy: 0.5976 - val_auc: 0.6130 - 4s/epoch - 109ms/step\n",
      "Epoch 67/100\n",
      "33/33 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7324 - val_accuracy: 0.5976 - val_auc: 0.6120 - 4s/epoch - 109ms/step\n",
      "Epoch 68/100\n",
      "33/33 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7442 - val_accuracy: 0.5917 - val_auc: 0.6121 - 4s/epoch - 109ms/step\n",
      "Epoch 69/100\n",
      "33/33 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7584 - val_accuracy: 0.5917 - val_auc: 0.6134 - 4s/epoch - 109ms/step\n",
      "Epoch 70/100\n",
      "33/33 - 4s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7723 - val_accuracy: 0.5917 - val_auc: 0.6108 - 4s/epoch - 109ms/step\n",
      "Epoch 71/100\n",
      "33/33 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7824 - val_accuracy: 0.5917 - val_auc: 0.6096 - 4s/epoch - 109ms/step\n",
      "Epoch 72/100\n",
      "33/33 - 4s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7935 - val_accuracy: 0.5917 - val_auc: 0.6113 - 4s/epoch - 109ms/step\n",
      "Epoch 73/100\n",
      "33/33 - 4s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8098 - val_accuracy: 0.5917 - val_auc: 0.6068 - 4s/epoch - 109ms/step\n",
      "Epoch 74/100\n",
      "33/33 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8207 - val_accuracy: 0.5917 - val_auc: 0.6061 - 4s/epoch - 109ms/step\n",
      "Epoch 75/100\n",
      "33/33 - 4s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8347 - val_accuracy: 0.5917 - val_auc: 0.6067 - 4s/epoch - 109ms/step\n",
      "Epoch 76/100\n",
      "33/33 - 4s - loss: 8.5477e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8452 - val_accuracy: 0.5917 - val_auc: 0.6067 - 4s/epoch - 109ms/step\n",
      "Epoch 77/100\n",
      "33/33 - 4s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8563 - val_accuracy: 0.5917 - val_auc: 0.6068 - 4s/epoch - 109ms/step\n",
      "Epoch 78/100\n",
      "33/33 - 4s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8738 - val_accuracy: 0.5917 - val_auc: 0.6044 - 4s/epoch - 109ms/step\n",
      "Epoch 79/100\n",
      "33/33 - 4s - loss: 9.1804e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8835 - val_accuracy: 0.5917 - val_auc: 0.6047 - 4s/epoch - 109ms/step\n",
      "Epoch 80/100\n",
      "33/33 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8942 - val_accuracy: 0.5917 - val_auc: 0.6061 - 4s/epoch - 109ms/step\n",
      "Epoch 81/100\n",
      "33/33 - 4s - loss: 9.3541e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9038 - val_accuracy: 0.5917 - val_auc: 0.6032 - 4s/epoch - 109ms/step\n",
      "Epoch 82/100\n",
      "33/33 - 4s - loss: 7.8354e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9193 - val_accuracy: 0.5917 - val_auc: 0.6017 - 4s/epoch - 109ms/step\n",
      "Epoch 83/100\n",
      "33/33 - 4s - loss: 6.2826e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9289 - val_accuracy: 0.5917 - val_auc: 0.6003 - 4s/epoch - 109ms/step\n",
      "Epoch 84/100\n",
      "33/33 - 4s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9406 - val_accuracy: 0.5917 - val_auc: 0.6000 - 4s/epoch - 109ms/step\n",
      "Epoch 85/100\n",
      "33/33 - 4s - loss: 8.0103e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9511 - val_accuracy: 0.5917 - val_auc: 0.5999 - 4s/epoch - 109ms/step\n",
      "Epoch 86/100\n",
      "33/33 - 4s - loss: 8.4219e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9603 - val_accuracy: 0.5917 - val_auc: 0.5985 - 4s/epoch - 109ms/step\n",
      "Epoch 87/100\n",
      "33/33 - 4s - loss: 5.3042e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9699 - val_accuracy: 0.5917 - val_auc: 0.6002 - 4s/epoch - 109ms/step\n",
      "Epoch 88/100\n",
      "33/33 - 4s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9841 - val_accuracy: 0.5858 - val_auc: 0.5984 - 4s/epoch - 109ms/step\n",
      "Epoch 89/100\n",
      "33/33 - 4s - loss: 8.1881e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.9934 - val_accuracy: 0.5858 - val_auc: 0.5995 - 4s/epoch - 109ms/step\n",
      "Epoch 90/100\n",
      "33/33 - 4s - loss: 8.4084e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0111 - val_accuracy: 0.5858 - val_auc: 0.6007 - 4s/epoch - 108ms/step\n",
      "Epoch 91/100\n",
      "33/33 - 4s - loss: 6.4174e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0226 - val_accuracy: 0.5858 - val_auc: 0.6006 - 4s/epoch - 109ms/step\n",
      "Epoch 92/100\n",
      "33/33 - 4s - loss: 4.3566e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0284 - val_accuracy: 0.5858 - val_auc: 0.6006 - 4s/epoch - 108ms/step\n",
      "Epoch 93/100\n",
      "33/33 - 4s - loss: 5.0484e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0358 - val_accuracy: 0.5858 - val_auc: 0.6007 - 4s/epoch - 109ms/step\n",
      "Epoch 94/100\n",
      "33/33 - 4s - loss: 6.7888e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0454 - val_accuracy: 0.5858 - val_auc: 0.6007 - 4s/epoch - 110ms/step\n",
      "Epoch 95/100\n",
      "33/33 - 4s - loss: 8.2812e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0506 - val_accuracy: 0.5858 - val_auc: 0.6010 - 4s/epoch - 109ms/step\n",
      "Epoch 96/100\n",
      "33/33 - 4s - loss: 9.8409e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0617 - val_accuracy: 0.5858 - val_auc: 0.6028 - 4s/epoch - 108ms/step\n",
      "Epoch 97/100\n",
      "33/33 - 4s - loss: 9.1862e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0749 - val_accuracy: 0.5858 - val_auc: 0.6027 - 4s/epoch - 108ms/step\n",
      "Epoch 98/100\n",
      "33/33 - 4s - loss: 9.2065e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0865 - val_accuracy: 0.5858 - val_auc: 0.6028 - 4s/epoch - 108ms/step\n",
      "Epoch 99/100\n",
      "33/33 - 4s - loss: 7.5281e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.0979 - val_accuracy: 0.5858 - val_auc: 0.6027 - 4s/epoch - 108ms/step\n",
      "Epoch 100/100\n",
      "33/33 - 4s - loss: 4.9076e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1068 - val_accuracy: 0.5799 - val_auc: 0.6030 - 4s/epoch - 108ms/step\n",
      "6/6 [==============================] - 1s 53ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.55      0.51        67\n",
      "           1       0.67      0.60      0.63       102\n",
      "\n",
      "    accuracy                           0.58       169\n",
      "   macro avg       0.57      0.58      0.57       169\n",
      "weighted avg       0.59      0.58      0.58       169\n",
      "\n",
      "Roc 0.6143845686291826\n",
      "Confusion Matrix\n",
      "[[37 30]\n",
      " [41 61]]\n",
      "{'0': {'precision': 0.44, 'recall': 0.5789473684210527, 'f1-score': 0.5, 'support': 38.0}, '1': {'precision': 0.7647058823529411, 'recall': 0.65, 'f1-score': 0.7027027027027027, 'support': 80.0}, 'accuracy': 0.6271186440677966, 'macro avg': {'precision': 0.6023529411764705, 'recall': 0.6144736842105263, 'f1-score': 0.6013513513513513, 'support': 118.0}, 'weighted avg': {'precision': 0.6601395812562313, 'recall': 0.6271186440677966, 'f1-score': 0.6374255611543748, 'support': 118.0}}\n",
      "{'0': {'precision': 0.4657534246575342, 'recall': 0.7727272727272727, 'f1-score': 0.5811965811965812, 'support': 44.0}, '1': {'precision': 0.8412698412698413, 'recall': 0.5760869565217391, 'f1-score': 0.6838709677419355, 'support': 92.0}, 'accuracy': 0.6397058823529411, 'macro avg': {'precision': 0.6535116329636877, 'recall': 0.6744071146245059, 'f1-score': 0.6325337744692583, 'support': 136.0}, 'weighted avg': {'precision': 0.7197792358952713, 'recall': 0.6397058823529411, 'f1-score': 0.650652783859615, 'support': 136.0}}\n",
      "{'0': {'precision': 0.5, 'recall': 0.34210526315789475, 'f1-score': 0.40625000000000006, 'support': 38.0}, '1': {'precision': 0.6621621621621622, 'recall': 0.7903225806451613, 'f1-score': 0.7205882352941176, 'support': 62.0}, 'accuracy': 0.62, 'macro avg': {'precision': 0.5810810810810811, 'recall': 0.566213921901528, 'f1-score': 0.5634191176470589, 'support': 100.0}, 'weighted avg': {'precision': 0.6005405405405405, 'recall': 0.62, 'f1-score': 0.601139705882353, 'support': 100.0}}\n",
      "{'0': {'precision': 0.52, 'recall': 0.6842105263157895, 'f1-score': 0.5909090909090909, 'support': 38.0}, '1': {'precision': 0.7272727272727273, 'recall': 0.5714285714285714, 'f1-score': 0.64, 'support': 56.0}, 'accuracy': 0.6170212765957447, 'macro avg': {'precision': 0.6236363636363637, 'recall': 0.6278195488721805, 'f1-score': 0.6154545454545455, 'support': 94.0}, 'weighted avg': {'precision': 0.6434816247582205, 'recall': 0.6170212765957447, 'f1-score': 0.6201547388781432, 'support': 94.0}}\n",
      "{'0': {'precision': 0.47435897435897434, 'recall': 0.5522388059701493, 'f1-score': 0.5103448275862068, 'support': 67.0}, '1': {'precision': 0.6703296703296703, 'recall': 0.5980392156862745, 'f1-score': 0.6321243523316062, 'support': 102.0}, 'accuracy': 0.5798816568047337, 'macro avg': {'precision': 0.5723443223443223, 'recall': 0.575139010828212, 'f1-score': 0.5712345899589065, 'support': 169.0}, 'weighted avg': {'precision': 0.5926371458915837, 'recall': 0.5798816568047337, 'f1-score': 0.5838448957757378, 'support': 169.0}}\n",
      "Mean accuracy 0.6167454919642432\n",
      "Mean precision 0.6433156256683694\n",
      "Mean recall 0.6167454919642432\n",
      "Mean F1 0.6186435371100447\n",
      "None\n",
      "AUC\n",
      "0.641118162062374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "aa = []\n",
    "saucs = []\n",
    "saa = []\n",
    "histories = []\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "#from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow\n",
    "\n",
    "def concilie_per_patient_res(predx, y_test, usercodes):\n",
    "    new_pred = []\n",
    "    new_y_test = []\n",
    "     \n",
    "    #print('Prediced shape')\n",
    "    #print(predx.shape)\n",
    "    \n",
    "    if y_test.shape[-1] < 2:\n",
    "      y_test = to_categorical(y_test)\n",
    "    patient = {}\n",
    "    for i in range(len(y_test)):\n",
    "      if not usercodes[i] in patient:\n",
    "        patient[usercodes[i]] = {}\n",
    "        patient[usercodes[i]]['predicted'] = []\n",
    "        patient[usercodes[i]]['y_test'] = []               \n",
    "      patient[usercodes[i]]['predicted'].append(predx[i])\n",
    "      patient[usercodes[i]]['y_test'].append(y_test[i])\n",
    "      #print(patient[usercodes[i]]['predicted'])\n",
    "    keys = list(patient.keys())\n",
    "    for key in keys:\n",
    "       predi = patient[key]['predicted']\n",
    "       yi = patient[key]['y_test']\n",
    "       mean_pred = np.asarray(predi).mean(axis=0)\n",
    "       mean_y = np.asarray(yi).mean(axis=0)\n",
    "       #print('Mean pred shape '+str(mean_pred.shape))\n",
    "       #print('Mean y shape '+str(mean_y.shape))\n",
    "       new_pred.append(mean_pred)\n",
    "       new_y_test.append(mean_y)\n",
    "\n",
    "    new_pred = np.asarray(new_pred)\n",
    "    #print(new_pred.shape)\n",
    "    new_y_test = np.asarray(new_y_test)\n",
    "    #print(new_y_test.shape)\n",
    "\n",
    "    return new_pred, new_y_test\n",
    "    \n",
    " \n",
    "\n",
    "def report_average(reports):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for report in reports:\n",
    "        print(report)\n",
    "        accuracy.append(report['accuracy'])\n",
    "        precision.append(report['weighted avg']['precision'])\n",
    "        recall.append(report['weighted avg']['recall'])\n",
    "        f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "    print('Mean accuracy '+str(np.mean(accuracy)))\n",
    "    print('Mean precision ' + str(np.mean(precision)))\n",
    "    print('Mean recall ' + str(np.mean(recall)))\n",
    "    print('Mean F1 ' + str(np.mean(f1)))\n",
    "\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    " \n",
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "          \n",
    " \n",
    "for i in range(5):\n",
    "    #K.clear_session()#puliamo la ram della GPU \n",
    "    tf.keras.backend.clear_session()\n",
    " \n",
    "    y_new = np.asarray(y,dtype=np.float32)\n",
    "    X_new = np.asarray(X,dtype=np.float32)\n",
    "    y_size = 0\n",
    "\n",
    "    \n",
    "    if True:\n",
    "      #while y_size < int(len(X_new)*0.05):\n",
    "     \n",
    "      X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2)\n",
    "      cd = np.where(y_train == to_categorical([1.0]))\n",
    "      cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
    "      y_size = len(cd2[0])\n",
    "      print('y size',y_size)\n",
    "      print('other size',len(cd[0]))\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    "    print(test_usercodes)\n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    "\n",
    "    input_shape = (1, X_train[0].shape[1])\n",
    "    #report_standard_algo(X_train.copy(),X_test.copy(),y_train.copy(),y_test.copy(),train_usercodes,test_usercodes)\n",
    "\n",
    "\n",
    "    \n",
    "     \n",
    "    for k in range(1):\n",
    "      model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='transformer'+str(i)+'.weights.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "      #strategy = tf.distribute.MirroredStrategy()\n",
    "      if True:#with strategy.scope():\n",
    "          # Everything that creates variables should be under the strategy scope.\n",
    "          # In general this is only model construction & `compile()`.\n",
    "          model = AudioTransformer(2, embed_size=64, num_heads=4, ff_dim=64, rate=0.25)\n",
    "          model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                          loss=\"categorical_crossentropy\",\n",
    "                           metrics=['accuracy','AUC'])\n",
    "      \n",
    "      \n",
    "      history = model.fit(X_train,y_train, epochs=100, batch_size=16,  validation_data = (X_test,y_test), \n",
    "                                callbacks=[model_checkpoint_callback], verbose=2)\n",
    "      model2 = model\n",
    "          \n",
    "          \n",
    "          \n",
    "      if model2 != None:\n",
    "        model2.load_weights('transformer'+str(i)+'.weights.h5')\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        \n",
    "        new_pred = y_pred\n",
    "        new_y_test = y_test\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "        aa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "        aucs.append(roc_auc)\n",
    "        # Plot non-normalized confusion matrix\n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "\n",
    "\n",
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.44, 'recall': 0.5789473684210527, 'f1-score': 0.5, 'support': 38.0}, '1': {'precision': 0.7647058823529411, 'recall': 0.65, 'f1-score': 0.7027027027027027, 'support': 80.0}, 'accuracy': 0.6271186440677966, 'macro avg': {'precision': 0.6023529411764705, 'recall': 0.6144736842105263, 'f1-score': 0.6013513513513513, 'support': 118.0}, 'weighted avg': {'precision': 0.6601395812562313, 'recall': 0.6271186440677966, 'f1-score': 0.6374255611543748, 'support': 118.0}}\n",
      "{'0': {'precision': 0.4657534246575342, 'recall': 0.7727272727272727, 'f1-score': 0.5811965811965812, 'support': 44.0}, '1': {'precision': 0.8412698412698413, 'recall': 0.5760869565217391, 'f1-score': 0.6838709677419355, 'support': 92.0}, 'accuracy': 0.6397058823529411, 'macro avg': {'precision': 0.6535116329636877, 'recall': 0.6744071146245059, 'f1-score': 0.6325337744692583, 'support': 136.0}, 'weighted avg': {'precision': 0.7197792358952713, 'recall': 0.6397058823529411, 'f1-score': 0.650652783859615, 'support': 136.0}}\n",
      "{'0': {'precision': 0.5, 'recall': 0.34210526315789475, 'f1-score': 0.40625000000000006, 'support': 38.0}, '1': {'precision': 0.6621621621621622, 'recall': 0.7903225806451613, 'f1-score': 0.7205882352941176, 'support': 62.0}, 'accuracy': 0.62, 'macro avg': {'precision': 0.5810810810810811, 'recall': 0.566213921901528, 'f1-score': 0.5634191176470589, 'support': 100.0}, 'weighted avg': {'precision': 0.6005405405405405, 'recall': 0.62, 'f1-score': 0.601139705882353, 'support': 100.0}}\n",
      "{'0': {'precision': 0.52, 'recall': 0.6842105263157895, 'f1-score': 0.5909090909090909, 'support': 38.0}, '1': {'precision': 0.7272727272727273, 'recall': 0.5714285714285714, 'f1-score': 0.64, 'support': 56.0}, 'accuracy': 0.6170212765957447, 'macro avg': {'precision': 0.6236363636363637, 'recall': 0.6278195488721805, 'f1-score': 0.6154545454545455, 'support': 94.0}, 'weighted avg': {'precision': 0.6434816247582205, 'recall': 0.6170212765957447, 'f1-score': 0.6201547388781432, 'support': 94.0}}\n",
      "{'0': {'precision': 0.47435897435897434, 'recall': 0.5522388059701493, 'f1-score': 0.5103448275862068, 'support': 67.0}, '1': {'precision': 0.6703296703296703, 'recall': 0.5980392156862745, 'f1-score': 0.6321243523316062, 'support': 102.0}, 'accuracy': 0.5798816568047337, 'macro avg': {'precision': 0.5723443223443223, 'recall': 0.575139010828212, 'f1-score': 0.5712345899589065, 'support': 169.0}, 'weighted avg': {'precision': 0.5926371458915837, 'recall': 0.5798816568047337, 'f1-score': 0.5838448957757378, 'support': 169.0}}\n",
      "Mean accuracy 0.6167454919642432\n",
      "Mean precision 0.6433156256683694\n",
      "Mean recall 0.6167454919642432\n",
      "Mean F1 0.6186435371100447\n",
      "None\n",
      "AUC\n",
      "0.641118162062374\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISION TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from vit_keras import vit\n",
    "\n",
    "class AudioVisionTransformer(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(AudioVisionTransformer, self).__init__()\n",
    "        self.num_mel_bins = 64\n",
    "        self.vit_model = vit.vit_b32(\n",
    "            image_size=64,\n",
    "            activation='softmax',\n",
    "            pretrained=True,\n",
    "            include_top=True,\n",
    "            pretrained_top=False,\n",
    "            classes=num_classes,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        sample_rate = 22050  # Define your sample rate\n",
    "        \n",
    "        # Cast inputs to float32 to ensure compatibility with STFT\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "        stfts = tf.signal.stft(\n",
    "            inputs,\n",
    "            frame_length=255,\n",
    "            frame_step=128,\n",
    "            fft_length=256,\n",
    "        )\n",
    "        magnitude_spectrograms = tf.abs(stfts)\n",
    "        num_spectrogram_bins = magnitude_spectrograms.shape[-1]\n",
    "        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 80.0, 7600.0, self.num_mel_bins\n",
    "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "            self.num_mel_bins,\n",
    "            num_spectrogram_bins,\n",
    "            sample_rate,\n",
    "            lower_edge_hertz,\n",
    "            upper_edge_hertz,\n",
    "        )\n",
    "        mel_spectrograms = tf.tensordot(\n",
    "            magnitude_spectrograms,\n",
    "            linear_to_mel_weight_matrix,\n",
    "            1,\n",
    "        )\n",
    "        mel_spectrograms.set_shape(\n",
    "            magnitude_spectrograms.shape[:-1].concatenate(\n",
    "                linear_to_mel_weight_matrix.shape[-1:]\n",
    "            )\n",
    "        )\n",
    "        # Reshape the Mel spectrograms to have dimensions of (64, 64)\n",
    "        mel_spectrograms = tf.image.resize(mel_spectrograms, [64, 64])\n",
    "        # Select the first 3 channels\n",
    "        mel_spectrograms = mel_spectrograms[..., :3]\n",
    "        return self.vit_model(mel_spectrograms, training=training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n",
      "minority class [1.]\n",
      "minority people 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:48:04.202444: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.202634: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.202720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.202861: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.202938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.202999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-07 14:48:04.203093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.203169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.203237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.203318: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.203388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:48:04.203442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y size 0\n",
      "other size 810\n",
      "['Biagio P', 'Biagio P', 'Biagio P', 'Davide S', 'Davide S', 'Davide S', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Ugo B', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/2551710120.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:48:22.710130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 30s - loss: 0.8248 - accuracy: 0.6877 - auc: 0.7813 - val_loss: 0.1864 - val_accuracy: 0.9211 - val_auc: 0.9820 - 30s/epoch - 5s/step\n",
      "Epoch 2/100\n",
      "6/6 - 1s - loss: 0.5139 - accuracy: 0.7973 - auc: 0.8821 - val_loss: 0.2100 - val_accuracy: 0.8947 - val_auc: 0.9751 - 583ms/epoch - 97ms/step\n",
      "Epoch 3/100\n",
      "6/6 - 1s - loss: 0.3402 - accuracy: 0.8498 - auc: 0.9286 - val_loss: 0.1719 - val_accuracy: 0.9474 - val_auc: 0.9861 - 1s/epoch - 196ms/step\n",
      "Epoch 4/100\n",
      "6/6 - 1s - loss: 0.2572 - accuracy: 0.8859 - auc: 0.9598 - val_loss: 0.1332 - val_accuracy: 0.9474 - val_auc: 0.9945 - 812ms/epoch - 135ms/step\n",
      "Epoch 5/100\n",
      "6/6 - 1s - loss: 0.2085 - accuracy: 0.9039 - auc: 0.9737 - val_loss: 0.1163 - val_accuracy: 0.9474 - val_auc: 0.9972 - 804ms/epoch - 134ms/step\n",
      "Epoch 6/100\n",
      "6/6 - 1s - loss: 0.1844 - accuracy: 0.9264 - auc: 0.9790 - val_loss: 0.1105 - val_accuracy: 1.0000 - val_auc: 1.0000 - 799ms/epoch - 133ms/step\n",
      "Epoch 7/100\n",
      "6/6 - 1s - loss: 0.1676 - accuracy: 0.9279 - auc: 0.9829 - val_loss: 0.1910 - val_accuracy: 0.8947 - val_auc: 0.9861 - 537ms/epoch - 90ms/step\n",
      "Epoch 8/100\n",
      "6/6 - 1s - loss: 0.1472 - accuracy: 0.9369 - auc: 0.9875 - val_loss: 0.0817 - val_accuracy: 0.9737 - val_auc: 0.9993 - 553ms/epoch - 92ms/step\n",
      "Epoch 9/100\n",
      "6/6 - 1s - loss: 0.1066 - accuracy: 0.9625 - auc: 0.9925 - val_loss: 0.0679 - val_accuracy: 0.9737 - val_auc: 0.9993 - 543ms/epoch - 90ms/step\n",
      "Epoch 10/100\n",
      "6/6 - 1s - loss: 0.1034 - accuracy: 0.9565 - auc: 0.9939 - val_loss: 0.2235 - val_accuracy: 0.8684 - val_auc: 0.9723 - 527ms/epoch - 88ms/step\n",
      "Epoch 11/100\n",
      "6/6 - 1s - loss: 0.0786 - accuracy: 0.9715 - auc: 0.9962 - val_loss: 0.0749 - val_accuracy: 0.9737 - val_auc: 0.9979 - 554ms/epoch - 92ms/step\n",
      "Epoch 12/100\n",
      "6/6 - 1s - loss: 0.0626 - accuracy: 0.9775 - auc: 0.9976 - val_loss: 0.1464 - val_accuracy: 0.9737 - val_auc: 0.9834 - 562ms/epoch - 94ms/step\n",
      "Epoch 13/100\n",
      "6/6 - 1s - loss: 0.0505 - accuracy: 0.9820 - auc: 0.9985 - val_loss: 0.1832 - val_accuracy: 0.9474 - val_auc: 0.9827 - 534ms/epoch - 89ms/step\n",
      "Epoch 14/100\n",
      "6/6 - 1s - loss: 0.0540 - accuracy: 0.9805 - auc: 0.9982 - val_loss: 0.0743 - val_accuracy: 0.9737 - val_auc: 0.9972 - 534ms/epoch - 89ms/step\n",
      "Epoch 15/100\n",
      "6/6 - 1s - loss: 0.0366 - accuracy: 0.9865 - auc: 0.9978 - val_loss: 0.1271 - val_accuracy: 0.9737 - val_auc: 0.9882 - 537ms/epoch - 89ms/step\n",
      "Epoch 16/100\n",
      "6/6 - 1s - loss: 0.0300 - accuracy: 0.9865 - auc: 0.9995 - val_loss: 0.2074 - val_accuracy: 0.9474 - val_auc: 0.9654 - 537ms/epoch - 89ms/step\n",
      "Epoch 17/100\n",
      "6/6 - 1s - loss: 0.0214 - accuracy: 0.9925 - auc: 0.9998 - val_loss: 0.1650 - val_accuracy: 0.9737 - val_auc: 0.9675 - 535ms/epoch - 89ms/step\n",
      "Epoch 18/100\n",
      "6/6 - 1s - loss: 0.0132 - accuracy: 0.9985 - auc: 0.9999 - val_loss: 0.1677 - val_accuracy: 0.9737 - val_auc: 0.9681 - 576ms/epoch - 96ms/step\n",
      "Epoch 19/100\n",
      "6/6 - 1s - loss: 0.0344 - accuracy: 0.9850 - auc: 0.9993 - val_loss: 0.3091 - val_accuracy: 0.9211 - val_auc: 0.9598 - 527ms/epoch - 88ms/step\n",
      "Epoch 20/100\n",
      "6/6 - 1s - loss: 0.0385 - accuracy: 0.9895 - auc: 0.9978 - val_loss: 0.2871 - val_accuracy: 0.8947 - val_auc: 0.9820 - 567ms/epoch - 94ms/step\n",
      "Epoch 21/100\n",
      "6/6 - 1s - loss: 0.0109 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9211 - val_auc: 0.9335 - 540ms/epoch - 90ms/step\n",
      "Epoch 22/100\n",
      "6/6 - 1s - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.8947 - val_auc: 0.9398 - 568ms/epoch - 95ms/step\n",
      "Epoch 23/100\n",
      "6/6 - 1s - loss: 0.0086 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.8947 - val_auc: 0.9349 - 614ms/epoch - 102ms/step\n",
      "Epoch 24/100\n",
      "6/6 - 1s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.9211 - val_auc: 0.9370 - 581ms/epoch - 97ms/step\n",
      "Epoch 25/100\n",
      "6/6 - 1s - loss: 0.0046 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.1859 - val_accuracy: 0.9474 - val_auc: 0.9868 - 549ms/epoch - 91ms/step\n",
      "Epoch 26/100\n",
      "6/6 - 1s - loss: 3.4172e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9474 - val_auc: 0.9910 - 534ms/epoch - 89ms/step\n",
      "Epoch 27/100\n",
      "6/6 - 1s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2340 - val_accuracy: 0.9211 - val_auc: 0.9938 - 537ms/epoch - 90ms/step\n",
      "Epoch 28/100\n",
      "6/6 - 1s - loss: 0.0033 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9737 - val_auc: 0.9681 - 535ms/epoch - 89ms/step\n",
      "Epoch 29/100\n",
      "6/6 - 1s - loss: 5.1684e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9211 - val_auc: 0.9591 - 536ms/epoch - 89ms/step\n",
      "Epoch 30/100\n",
      "6/6 - 1s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9474 - val_auc: 0.9668 - 532ms/epoch - 89ms/step\n",
      "Epoch 31/100\n",
      "6/6 - 1s - loss: 3.0314e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1793 - val_accuracy: 0.9737 - val_auc: 0.9688 - 537ms/epoch - 89ms/step\n",
      "Epoch 32/100\n",
      "6/6 - 1s - loss: 0.0020 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9737 - val_auc: 0.9688 - 542ms/epoch - 90ms/step\n",
      "Epoch 33/100\n",
      "6/6 - 1s - loss: 0.0019 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9211 - val_auc: 0.9882 - 532ms/epoch - 89ms/step\n",
      "Epoch 34/100\n",
      "6/6 - 1s - loss: 0.0035 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 0.1520 - val_accuracy: 0.9737 - val_auc: 0.9896 - 537ms/epoch - 89ms/step\n",
      "Epoch 35/100\n",
      "6/6 - 1s - loss: 5.2918e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9474 - val_auc: 0.9619 - 534ms/epoch - 89ms/step\n",
      "Epoch 36/100\n",
      "6/6 - 1s - loss: 0.0188 - accuracy: 0.9970 - auc: 0.9985 - val_loss: 0.0997 - val_accuracy: 0.9737 - val_auc: 0.9938 - 535ms/epoch - 89ms/step\n",
      "Epoch 37/100\n",
      "6/6 - 1s - loss: 0.0133 - accuracy: 0.9970 - auc: 0.9985 - val_loss: 0.2290 - val_accuracy: 0.9737 - val_auc: 0.9688 - 529ms/epoch - 88ms/step\n",
      "Epoch 38/100\n",
      "6/6 - 1s - loss: 0.0048 - accuracy: 0.9970 - auc: 1.0000 - val_loss: 0.3010 - val_accuracy: 0.9211 - val_auc: 0.9626 - 538ms/epoch - 90ms/step\n",
      "Epoch 39/100\n",
      "6/6 - 1s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.9211 - val_auc: 0.9342 - 535ms/epoch - 89ms/step\n",
      "Epoch 40/100\n",
      "6/6 - 1s - loss: 0.0124 - accuracy: 0.9985 - auc: 0.9984 - val_loss: 0.5664 - val_accuracy: 0.9211 - val_auc: 0.9107 - 536ms/epoch - 89ms/step\n",
      "Epoch 41/100\n",
      "6/6 - 1s - loss: 0.0068 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.9211 - val_auc: 0.9522 - 532ms/epoch - 89ms/step\n",
      "Epoch 42/100\n",
      "6/6 - 1s - loss: 7.4480e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.8947 - val_auc: 0.9571 - 542ms/epoch - 90ms/step\n",
      "Epoch 43/100\n",
      "6/6 - 1s - loss: 0.0016 - accuracy: 0.9985 - auc: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.9211 - val_auc: 0.9107 - 533ms/epoch - 89ms/step\n",
      "Epoch 44/100\n",
      "6/6 - 1s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6289 - val_accuracy: 0.9211 - val_auc: 0.9107 - 543ms/epoch - 90ms/step\n",
      "Epoch 45/100\n",
      "6/6 - 1s - loss: 6.0535e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6494 - val_accuracy: 0.9211 - val_auc: 0.9107 - 536ms/epoch - 89ms/step\n",
      "Epoch 46/100\n",
      "6/6 - 1s - loss: 3.4902e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.9211 - val_auc: 0.9107 - 537ms/epoch - 89ms/step\n",
      "Epoch 47/100\n",
      "6/6 - 1s - loss: 6.6735e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6611 - val_accuracy: 0.9211 - val_auc: 0.9107 - 540ms/epoch - 90ms/step\n",
      "Epoch 48/100\n",
      "6/6 - 1s - loss: 1.6576e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.9211 - val_auc: 0.9321 - 541ms/epoch - 90ms/step\n",
      "Epoch 49/100\n",
      "6/6 - 1s - loss: 1.8496e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.9211 - val_auc: 0.9107 - 527ms/epoch - 88ms/step\n",
      "Epoch 50/100\n",
      "6/6 - 1s - loss: 1.2736e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6597 - val_accuracy: 0.9211 - val_auc: 0.9107 - 542ms/epoch - 90ms/step\n",
      "Epoch 51/100\n",
      "6/6 - 1s - loss: 4.8882e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.9211 - val_auc: 0.9107 - 542ms/epoch - 90ms/step\n",
      "Epoch 52/100\n",
      "6/6 - 1s - loss: 1.1437e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6255 - val_accuracy: 0.9211 - val_auc: 0.9321 - 541ms/epoch - 90ms/step\n",
      "Epoch 53/100\n",
      "6/6 - 1s - loss: 2.3733e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9211 - val_auc: 0.9342 - 536ms/epoch - 89ms/step\n",
      "Epoch 54/100\n",
      "6/6 - 1s - loss: 7.5895e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5938 - val_accuracy: 0.9211 - val_auc: 0.9342 - 534ms/epoch - 89ms/step\n",
      "Epoch 55/100\n",
      "6/6 - 1s - loss: 8.6527e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8947 - val_auc: 0.9335 - 537ms/epoch - 89ms/step\n",
      "Epoch 56/100\n",
      "6/6 - 1s - loss: 1.0050e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.8947 - val_auc: 0.9335 - 538ms/epoch - 90ms/step\n",
      "Epoch 57/100\n",
      "6/6 - 1s - loss: 5.1858e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.8947 - val_auc: 0.9335 - 544ms/epoch - 91ms/step\n",
      "Epoch 58/100\n",
      "6/6 - 1s - loss: 7.0215e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.8947 - val_auc: 0.9335 - 533ms/epoch - 89ms/step\n",
      "Epoch 59/100\n",
      "6/6 - 1s - loss: 5.6685e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.8947 - val_auc: 0.9363 - 546ms/epoch - 91ms/step\n",
      "Epoch 60/100\n",
      "6/6 - 1s - loss: 4.8371e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5952 - val_accuracy: 0.8947 - val_auc: 0.9363 - 540ms/epoch - 90ms/step\n",
      "Epoch 61/100\n",
      "6/6 - 1s - loss: 2.1787e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.8947 - val_auc: 0.9335 - 539ms/epoch - 90ms/step\n",
      "Epoch 62/100\n",
      "6/6 - 1s - loss: 7.4678e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6099 - val_accuracy: 0.9211 - val_auc: 0.9342 - 537ms/epoch - 90ms/step\n",
      "Epoch 63/100\n",
      "6/6 - 1s - loss: 5.0695e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.9211 - val_auc: 0.9342 - 540ms/epoch - 90ms/step\n",
      "Epoch 64/100\n",
      "6/6 - 1s - loss: 2.0500e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.9211 - val_auc: 0.9321 - 543ms/epoch - 90ms/step\n",
      "Epoch 65/100\n",
      "6/6 - 1s - loss: 4.2575e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.9211 - val_auc: 0.9107 - 534ms/epoch - 89ms/step\n",
      "Epoch 66/100\n",
      "6/6 - 1s - loss: 5.1369e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.9211 - val_auc: 0.9107 - 539ms/epoch - 90ms/step\n",
      "Epoch 67/100\n",
      "6/6 - 1s - loss: 9.8541e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.9211 - val_auc: 0.9107 - 538ms/epoch - 90ms/step\n",
      "Epoch 68/100\n",
      "6/6 - 1s - loss: 8.1522e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.9211 - val_auc: 0.9107 - 538ms/epoch - 90ms/step\n",
      "Epoch 69/100\n",
      "6/6 - 1s - loss: 5.9160e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.9211 - val_auc: 0.9107 - 536ms/epoch - 89ms/step\n",
      "Epoch 70/100\n",
      "6/6 - 1s - loss: 3.6151e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.9211 - val_auc: 0.9107 - 543ms/epoch - 90ms/step\n",
      "Epoch 71/100\n",
      "6/6 - 1s - loss: 4.8210e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7153 - val_accuracy: 0.9211 - val_auc: 0.9107 - 541ms/epoch - 90ms/step\n",
      "Epoch 72/100\n",
      "6/6 - 1s - loss: 6.5519e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7109 - val_accuracy: 0.9211 - val_auc: 0.9107 - 539ms/epoch - 90ms/step\n",
      "Epoch 73/100\n",
      "6/6 - 1s - loss: 5.2974e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7090 - val_accuracy: 0.9211 - val_auc: 0.9107 - 541ms/epoch - 90ms/step\n",
      "Epoch 74/100\n",
      "6/6 - 1s - loss: 4.2134e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.9211 - val_auc: 0.9107 - 543ms/epoch - 90ms/step\n",
      "Epoch 75/100\n",
      "6/6 - 1s - loss: 4.4138e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7061 - val_accuracy: 0.9211 - val_auc: 0.9107 - 541ms/epoch - 90ms/step\n",
      "Epoch 76/100\n",
      "6/6 - 1s - loss: 7.3324e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7021 - val_accuracy: 0.9211 - val_auc: 0.9107 - 535ms/epoch - 89ms/step\n",
      "Epoch 77/100\n",
      "6/6 - 1s - loss: 2.5752e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6953 - val_accuracy: 0.9211 - val_auc: 0.9107 - 544ms/epoch - 91ms/step\n",
      "Epoch 78/100\n",
      "6/6 - 1s - loss: 4.5282e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.9211 - val_auc: 0.9214 - 536ms/epoch - 89ms/step\n",
      "Epoch 79/100\n",
      "6/6 - 1s - loss: 2.3034e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.9211 - val_auc: 0.9321 - 541ms/epoch - 90ms/step\n",
      "Epoch 80/100\n",
      "6/6 - 1s - loss: 3.7684e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.9211 - val_auc: 0.9321 - 534ms/epoch - 89ms/step\n",
      "Epoch 81/100\n",
      "6/6 - 1s - loss: 4.0487e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.9211 - val_auc: 0.9321 - 545ms/epoch - 91ms/step\n",
      "Epoch 82/100\n",
      "6/6 - 1s - loss: 3.0143e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.9211 - val_auc: 0.9321 - 539ms/epoch - 90ms/step\n",
      "Epoch 83/100\n",
      "6/6 - 1s - loss: 2.9969e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.9211 - val_auc: 0.9321 - 536ms/epoch - 89ms/step\n",
      "Epoch 84/100\n",
      "6/6 - 1s - loss: 2.7772e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6865 - val_accuracy: 0.9211 - val_auc: 0.9321 - 536ms/epoch - 89ms/step\n",
      "Epoch 85/100\n",
      "6/6 - 1s - loss: 2.8722e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.9211 - val_auc: 0.9321 - 538ms/epoch - 90ms/step\n",
      "Epoch 86/100\n",
      "6/6 - 1s - loss: 2.0700e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6890 - val_accuracy: 0.9211 - val_auc: 0.9321 - 535ms/epoch - 89ms/step\n",
      "Epoch 87/100\n",
      "6/6 - 1s - loss: 2.2855e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6899 - val_accuracy: 0.9211 - val_auc: 0.9321 - 539ms/epoch - 90ms/step\n",
      "Epoch 88/100\n",
      "6/6 - 1s - loss: 2.5879e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.9211 - val_auc: 0.9321 - 546ms/epoch - 91ms/step\n",
      "Epoch 89/100\n",
      "6/6 - 1s - loss: 2.6245e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.9211 - val_auc: 0.9321 - 542ms/epoch - 90ms/step\n",
      "Epoch 90/100\n",
      "6/6 - 1s - loss: 2.9662e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.9211 - val_auc: 0.9321 - 539ms/epoch - 90ms/step\n",
      "Epoch 91/100\n",
      "6/6 - 1s - loss: 3.2765e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6914 - val_accuracy: 0.9211 - val_auc: 0.9321 - 533ms/epoch - 89ms/step\n",
      "Epoch 92/100\n",
      "6/6 - 1s - loss: 5.5230e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.9211 - val_auc: 0.9321 - 542ms/epoch - 90ms/step\n",
      "Epoch 93/100\n",
      "6/6 - 1s - loss: 4.4060e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.9211 - val_auc: 0.9321 - 539ms/epoch - 90ms/step\n",
      "Epoch 94/100\n",
      "6/6 - 1s - loss: 3.0962e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.9211 - val_auc: 0.9321 - 536ms/epoch - 89ms/step\n",
      "Epoch 95/100\n",
      "6/6 - 1s - loss: 2.0243e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.9211 - val_auc: 0.9321 - 533ms/epoch - 89ms/step\n",
      "Epoch 96/100\n",
      "6/6 - 1s - loss: 3.0584e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6875 - val_accuracy: 0.9211 - val_auc: 0.9321 - 537ms/epoch - 90ms/step\n",
      "Epoch 97/100\n",
      "6/6 - 1s - loss: 2.1949e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.9211 - val_auc: 0.9321 - 540ms/epoch - 90ms/step\n",
      "Epoch 98/100\n",
      "6/6 - 1s - loss: 2.1695e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6860 - val_accuracy: 0.9211 - val_auc: 0.9321 - 539ms/epoch - 90ms/step\n",
      "Epoch 99/100\n",
      "6/6 - 1s - loss: 1.8305e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.9211 - val_auc: 0.9321 - 518ms/epoch - 86ms/step\n",
      "Epoch 100/100\n",
      "6/6 - 1s - loss: 3.3015e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.9211 - val_auc: 0.9321 - 515ms/epoch - 86ms/step\n",
      "2/2 [==============================] - 2s 69ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "Roc 1.0\n",
      "Confusion Matrix\n",
      "[[ 6  0]\n",
      " [ 0 32]]\n",
      "minority class [1.]\n",
      "minority people 21\n",
      "y size 0\n",
      "other size 750\n",
      "['SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'SUMMO L', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'GIOVANNA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'ANGELA G', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Giovanni M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M', 'Nicola M']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/2551710120.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
      "/home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 2, 2\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 20s - loss: 0.5680 - accuracy: 0.7458 - auc: 0.8384 - val_loss: 0.4463 - val_accuracy: 0.8182 - val_auc: 0.9076 - 20s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "5/5 - 1s - loss: 0.3511 - accuracy: 0.8418 - auc: 0.9245 - val_loss: 0.4788 - val_accuracy: 0.8182 - val_auc: 0.9127 - 851ms/epoch - 170ms/step\n",
      "Epoch 3/100\n",
      "5/5 - 1s - loss: 0.2886 - accuracy: 0.8822 - auc: 0.9496 - val_loss: 0.1886 - val_accuracy: 0.8909 - val_auc: 0.9777 - 831ms/epoch - 166ms/step\n",
      "Epoch 4/100\n",
      "5/5 - 1s - loss: 0.2141 - accuracy: 0.9226 - auc: 0.9722 - val_loss: 0.3242 - val_accuracy: 0.8636 - val_auc: 0.9578 - 501ms/epoch - 100ms/step\n",
      "Epoch 5/100\n",
      "5/5 - 1s - loss: 0.1682 - accuracy: 0.9360 - auc: 0.9828 - val_loss: 0.1661 - val_accuracy: 0.9091 - val_auc: 0.9829 - 833ms/epoch - 167ms/step\n",
      "Epoch 6/100\n",
      "5/5 - 1s - loss: 0.1404 - accuracy: 0.9444 - auc: 0.9884 - val_loss: 0.2312 - val_accuracy: 0.8727 - val_auc: 0.9746 - 507ms/epoch - 101ms/step\n",
      "Epoch 7/100\n",
      "5/5 - 1s - loss: 0.1120 - accuracy: 0.9579 - auc: 0.9926 - val_loss: 0.1875 - val_accuracy: 0.9182 - val_auc: 0.9807 - 503ms/epoch - 101ms/step\n",
      "Epoch 8/100\n",
      "5/5 - 1s - loss: 0.0828 - accuracy: 0.9697 - auc: 0.9967 - val_loss: 0.2627 - val_accuracy: 0.9000 - val_auc: 0.9731 - 508ms/epoch - 102ms/step\n",
      "Epoch 9/100\n",
      "5/5 - 1s - loss: 0.0737 - accuracy: 0.9781 - auc: 0.9965 - val_loss: 0.2654 - val_accuracy: 0.9091 - val_auc: 0.9703 - 504ms/epoch - 101ms/step\n",
      "Epoch 10/100\n",
      "5/5 - 1s - loss: 0.0494 - accuracy: 0.9865 - auc: 0.9980 - val_loss: 0.4316 - val_accuracy: 0.9091 - val_auc: 0.9386 - 506ms/epoch - 101ms/step\n",
      "Epoch 11/100\n",
      "5/5 - 1s - loss: 0.0376 - accuracy: 0.9899 - auc: 0.9992 - val_loss: 0.5757 - val_accuracy: 0.9000 - val_auc: 0.9338 - 500ms/epoch - 100ms/step\n",
      "Epoch 12/100\n",
      "5/5 - 1s - loss: 0.0291 - accuracy: 0.9916 - auc: 0.9995 - val_loss: 0.3660 - val_accuracy: 0.9000 - val_auc: 0.9519 - 516ms/epoch - 103ms/step\n",
      "Epoch 13/100\n",
      "5/5 - 1s - loss: 0.0442 - accuracy: 0.9848 - auc: 0.9987 - val_loss: 0.8809 - val_accuracy: 0.8545 - val_auc: 0.9021 - 500ms/epoch - 100ms/step\n",
      "Epoch 14/100\n",
      "5/5 - 1s - loss: 0.0212 - accuracy: 0.9899 - auc: 0.9997 - val_loss: 0.6577 - val_accuracy: 0.8909 - val_auc: 0.9313 - 504ms/epoch - 101ms/step\n",
      "Epoch 15/100\n",
      "5/5 - 1s - loss: 0.0293 - accuracy: 0.9882 - auc: 0.9995 - val_loss: 1.0537 - val_accuracy: 0.8636 - val_auc: 0.8819 - 500ms/epoch - 100ms/step\n",
      "Epoch 16/100\n",
      "5/5 - 1s - loss: 0.0158 - accuracy: 0.9916 - auc: 0.9999 - val_loss: 0.4675 - val_accuracy: 0.9091 - val_auc: 0.9402 - 502ms/epoch - 100ms/step\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.0095 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9000 - val_auc: 0.9494 - 496ms/epoch - 99ms/step\n",
      "Epoch 18/100\n",
      "5/5 - 1s - loss: 0.0050 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8818 - val_auc: 0.9123 - 507ms/epoch - 101ms/step\n",
      "Epoch 19/100\n",
      "5/5 - 1s - loss: 0.0085 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.8818 - val_auc: 0.9269 - 501ms/epoch - 100ms/step\n",
      "Epoch 20/100\n",
      "5/5 - 1s - loss: 0.0044 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9091 - val_auc: 0.9595 - 502ms/epoch - 100ms/step\n",
      "Epoch 21/100\n",
      "5/5 - 1s - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.8818 - val_auc: 0.9231 - 504ms/epoch - 101ms/step\n",
      "Epoch 22/100\n",
      "5/5 - 1s - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.0771 - val_accuracy: 0.8636 - val_auc: 0.8802 - 502ms/epoch - 100ms/step\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.0061 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9364 - val_auc: 0.9476 - 494ms/epoch - 99ms/step\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.0099 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9182 - val_auc: 0.9538 - 499ms/epoch - 100ms/step\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.0038 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.7354 - val_accuracy: 0.8455 - val_auc: 0.9243 - 499ms/epoch - 100ms/step\n",
      "Epoch 26/100\n",
      "5/5 - 1s - loss: 0.0044 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9091 - val_auc: 0.9494 - 506ms/epoch - 101ms/step\n",
      "Epoch 27/100\n",
      "5/5 - 1s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9545 - val_auc: 0.9769 - 500ms/epoch - 100ms/step\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.0069 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.9000 - val_auc: 0.9412 - 500ms/epoch - 100ms/step\n",
      "Epoch 29/100\n",
      "5/5 - 1s - loss: 0.0127 - accuracy: 0.9966 - auc: 0.9999 - val_loss: 0.8506 - val_accuracy: 0.8636 - val_auc: 0.9038 - 501ms/epoch - 100ms/step\n",
      "Epoch 30/100\n",
      "5/5 - 1s - loss: 0.0153 - accuracy: 0.9933 - auc: 0.9999 - val_loss: 0.5181 - val_accuracy: 0.9000 - val_auc: 0.9432 - 501ms/epoch - 100ms/step\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 8.4798e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.7964 - val_accuracy: 0.8727 - val_auc: 0.9141 - 499ms/epoch - 100ms/step\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.0229 - accuracy: 0.9933 - auc: 0.9982 - val_loss: 0.4243 - val_accuracy: 0.9182 - val_auc: 0.9620 - 497ms/epoch - 99ms/step\n",
      "Epoch 33/100\n",
      "5/5 - 1s - loss: 0.0236 - accuracy: 0.9916 - auc: 0.9982 - val_loss: 0.4265 - val_accuracy: 0.9455 - val_auc: 0.9504 - 501ms/epoch - 100ms/step\n",
      "Epoch 34/100\n",
      "5/5 - 1s - loss: 0.0125 - accuracy: 0.9933 - auc: 0.9999 - val_loss: 0.4312 - val_accuracy: 0.9455 - val_auc: 0.9576 - 502ms/epoch - 100ms/step\n",
      "Epoch 35/100\n",
      "5/5 - 1s - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9364 - val_auc: 0.9746 - 507ms/epoch - 101ms/step\n",
      "Epoch 36/100\n",
      "5/5 - 1s - loss: 0.0163 - accuracy: 0.9966 - auc: 0.9982 - val_loss: 0.7485 - val_accuracy: 0.8727 - val_auc: 0.9180 - 500ms/epoch - 100ms/step\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.0045 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8909 - val_auc: 0.9213 - 498ms/epoch - 100ms/step\n",
      "Epoch 38/100\n",
      "5/5 - 1s - loss: 0.0033 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.9091 - val_auc: 0.9447 - 501ms/epoch - 100ms/step\n",
      "Epoch 39/100\n",
      "5/5 - 1s - loss: 0.0053 - accuracy: 0.9966 - auc: 1.0000 - val_loss: 0.6177 - val_accuracy: 0.8909 - val_auc: 0.9333 - 505ms/epoch - 101ms/step\n",
      "Epoch 40/100\n",
      "5/5 - 1s - loss: 0.0121 - accuracy: 0.9966 - auc: 0.9999 - val_loss: 0.6411 - val_accuracy: 0.9000 - val_auc: 0.9271 - 502ms/epoch - 100ms/step\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 7.4200e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.9091 - val_auc: 0.9429 - 499ms/epoch - 100ms/step\n",
      "Epoch 42/100\n",
      "5/5 - 1s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9000 - val_auc: 0.9530 - 504ms/epoch - 101ms/step\n",
      "Epoch 43/100\n",
      "5/5 - 1s - loss: 0.0062 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.3303 - val_accuracy: 0.9545 - val_auc: 0.9604 - 502ms/epoch - 100ms/step\n",
      "Epoch 44/100\n",
      "5/5 - 1s - loss: 0.0168 - accuracy: 0.9983 - auc: 0.9983 - val_loss: 0.3005 - val_accuracy: 0.9545 - val_auc: 0.9692 - 500ms/epoch - 100ms/step\n",
      "Epoch 45/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9455 - val_auc: 0.9496 - 500ms/epoch - 100ms/step\n",
      "Epoch 46/100\n",
      "5/5 - 1s - loss: 5.2493e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9182 - val_auc: 0.9472 - 505ms/epoch - 101ms/step\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9273 - val_auc: 0.9472 - 498ms/epoch - 100ms/step\n",
      "Epoch 48/100\n",
      "5/5 - 1s - loss: 5.5850e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9364 - val_auc: 0.9562 - 504ms/epoch - 101ms/step\n",
      "Epoch 49/100\n",
      "5/5 - 0s - loss: 1.7726e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3252 - val_accuracy: 0.9455 - val_auc: 0.9648 - 500ms/epoch - 100ms/step\n",
      "Epoch 50/100\n",
      "5/5 - 1s - loss: 8.7817e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9455 - val_auc: 0.9750 - 504ms/epoch - 101ms/step\n",
      "Epoch 51/100\n",
      "5/5 - 1s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2661 - val_accuracy: 0.9455 - val_auc: 0.9750 - 510ms/epoch - 102ms/step\n",
      "Epoch 52/100\n",
      "5/5 - 0s - loss: 1.3900e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9364 - val_auc: 0.9750 - 498ms/epoch - 100ms/step\n",
      "Epoch 53/100\n",
      "5/5 - 0s - loss: 1.5414e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9455 - val_auc: 0.9673 - 494ms/epoch - 99ms/step\n",
      "Epoch 54/100\n",
      "5/5 - 1s - loss: 1.2151e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9455 - val_auc: 0.9669 - 508ms/epoch - 102ms/step\n",
      "Epoch 55/100\n",
      "5/5 - 0s - loss: 1.9341e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2917 - val_accuracy: 0.9364 - val_auc: 0.9669 - 497ms/epoch - 99ms/step\n",
      "Epoch 56/100\n",
      "5/5 - 0s - loss: 1.1438e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9364 - val_auc: 0.9669 - 500ms/epoch - 100ms/step\n",
      "Epoch 57/100\n",
      "5/5 - 1s - loss: 1.7455e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2961 - val_accuracy: 0.9364 - val_auc: 0.9669 - 501ms/epoch - 100ms/step\n",
      "Epoch 58/100\n",
      "5/5 - 1s - loss: 1.0072e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9364 - val_auc: 0.9669 - 504ms/epoch - 101ms/step\n",
      "Epoch 59/100\n",
      "5/5 - 1s - loss: 1.5169e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9364 - val_auc: 0.9667 - 503ms/epoch - 101ms/step\n",
      "Epoch 60/100\n",
      "5/5 - 1s - loss: 9.4876e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9364 - val_auc: 0.9665 - 503ms/epoch - 101ms/step\n",
      "Epoch 61/100\n",
      "5/5 - 1s - loss: 1.4183e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3027 - val_accuracy: 0.9455 - val_auc: 0.9667 - 501ms/epoch - 100ms/step\n",
      "Epoch 62/100\n",
      "5/5 - 1s - loss: 9.1325e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9455 - val_auc: 0.9670 - 509ms/epoch - 102ms/step\n",
      "Epoch 63/100\n",
      "5/5 - 1s - loss: 8.8832e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2991 - val_accuracy: 0.9455 - val_auc: 0.9669 - 503ms/epoch - 101ms/step\n",
      "Epoch 64/100\n",
      "5/5 - 1s - loss: 8.9786e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9455 - val_auc: 0.9670 - 504ms/epoch - 101ms/step\n",
      "Epoch 65/100\n",
      "5/5 - 1s - loss: 7.5516e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2998 - val_accuracy: 0.9455 - val_auc: 0.9671 - 505ms/epoch - 101ms/step\n",
      "Epoch 66/100\n",
      "5/5 - 0s - loss: 6.8971e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9455 - val_auc: 0.9672 - 495ms/epoch - 99ms/step\n",
      "Epoch 67/100\n",
      "5/5 - 1s - loss: 1.1170e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9455 - val_auc: 0.9671 - 505ms/epoch - 101ms/step\n",
      "Epoch 68/100\n",
      "5/5 - 0s - loss: 5.1544e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9455 - val_auc: 0.9671 - 499ms/epoch - 100ms/step\n",
      "Epoch 69/100\n",
      "5/5 - 1s - loss: 6.9759e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3032 - val_accuracy: 0.9364 - val_auc: 0.9670 - 517ms/epoch - 103ms/step\n",
      "Epoch 70/100\n",
      "5/5 - 1s - loss: 1.1186e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9455 - val_auc: 0.9669 - 508ms/epoch - 102ms/step\n",
      "Epoch 71/100\n",
      "5/5 - 1s - loss: 4.3587e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3149 - val_accuracy: 0.9455 - val_auc: 0.9667 - 506ms/epoch - 101ms/step\n",
      "Epoch 72/100\n",
      "5/5 - 1s - loss: 4.2944e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9364 - val_auc: 0.9664 - 503ms/epoch - 101ms/step\n",
      "Epoch 73/100\n",
      "5/5 - 0s - loss: 5.6255e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9364 - val_auc: 0.9664 - 499ms/epoch - 100ms/step\n",
      "Epoch 74/100\n",
      "5/5 - 1s - loss: 3.9237e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9364 - val_auc: 0.9664 - 513ms/epoch - 103ms/step\n",
      "Epoch 75/100\n",
      "5/5 - 1s - loss: 6.6742e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9364 - val_auc: 0.9664 - 501ms/epoch - 100ms/step\n",
      "Epoch 76/100\n",
      "5/5 - 1s - loss: 3.9638e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9364 - val_auc: 0.9664 - 500ms/epoch - 100ms/step\n",
      "Epoch 77/100\n",
      "5/5 - 1s - loss: 4.6120e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9364 - val_auc: 0.9664 - 511ms/epoch - 102ms/step\n",
      "Epoch 78/100\n",
      "5/5 - 1s - loss: 7.3770e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9364 - val_auc: 0.9664 - 504ms/epoch - 101ms/step\n",
      "Epoch 79/100\n",
      "5/5 - 1s - loss: 4.6561e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.9364 - val_auc: 0.9664 - 501ms/epoch - 100ms/step\n",
      "Epoch 80/100\n",
      "5/5 - 0s - loss: 4.5179e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9273 - val_auc: 0.9664 - 499ms/epoch - 100ms/step\n",
      "Epoch 81/100\n",
      "5/5 - 0s - loss: 7.5680e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9273 - val_auc: 0.9664 - 496ms/epoch - 99ms/step\n",
      "Epoch 82/100\n",
      "5/5 - 1s - loss: 4.4553e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9273 - val_auc: 0.9665 - 502ms/epoch - 100ms/step\n",
      "Epoch 83/100\n",
      "5/5 - 0s - loss: 4.7674e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9273 - val_auc: 0.9664 - 498ms/epoch - 100ms/step\n",
      "Epoch 84/100\n",
      "5/5 - 1s - loss: 4.6164e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9273 - val_auc: 0.9666 - 503ms/epoch - 101ms/step\n",
      "Epoch 85/100\n",
      "5/5 - 1s - loss: 3.9924e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9273 - val_auc: 0.9666 - 500ms/epoch - 100ms/step\n",
      "Epoch 86/100\n",
      "5/5 - 1s - loss: 5.4851e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9273 - val_auc: 0.9666 - 503ms/epoch - 101ms/step\n",
      "Epoch 87/100\n",
      "5/5 - 1s - loss: 3.8575e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9273 - val_auc: 0.9667 - 501ms/epoch - 100ms/step\n",
      "Epoch 88/100\n",
      "5/5 - 1s - loss: 3.7977e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9273 - val_auc: 0.9669 - 502ms/epoch - 100ms/step\n",
      "Epoch 89/100\n",
      "5/5 - 1s - loss: 4.3338e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9273 - val_auc: 0.9669 - 502ms/epoch - 100ms/step\n",
      "Epoch 90/100\n",
      "5/5 - 1s - loss: 3.0500e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9273 - val_auc: 0.9669 - 502ms/epoch - 100ms/step\n",
      "Epoch 91/100\n",
      "5/5 - 1s - loss: 3.2033e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9273 - val_auc: 0.9669 - 500ms/epoch - 100ms/step\n",
      "Epoch 92/100\n",
      "5/5 - 1s - loss: 3.3057e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9273 - val_auc: 0.9669 - 504ms/epoch - 101ms/step\n",
      "Epoch 93/100\n",
      "5/5 - 1s - loss: 4.8677e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.9364 - val_auc: 0.9669 - 501ms/epoch - 100ms/step\n",
      "Epoch 94/100\n",
      "5/5 - 1s - loss: 3.1506e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9364 - val_auc: 0.9669 - 501ms/epoch - 100ms/step\n",
      "Epoch 95/100\n",
      "5/5 - 1s - loss: 2.9039e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.9364 - val_auc: 0.9669 - 505ms/epoch - 101ms/step\n",
      "Epoch 96/100\n",
      "5/5 - 1s - loss: 2.7630e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9364 - val_auc: 0.9669 - 507ms/epoch - 101ms/step\n",
      "Epoch 97/100\n",
      "5/5 - 1s - loss: 4.1568e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3276 - val_accuracy: 0.9364 - val_auc: 0.9669 - 501ms/epoch - 100ms/step\n",
      "Epoch 98/100\n",
      "5/5 - 0s - loss: 2.6145e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9364 - val_auc: 0.9669 - 497ms/epoch - 99ms/step\n",
      "Epoch 99/100\n",
      "5/5 - 0s - loss: 2.6224e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9364 - val_auc: 0.9669 - 468ms/epoch - 94ms/step\n",
      "Epoch 100/100\n",
      "5/5 - 0s - loss: 3.5477e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3281 - val_accuracy: 0.9364 - val_auc: 0.9669 - 478ms/epoch - 96ms/step\n",
      "4/4 [==============================] - 2s 46ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        48\n",
      "           1       0.95      0.89      0.92        62\n",
      "\n",
      "    accuracy                           0.91       110\n",
      "   macro avg       0.91      0.91      0.91       110\n",
      "weighted avg       0.91      0.91      0.91       110\n",
      "\n",
      "Roc 0.9838709677419356\n",
      "Confusion Matrix\n",
      "[[45  3]\n",
      " [ 7 55]]\n",
      "minority class [1.]\n",
      "minority people 20\n",
      "y size 0\n",
      "other size 746\n",
      "['VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'VITO L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Leonarda L', 'Giuseppe M', 'Giuseppe M', 'Giuseppe M', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Antonia G', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'Michele C', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/2551710120.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
      "/home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 2, 2\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 21s - loss: 0.7816 - accuracy: 0.6750 - auc: 0.7577 - val_loss: 0.1903 - val_accuracy: 0.9398 - val_auc: 0.9817 - 21s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "5/5 - 0s - loss: 0.3383 - accuracy: 0.8589 - auc: 0.9324 - val_loss: 0.3069 - val_accuracy: 0.8554 - val_auc: 0.9430 - 478ms/epoch - 96ms/step\n",
      "Epoch 3/100\n",
      "5/5 - 0s - loss: 0.2708 - accuracy: 0.8964 - auc: 0.9554 - val_loss: 0.2083 - val_accuracy: 0.9036 - val_auc: 0.9740 - 472ms/epoch - 94ms/step\n",
      "Epoch 4/100\n",
      "5/5 - 0s - loss: 0.2186 - accuracy: 0.9143 - auc: 0.9710 - val_loss: 0.1782 - val_accuracy: 0.9398 - val_auc: 0.9807 - 476ms/epoch - 95ms/step\n",
      "Epoch 5/100\n",
      "5/5 - 1s - loss: 0.1716 - accuracy: 0.9268 - auc: 0.9825 - val_loss: 0.1766 - val_accuracy: 0.9398 - val_auc: 0.9821 - 800ms/epoch - 160ms/step\n",
      "Epoch 6/100\n",
      "5/5 - 0s - loss: 0.1218 - accuracy: 0.9536 - auc: 0.9907 - val_loss: 0.2659 - val_accuracy: 0.8916 - val_auc: 0.9753 - 485ms/epoch - 97ms/step\n",
      "Epoch 7/100\n",
      "5/5 - 0s - loss: 0.1118 - accuracy: 0.9536 - auc: 0.9926 - val_loss: 0.2925 - val_accuracy: 0.9157 - val_auc: 0.9641 - 477ms/epoch - 95ms/step\n",
      "Epoch 8/100\n",
      "5/5 - 0s - loss: 0.1030 - accuracy: 0.9661 - auc: 0.9933 - val_loss: 0.2198 - val_accuracy: 0.9157 - val_auc: 0.9791 - 482ms/epoch - 96ms/step\n",
      "Epoch 9/100\n",
      "5/5 - 1s - loss: 0.0844 - accuracy: 0.9696 - auc: 0.9954 - val_loss: 0.1526 - val_accuracy: 0.9157 - val_auc: 0.9893 - 795ms/epoch - 159ms/step\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.0664 - accuracy: 0.9786 - auc: 0.9974 - val_loss: 0.1433 - val_accuracy: 0.9398 - val_auc: 0.9885 - 476ms/epoch - 95ms/step\n",
      "Epoch 11/100\n",
      "5/5 - 0s - loss: 0.0672 - accuracy: 0.9714 - auc: 0.9975 - val_loss: 0.2554 - val_accuracy: 0.9036 - val_auc: 0.9673 - 474ms/epoch - 95ms/step\n",
      "Epoch 12/100\n",
      "5/5 - 0s - loss: 0.0728 - accuracy: 0.9750 - auc: 0.9962 - val_loss: 0.1650 - val_accuracy: 0.9277 - val_auc: 0.9875 - 477ms/epoch - 95ms/step\n",
      "Epoch 13/100\n",
      "5/5 - 0s - loss: 0.0233 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.2218 - val_accuracy: 0.9277 - val_auc: 0.9824 - 477ms/epoch - 95ms/step\n",
      "Epoch 14/100\n",
      "5/5 - 1s - loss: 0.0282 - accuracy: 0.9875 - auc: 0.9997 - val_loss: 0.1975 - val_accuracy: 0.9277 - val_auc: 0.9897 - 792ms/epoch - 158ms/step\n",
      "Epoch 15/100\n",
      "5/5 - 0s - loss: 0.0147 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3066 - val_accuracy: 0.9157 - val_auc: 0.9752 - 478ms/epoch - 96ms/step\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.0183 - accuracy: 0.9929 - auc: 0.9998 - val_loss: 0.2896 - val_accuracy: 0.9277 - val_auc: 0.9760 - 475ms/epoch - 95ms/step\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.0107 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.1956 - val_accuracy: 0.9398 - val_auc: 0.9807 - 475ms/epoch - 95ms/step\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.0119 - accuracy: 0.9929 - auc: 0.9999 - val_loss: 0.3132 - val_accuracy: 0.9518 - val_auc: 0.9569 - 481ms/epoch - 96ms/step\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9036 - val_auc: 0.9553 - 478ms/epoch - 96ms/step\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.0057 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9277 - val_auc: 0.9563 - 481ms/epoch - 96ms/step\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.0050 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9157 - val_auc: 0.9550 - 477ms/epoch - 95ms/step\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.0036 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9398 - val_auc: 0.9676 - 477ms/epoch - 95ms/step\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9398 - val_auc: 0.9441 - 474ms/epoch - 95ms/step\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.0137 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.3145 - val_accuracy: 0.9277 - val_auc: 0.9666 - 479ms/epoch - 96ms/step\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.0028 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8916 - val_auc: 0.9633 - 475ms/epoch - 95ms/step\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.0042 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3262 - val_accuracy: 0.9157 - val_auc: 0.9759 - 474ms/epoch - 95ms/step\n",
      "Epoch 27/100\n",
      "5/5 - 0s - loss: 0.0020 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.2477 - val_accuracy: 0.9277 - val_auc: 0.9791 - 476ms/epoch - 95ms/step\n",
      "Epoch 28/100\n",
      "5/5 - 1s - loss: 5.4351e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9398 - val_auc: 0.9917 - 811ms/epoch - 162ms/step\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2588 - val_accuracy: 0.9398 - val_auc: 0.9738 - 477ms/epoch - 95ms/step\n",
      "Epoch 30/100\n",
      "5/5 - 0s - loss: 0.0089 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9398 - val_auc: 0.9576 - 471ms/epoch - 94ms/step\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 0.0196 - accuracy: 0.9929 - auc: 0.9998 - val_loss: 0.3105 - val_accuracy: 0.9518 - val_auc: 0.9598 - 471ms/epoch - 94ms/step\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.0141 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.3779 - val_accuracy: 0.9398 - val_auc: 0.9592 - 475ms/epoch - 95ms/step\n",
      "Epoch 33/100\n",
      "5/5 - 0s - loss: 7.6789e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9157 - val_auc: 0.9668 - 478ms/epoch - 96ms/step\n",
      "Epoch 34/100\n",
      "5/5 - 0s - loss: 0.0024 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9157 - val_auc: 0.9572 - 478ms/epoch - 96ms/step\n",
      "Epoch 35/100\n",
      "5/5 - 0s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9277 - val_auc: 0.9580 - 485ms/epoch - 97ms/step\n",
      "Epoch 36/100\n",
      "5/5 - 0s - loss: 0.0087 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9157 - val_auc: 0.9564 - 478ms/epoch - 96ms/step\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.0039 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9277 - val_auc: 0.9566 - 488ms/epoch - 98ms/step\n",
      "Epoch 38/100\n",
      "5/5 - 0s - loss: 0.0048 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9277 - val_auc: 0.9684 - 476ms/epoch - 95ms/step\n",
      "Epoch 39/100\n",
      "5/5 - 0s - loss: 0.1127 - accuracy: 0.9536 - auc: 0.9910 - val_loss: 0.5698 - val_accuracy: 0.8193 - val_auc: 0.9144 - 475ms/epoch - 95ms/step\n",
      "Epoch 40/100\n",
      "5/5 - 0s - loss: 0.1178 - accuracy: 0.9607 - auc: 0.9915 - val_loss: 0.4402 - val_accuracy: 0.8916 - val_auc: 0.9444 - 486ms/epoch - 97ms/step\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 0.0583 - accuracy: 0.9804 - auc: 0.9966 - val_loss: 0.2354 - val_accuracy: 0.9157 - val_auc: 0.9676 - 481ms/epoch - 96ms/step\n",
      "Epoch 42/100\n",
      "5/5 - 0s - loss: 0.0275 - accuracy: 0.9893 - auc: 0.9997 - val_loss: 0.2031 - val_accuracy: 0.9157 - val_auc: 0.9750 - 483ms/epoch - 97ms/step\n",
      "Epoch 43/100\n",
      "5/5 - 0s - loss: 0.0338 - accuracy: 0.9875 - auc: 0.9994 - val_loss: 0.2771 - val_accuracy: 0.9157 - val_auc: 0.9689 - 475ms/epoch - 95ms/step\n",
      "Epoch 44/100\n",
      "5/5 - 0s - loss: 0.0280 - accuracy: 0.9929 - auc: 0.9980 - val_loss: 0.4338 - val_accuracy: 0.9036 - val_auc: 0.9496 - 480ms/epoch - 96ms/step\n",
      "Epoch 45/100\n",
      "5/5 - 0s - loss: 0.0069 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.3115 - val_accuracy: 0.9277 - val_auc: 0.9660 - 476ms/epoch - 95ms/step\n",
      "Epoch 46/100\n",
      "5/5 - 0s - loss: 0.0044 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.9277 - val_auc: 0.9778 - 479ms/epoch - 96ms/step\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2104 - val_accuracy: 0.9277 - val_auc: 0.9795 - 473ms/epoch - 95ms/step\n",
      "Epoch 48/100\n",
      "5/5 - 0s - loss: 4.3110e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9157 - val_auc: 0.9880 - 482ms/epoch - 96ms/step\n",
      "Epoch 49/100\n",
      "5/5 - 0s - loss: 0.0091 - accuracy: 0.9982 - auc: 0.9999 - val_loss: 0.2932 - val_accuracy: 0.9036 - val_auc: 0.9859 - 474ms/epoch - 95ms/step\n",
      "Epoch 50/100\n",
      "5/5 - 0s - loss: 6.4822e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9036 - val_auc: 0.9697 - 480ms/epoch - 96ms/step\n",
      "Epoch 51/100\n",
      "5/5 - 0s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.9036 - val_auc: 0.9704 - 477ms/epoch - 95ms/step\n",
      "Epoch 52/100\n",
      "5/5 - 0s - loss: 5.2843e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9036 - val_auc: 0.9835 - 483ms/epoch - 97ms/step\n",
      "Epoch 53/100\n",
      "5/5 - 0s - loss: 9.9079e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2610 - val_accuracy: 0.8916 - val_auc: 0.9845 - 474ms/epoch - 95ms/step\n",
      "Epoch 54/100\n",
      "5/5 - 0s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2666 - val_accuracy: 0.8916 - val_auc: 0.9845 - 480ms/epoch - 96ms/step\n",
      "Epoch 55/100\n",
      "5/5 - 0s - loss: 4.3693e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9036 - val_auc: 0.9845 - 472ms/epoch - 94ms/step\n",
      "Epoch 56/100\n",
      "5/5 - 0s - loss: 4.0532e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2966 - val_accuracy: 0.9157 - val_auc: 0.9745 - 482ms/epoch - 96ms/step\n",
      "Epoch 57/100\n",
      "5/5 - 0s - loss: 4.5335e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9157 - val_auc: 0.9751 - 475ms/epoch - 95ms/step\n",
      "Epoch 58/100\n",
      "5/5 - 0s - loss: 3.9385e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3179 - val_accuracy: 0.9036 - val_auc: 0.9745 - 485ms/epoch - 97ms/step\n",
      "Epoch 59/100\n",
      "5/5 - 0s - loss: 2.2705e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3245 - val_accuracy: 0.9036 - val_auc: 0.9747 - 478ms/epoch - 96ms/step\n",
      "Epoch 60/100\n",
      "5/5 - 0s - loss: 2.2366e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9036 - val_auc: 0.9742 - 482ms/epoch - 96ms/step\n",
      "Epoch 61/100\n",
      "5/5 - 0s - loss: 1.8595e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9036 - val_auc: 0.9740 - 484ms/epoch - 97ms/step\n",
      "Epoch 62/100\n",
      "5/5 - 0s - loss: 1.8399e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9036 - val_auc: 0.9747 - 478ms/epoch - 96ms/step\n",
      "Epoch 63/100\n",
      "5/5 - 0s - loss: 1.1742e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9036 - val_auc: 0.9747 - 480ms/epoch - 96ms/step\n",
      "Epoch 64/100\n",
      "5/5 - 0s - loss: 1.4847e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9036 - val_auc: 0.9753 - 483ms/epoch - 97ms/step\n",
      "Epoch 65/100\n",
      "5/5 - 0s - loss: 1.4106e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9036 - val_auc: 0.9750 - 480ms/epoch - 96ms/step\n",
      "Epoch 66/100\n",
      "5/5 - 0s - loss: 1.5310e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9036 - val_auc: 0.9747 - 474ms/epoch - 95ms/step\n",
      "Epoch 67/100\n",
      "5/5 - 0s - loss: 1.2318e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9036 - val_auc: 0.9750 - 480ms/epoch - 96ms/step\n",
      "Epoch 68/100\n",
      "5/5 - 0s - loss: 1.1095e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9036 - val_auc: 0.9750 - 482ms/epoch - 96ms/step\n",
      "Epoch 69/100\n",
      "5/5 - 0s - loss: 4.3071e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9036 - val_auc: 0.9643 - 476ms/epoch - 95ms/step\n",
      "Epoch 70/100\n",
      "5/5 - 0s - loss: 9.0402e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9036 - val_auc: 0.9637 - 478ms/epoch - 96ms/step\n",
      "Epoch 71/100\n",
      "5/5 - 0s - loss: 1.2456e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9036 - val_auc: 0.9634 - 477ms/epoch - 95ms/step\n",
      "Epoch 72/100\n",
      "5/5 - 0s - loss: 1.2758e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9036 - val_auc: 0.9633 - 477ms/epoch - 95ms/step\n",
      "Epoch 73/100\n",
      "5/5 - 0s - loss: 9.5284e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9036 - val_auc: 0.9630 - 475ms/epoch - 95ms/step\n",
      "Epoch 74/100\n",
      "5/5 - 0s - loss: 1.6102e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9036 - val_auc: 0.9630 - 488ms/epoch - 98ms/step\n",
      "Epoch 75/100\n",
      "5/5 - 0s - loss: 9.6328e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9036 - val_auc: 0.9630 - 478ms/epoch - 96ms/step\n",
      "Epoch 76/100\n",
      "5/5 - 0s - loss: 1.1537e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9036 - val_auc: 0.9634 - 476ms/epoch - 95ms/step\n",
      "Epoch 77/100\n",
      "5/5 - 0s - loss: 8.4988e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9036 - val_auc: 0.9640 - 479ms/epoch - 96ms/step\n",
      "Epoch 78/100\n",
      "5/5 - 0s - loss: 7.2890e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9036 - val_auc: 0.9640 - 475ms/epoch - 95ms/step\n",
      "Epoch 79/100\n",
      "5/5 - 0s - loss: 1.1759e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9036 - val_auc: 0.9640 - 483ms/epoch - 97ms/step\n",
      "Epoch 80/100\n",
      "5/5 - 0s - loss: 2.4051e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9036 - val_auc: 0.9643 - 474ms/epoch - 95ms/step\n",
      "Epoch 81/100\n",
      "5/5 - 0s - loss: 8.0139e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9036 - val_auc: 0.9643 - 486ms/epoch - 97ms/step\n",
      "Epoch 82/100\n",
      "5/5 - 0s - loss: 8.5863e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9036 - val_auc: 0.9646 - 479ms/epoch - 96ms/step\n",
      "Epoch 83/100\n",
      "5/5 - 0s - loss: 5.8680e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9036 - val_auc: 0.9646 - 478ms/epoch - 96ms/step\n",
      "Epoch 84/100\n",
      "5/5 - 0s - loss: 6.2646e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9036 - val_auc: 0.9646 - 477ms/epoch - 95ms/step\n",
      "Epoch 85/100\n",
      "5/5 - 0s - loss: 9.0054e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9036 - val_auc: 0.9646 - 476ms/epoch - 95ms/step\n",
      "Epoch 86/100\n",
      "5/5 - 0s - loss: 6.8719e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9036 - val_auc: 0.9646 - 479ms/epoch - 96ms/step\n",
      "Epoch 87/100\n",
      "5/5 - 0s - loss: 6.9943e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.9036 - val_auc: 0.9647 - 480ms/epoch - 96ms/step\n",
      "Epoch 88/100\n",
      "5/5 - 0s - loss: 5.9194e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9036 - val_auc: 0.9646 - 487ms/epoch - 97ms/step\n",
      "Epoch 89/100\n",
      "5/5 - 0s - loss: 6.1480e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9036 - val_auc: 0.9647 - 479ms/epoch - 96ms/step\n",
      "Epoch 90/100\n",
      "5/5 - 0s - loss: 7.8739e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9036 - val_auc: 0.9646 - 481ms/epoch - 96ms/step\n",
      "Epoch 91/100\n",
      "5/5 - 0s - loss: 1.0237e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9036 - val_auc: 0.9644 - 477ms/epoch - 95ms/step\n",
      "Epoch 92/100\n",
      "5/5 - 0s - loss: 7.6260e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9036 - val_auc: 0.9644 - 479ms/epoch - 96ms/step\n",
      "Epoch 93/100\n",
      "5/5 - 0s - loss: 7.0546e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9036 - val_auc: 0.9646 - 479ms/epoch - 96ms/step\n",
      "Epoch 94/100\n",
      "5/5 - 0s - loss: 6.3522e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9036 - val_auc: 0.9646 - 487ms/epoch - 97ms/step\n",
      "Epoch 95/100\n",
      "5/5 - 0s - loss: 5.0873e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9036 - val_auc: 0.9648 - 476ms/epoch - 95ms/step\n",
      "Epoch 96/100\n",
      "5/5 - 0s - loss: 4.1003e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9036 - val_auc: 0.9649 - 479ms/epoch - 96ms/step\n",
      "Epoch 97/100\n",
      "5/5 - 0s - loss: 5.4521e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9036 - val_auc: 0.9647 - 475ms/epoch - 95ms/step\n",
      "Epoch 98/100\n",
      "5/5 - 0s - loss: 5.4053e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9036 - val_auc: 0.9647 - 478ms/epoch - 96ms/step\n",
      "Epoch 99/100\n",
      "5/5 - 0s - loss: 7.4490e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9036 - val_auc: 0.9646 - 453ms/epoch - 91ms/step\n",
      "Epoch 100/100\n",
      "5/5 - 0s - loss: 6.3511e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9036 - val_auc: 0.9543 - 443ms/epoch - 89ms/step\n",
      "3/3 [==============================] - 2s 38ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        35\n",
      "           1       0.98      0.92      0.95        48\n",
      "\n",
      "    accuracy                           0.94        83\n",
      "   macro avg       0.94      0.94      0.94        83\n",
      "weighted avg       0.94      0.94      0.94        83\n",
      "\n",
      "Roc 0.9928571428571429\n",
      "Confusion Matrix\n",
      "[[34  1]\n",
      " [ 4 44]]\n",
      "minority class [1.]\n",
      "minority people 22\n",
      "y size 0\n",
      "other size 778\n",
      "['VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'Arianna P', 'Arianna P', 'Arianna P', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L', 'Giulia L']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/2551710120.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
      "/home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 2, 2\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 23s - loss: 0.6556 - accuracy: 0.7089 - auc: 0.8272 - val_loss: 0.4612 - val_accuracy: 0.8209 - val_auc: 0.8842 - 23s/epoch - 5s/step\n",
      "Epoch 2/100\n",
      "5/5 - 0s - loss: 0.3881 - accuracy: 0.8289 - auc: 0.9193 - val_loss: 0.6841 - val_accuracy: 0.5522 - val_auc: 0.6706 - 483ms/epoch - 97ms/step\n",
      "Epoch 3/100\n",
      "5/5 - 1s - loss: 0.3158 - accuracy: 0.8520 - auc: 0.9385 - val_loss: 0.3240 - val_accuracy: 0.8358 - val_auc: 0.9405 - 837ms/epoch - 167ms/step\n",
      "Epoch 4/100\n",
      "5/5 - 0s - loss: 0.2189 - accuracy: 0.9046 - auc: 0.9713 - val_loss: 0.3569 - val_accuracy: 0.8209 - val_auc: 0.9208 - 496ms/epoch - 99ms/step\n",
      "Epoch 5/100\n",
      "5/5 - 1s - loss: 0.2020 - accuracy: 0.9145 - auc: 0.9754 - val_loss: 0.2854 - val_accuracy: 0.8507 - val_auc: 0.9586 - 831ms/epoch - 166ms/step\n",
      "Epoch 6/100\n",
      "5/5 - 1s - loss: 0.1675 - accuracy: 0.9457 - auc: 0.9817 - val_loss: 0.2314 - val_accuracy: 0.9104 - val_auc: 0.9688 - 814ms/epoch - 163ms/step\n",
      "Epoch 7/100\n",
      "5/5 - 1s - loss: 0.1321 - accuracy: 0.9457 - auc: 0.9896 - val_loss: 0.2302 - val_accuracy: 0.9254 - val_auc: 0.9701 - 841ms/epoch - 168ms/step\n",
      "Epoch 8/100\n",
      "5/5 - 1s - loss: 0.1140 - accuracy: 0.9523 - auc: 0.9924 - val_loss: 0.2023 - val_accuracy: 0.9403 - val_auc: 0.9772 - 808ms/epoch - 162ms/step\n",
      "Epoch 9/100\n",
      "5/5 - 0s - loss: 0.0875 - accuracy: 0.9704 - auc: 0.9955 - val_loss: 0.2021 - val_accuracy: 0.9254 - val_auc: 0.9764 - 495ms/epoch - 99ms/step\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.0826 - accuracy: 0.9720 - auc: 0.9956 - val_loss: 0.3250 - val_accuracy: 0.8806 - val_auc: 0.9519 - 495ms/epoch - 99ms/step\n",
      "Epoch 11/100\n",
      "5/5 - 0s - loss: 0.0919 - accuracy: 0.9490 - auc: 0.9946 - val_loss: 0.4246 - val_accuracy: 0.8955 - val_auc: 0.9282 - 496ms/epoch - 99ms/step\n",
      "Epoch 12/100\n",
      "5/5 - 0s - loss: 0.0811 - accuracy: 0.9655 - auc: 0.9960 - val_loss: 0.2761 - val_accuracy: 0.8657 - val_auc: 0.9577 - 489ms/epoch - 98ms/step\n",
      "Epoch 13/100\n",
      "5/5 - 0s - loss: 0.0369 - accuracy: 0.9852 - auc: 0.9993 - val_loss: 0.3433 - val_accuracy: 0.9104 - val_auc: 0.9546 - 490ms/epoch - 98ms/step\n",
      "Epoch 14/100\n",
      "5/5 - 0s - loss: 0.0236 - accuracy: 0.9918 - auc: 0.9998 - val_loss: 0.3645 - val_accuracy: 0.8507 - val_auc: 0.9557 - 492ms/epoch - 98ms/step\n",
      "Epoch 15/100\n",
      "5/5 - 1s - loss: 0.0342 - accuracy: 0.9852 - auc: 0.9994 - val_loss: 0.4185 - val_accuracy: 0.9104 - val_auc: 0.9412 - 501ms/epoch - 100ms/step\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.0112 - accuracy: 0.9951 - auc: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9104 - val_auc: 0.9619 - 492ms/epoch - 98ms/step\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.0057 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9104 - val_auc: 0.9576 - 490ms/epoch - 98ms/step\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.0072 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9254 - val_auc: 0.9648 - 494ms/epoch - 99ms/step\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.0046 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5781 - val_accuracy: 0.8955 - val_auc: 0.9033 - 498ms/epoch - 100ms/step\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.0092 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8806 - val_auc: 0.9469 - 496ms/epoch - 99ms/step\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.0105 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 0.6401 - val_accuracy: 0.8507 - val_auc: 0.9280 - 498ms/epoch - 100ms/step\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.0287 - accuracy: 0.9918 - auc: 0.9996 - val_loss: 0.4873 - val_accuracy: 0.8955 - val_auc: 0.9399 - 492ms/epoch - 98ms/step\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.0061 - accuracy: 0.9951 - auc: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.9104 - val_auc: 0.9125 - 493ms/epoch - 99ms/step\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.0150 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.3926 - val_accuracy: 0.9254 - val_auc: 0.9617 - 496ms/epoch - 99ms/step\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.0121 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.3696 - val_accuracy: 0.9254 - val_auc: 0.9592 - 494ms/epoch - 99ms/step\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.0053 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9104 - val_auc: 0.9424 - 493ms/epoch - 99ms/step\n",
      "Epoch 27/100\n",
      "5/5 - 1s - loss: 0.0114 - accuracy: 0.9984 - auc: 0.9983 - val_loss: 0.7100 - val_accuracy: 0.8806 - val_auc: 0.9067 - 507ms/epoch - 101ms/step\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.0062 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.5879 - val_accuracy: 0.9104 - val_auc: 0.9238 - 489ms/epoch - 98ms/step\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.0053 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9104 - val_auc: 0.9599 - 493ms/epoch - 99ms/step\n",
      "Epoch 30/100\n",
      "5/5 - 0s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9254 - val_auc: 0.9619 - 494ms/epoch - 99ms/step\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.9104 - val_auc: 0.9439 - 499ms/epoch - 100ms/step\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.0094 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.4126 - val_accuracy: 0.9403 - val_auc: 0.9635 - 496ms/epoch - 99ms/step\n",
      "Epoch 33/100\n",
      "5/5 - 1s - loss: 0.0242 - accuracy: 0.9918 - auc: 0.9998 - val_loss: 0.8706 - val_accuracy: 0.8955 - val_auc: 0.9120 - 504ms/epoch - 101ms/step\n",
      "Epoch 34/100\n",
      "5/5 - 0s - loss: 0.0438 - accuracy: 0.9885 - auc: 0.9962 - val_loss: 0.5991 - val_accuracy: 0.9104 - val_auc: 0.9430 - 497ms/epoch - 99ms/step\n",
      "Epoch 35/100\n",
      "5/5 - 0s - loss: 0.0835 - accuracy: 0.9803 - auc: 0.9921 - val_loss: 0.8403 - val_accuracy: 0.8507 - val_auc: 0.9022 - 499ms/epoch - 100ms/step\n",
      "Epoch 36/100\n",
      "5/5 - 0s - loss: 0.0860 - accuracy: 0.9770 - auc: 0.9918 - val_loss: 0.4958 - val_accuracy: 0.8806 - val_auc: 0.9361 - 492ms/epoch - 98ms/step\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.0366 - accuracy: 0.9852 - auc: 0.9993 - val_loss: 0.3313 - val_accuracy: 0.9254 - val_auc: 0.9646 - 499ms/epoch - 100ms/step\n",
      "Epoch 38/100\n",
      "5/5 - 0s - loss: 0.0172 - accuracy: 0.9967 - auc: 0.9998 - val_loss: 0.5708 - val_accuracy: 0.8657 - val_auc: 0.9200 - 493ms/epoch - 99ms/step\n",
      "Epoch 39/100\n",
      "5/5 - 1s - loss: 0.0068 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8657 - val_auc: 0.9406 - 503ms/epoch - 101ms/step\n",
      "Epoch 40/100\n",
      "5/5 - 1s - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9104 - val_auc: 0.9376 - 502ms/epoch - 100ms/step\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5571 - val_accuracy: 0.8955 - val_auc: 0.9286 - 500ms/epoch - 100ms/step\n",
      "Epoch 42/100\n",
      "5/5 - 0s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.8955 - val_auc: 0.9436 - 494ms/epoch - 99ms/step\n",
      "Epoch 43/100\n",
      "5/5 - 0s - loss: 9.7415e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.9104 - val_auc: 0.9258 - 496ms/epoch - 99ms/step\n",
      "Epoch 44/100\n",
      "5/5 - 0s - loss: 9.3653e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6006 - val_accuracy: 0.8955 - val_auc: 0.9247 - 491ms/epoch - 98ms/step\n",
      "Epoch 45/100\n",
      "5/5 - 1s - loss: 5.2989e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.8806 - val_auc: 0.9243 - 503ms/epoch - 101ms/step\n",
      "Epoch 46/100\n",
      "5/5 - 0s - loss: 3.7388e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6270 - val_accuracy: 0.8955 - val_auc: 0.9245 - 495ms/epoch - 99ms/step\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 0.0021 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.5723 - val_accuracy: 0.9104 - val_auc: 0.9385 - 497ms/epoch - 99ms/step\n",
      "Epoch 48/100\n",
      "5/5 - 0s - loss: 6.5648e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.9104 - val_auc: 0.9410 - 491ms/epoch - 98ms/step\n",
      "Epoch 49/100\n",
      "5/5 - 1s - loss: 0.0102 - accuracy: 0.9984 - auc: 0.9983 - val_loss: 0.5679 - val_accuracy: 0.8955 - val_auc: 0.9260 - 504ms/epoch - 101ms/step\n",
      "Epoch 50/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8806 - val_auc: 0.9254 - 496ms/epoch - 99ms/step\n",
      "Epoch 51/100\n",
      "5/5 - 0s - loss: 0.0060 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9403 - val_auc: 0.9608 - 500ms/epoch - 100ms/step\n",
      "Epoch 52/100\n",
      "5/5 - 0s - loss: 0.0031 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9254 - val_auc: 0.9615 - 492ms/epoch - 98ms/step\n",
      "Epoch 53/100\n",
      "5/5 - 0s - loss: 0.0041 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.9104 - val_auc: 0.9575 - 496ms/epoch - 99ms/step\n",
      "Epoch 54/100\n",
      "5/5 - 0s - loss: 0.0099 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 0.5435 - val_accuracy: 0.9104 - val_auc: 0.9603 - 491ms/epoch - 98ms/step\n",
      "Epoch 55/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9104 - val_auc: 0.9630 - 491ms/epoch - 98ms/step\n",
      "Epoch 56/100\n",
      "5/5 - 0s - loss: 6.8046e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9104 - val_auc: 0.9630 - 488ms/epoch - 98ms/step\n",
      "Epoch 57/100\n",
      "5/5 - 0s - loss: 4.8256e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9104 - val_auc: 0.9630 - 500ms/epoch - 100ms/step\n",
      "Epoch 58/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9104 - val_auc: 0.9599 - 492ms/epoch - 98ms/step\n",
      "Epoch 59/100\n",
      "5/5 - 0s - loss: 2.9004e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5728 - val_accuracy: 0.8806 - val_auc: 0.9554 - 498ms/epoch - 100ms/step\n",
      "Epoch 60/100\n",
      "5/5 - 0s - loss: 2.9032e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6699 - val_accuracy: 0.8806 - val_auc: 0.9514 - 493ms/epoch - 99ms/step\n",
      "Epoch 61/100\n",
      "5/5 - 0s - loss: 9.4735e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5786 - val_accuracy: 0.9104 - val_auc: 0.9454 - 493ms/epoch - 99ms/step\n",
      "Epoch 62/100\n",
      "5/5 - 0s - loss: 4.5829e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6807 - val_accuracy: 0.8806 - val_auc: 0.9432 - 498ms/epoch - 100ms/step\n",
      "Epoch 63/100\n",
      "5/5 - 0s - loss: 1.8932e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.8071 - val_accuracy: 0.8806 - val_auc: 0.9178 - 492ms/epoch - 98ms/step\n",
      "Epoch 64/100\n",
      "5/5 - 0s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.9104 - val_auc: 0.9445 - 491ms/epoch - 98ms/step\n",
      "Epoch 65/100\n",
      "5/5 - 1s - loss: 4.5801e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.9104 - val_auc: 0.9436 - 501ms/epoch - 100ms/step\n",
      "Epoch 66/100\n",
      "5/5 - 0s - loss: 2.4445e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.9104 - val_auc: 0.9432 - 492ms/epoch - 98ms/step\n",
      "Epoch 67/100\n",
      "5/5 - 0s - loss: 2.8802e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6924 - val_accuracy: 0.9104 - val_auc: 0.9438 - 497ms/epoch - 99ms/step\n",
      "Epoch 68/100\n",
      "5/5 - 0s - loss: 1.3851e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6724 - val_accuracy: 0.9104 - val_auc: 0.9439 - 491ms/epoch - 98ms/step\n",
      "Epoch 69/100\n",
      "5/5 - 0s - loss: 2.1393e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.9104 - val_auc: 0.9459 - 495ms/epoch - 99ms/step\n",
      "Epoch 70/100\n",
      "5/5 - 0s - loss: 1.8206e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.9104 - val_auc: 0.9479 - 498ms/epoch - 100ms/step\n",
      "Epoch 71/100\n",
      "5/5 - 0s - loss: 1.0921e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6104 - val_accuracy: 0.9104 - val_auc: 0.9481 - 496ms/epoch - 99ms/step\n",
      "Epoch 72/100\n",
      "5/5 - 0s - loss: 9.4216e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.9104 - val_auc: 0.9485 - 493ms/epoch - 99ms/step\n",
      "Epoch 73/100\n",
      "5/5 - 0s - loss: 7.6103e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.9104 - val_auc: 0.9483 - 493ms/epoch - 99ms/step\n",
      "Epoch 74/100\n",
      "5/5 - 0s - loss: 1.9169e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.9104 - val_auc: 0.9481 - 496ms/epoch - 99ms/step\n",
      "Epoch 75/100\n",
      "5/5 - 1s - loss: 1.2615e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5679 - val_accuracy: 0.9254 - val_auc: 0.9479 - 500ms/epoch - 100ms/step\n",
      "Epoch 76/100\n",
      "5/5 - 0s - loss: 2.3730e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.9254 - val_auc: 0.9485 - 492ms/epoch - 98ms/step\n",
      "Epoch 77/100\n",
      "5/5 - 0s - loss: 7.0719e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5767 - val_accuracy: 0.9104 - val_auc: 0.9485 - 494ms/epoch - 99ms/step\n",
      "Epoch 78/100\n",
      "5/5 - 1s - loss: 7.6736e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9104 - val_auc: 0.9488 - 511ms/epoch - 102ms/step\n",
      "Epoch 79/100\n",
      "5/5 - 1s - loss: 1.4319e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5898 - val_accuracy: 0.9104 - val_auc: 0.9474 - 503ms/epoch - 101ms/step\n",
      "Epoch 80/100\n",
      "5/5 - 0s - loss: 7.1485e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5957 - val_accuracy: 0.9104 - val_auc: 0.9470 - 496ms/epoch - 99ms/step\n",
      "Epoch 81/100\n",
      "5/5 - 1s - loss: 9.3269e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.9104 - val_auc: 0.9474 - 501ms/epoch - 100ms/step\n",
      "Epoch 82/100\n",
      "5/5 - 0s - loss: 6.2557e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6025 - val_accuracy: 0.9104 - val_auc: 0.9474 - 494ms/epoch - 99ms/step\n",
      "Epoch 83/100\n",
      "5/5 - 0s - loss: 5.8240e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.9104 - val_auc: 0.9474 - 500ms/epoch - 100ms/step\n",
      "Epoch 84/100\n",
      "5/5 - 0s - loss: 2.6898e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9104 - val_auc: 0.9468 - 499ms/epoch - 100ms/step\n",
      "Epoch 85/100\n",
      "5/5 - 0s - loss: 6.5201e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9104 - val_auc: 0.9603 - 496ms/epoch - 99ms/step\n",
      "Epoch 86/100\n",
      "5/5 - 0s - loss: 7.3089e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.9104 - val_auc: 0.9612 - 497ms/epoch - 99ms/step\n",
      "Epoch 87/100\n",
      "5/5 - 0s - loss: 1.7945e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9254 - val_auc: 0.9485 - 499ms/epoch - 100ms/step\n",
      "Epoch 88/100\n",
      "5/5 - 0s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9104 - val_auc: 0.9603 - 498ms/epoch - 100ms/step\n",
      "Epoch 89/100\n",
      "5/5 - 1s - loss: 0.0034 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9254 - val_auc: 0.9592 - 501ms/epoch - 100ms/step\n",
      "Epoch 90/100\n",
      "5/5 - 1s - loss: 0.0064 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.8955 - val_auc: 0.9588 - 501ms/epoch - 100ms/step\n",
      "Epoch 91/100\n",
      "5/5 - 1s - loss: 5.7223e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.8955 - val_auc: 0.9557 - 501ms/epoch - 100ms/step\n",
      "Epoch 92/100\n",
      "5/5 - 0s - loss: 3.5846e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.8955 - val_auc: 0.9436 - 500ms/epoch - 100ms/step\n",
      "Epoch 93/100\n",
      "5/5 - 1s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6758 - val_accuracy: 0.8955 - val_auc: 0.9430 - 509ms/epoch - 102ms/step\n",
      "Epoch 94/100\n",
      "5/5 - 0s - loss: 0.0065 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.8806 - val_auc: 0.9283 - 495ms/epoch - 99ms/step\n",
      "Epoch 95/100\n",
      "5/5 - 1s - loss: 6.2538e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.8806 - val_auc: 0.9091 - 501ms/epoch - 100ms/step\n",
      "Epoch 96/100\n",
      "5/5 - 0s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.9043 - val_accuracy: 0.8657 - val_auc: 0.9006 - 496ms/epoch - 99ms/step\n",
      "Epoch 97/100\n",
      "5/5 - 1s - loss: 0.0044 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.8359 - val_accuracy: 0.8507 - val_auc: 0.9093 - 504ms/epoch - 101ms/step\n",
      "Epoch 98/100\n",
      "5/5 - 0s - loss: 0.0051 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 1.1680 - val_accuracy: 0.8955 - val_auc: 0.9018 - 487ms/epoch - 97ms/step\n",
      "Epoch 99/100\n",
      "5/5 - 0s - loss: 0.0166 - accuracy: 0.9934 - auc: 0.9998 - val_loss: 1.3037 - val_accuracy: 0.8657 - val_auc: 0.8697 - 472ms/epoch - 94ms/step\n",
      "Epoch 100/100\n",
      "5/5 - 0s - loss: 0.0540 - accuracy: 0.9885 - auc: 0.9948 - val_loss: 0.8901 - val_accuracy: 0.8806 - val_auc: 0.9307 - 463ms/epoch - 93ms/step\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d2cd077ac00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 2s 62ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        19\n",
      "           1       0.96      0.96      0.96        48\n",
      "\n",
      "    accuracy                           0.94        67\n",
      "   macro avg       0.93      0.93      0.93        67\n",
      "weighted avg       0.94      0.94      0.94        67\n",
      "\n",
      "Roc 0.9703947368421051\n",
      "Confusion Matrix\n",
      "[[17  2]\n",
      " [ 2 46]]\n",
      "minority class [1.]\n",
      "minority people 19\n",
      "y size 0\n",
      "other size 694\n",
      "['Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'Domenico C', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'GRAZIA G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G', 'LISCO G']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/2551710120.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
      "/home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/vit_keras/utils.py:81: UserWarning: Resizing position embeddings from 12, 12 to 2, 2\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 22s - loss: 0.5685 - accuracy: 0.7678 - auc: 0.8393 - val_loss: 0.6343 - val_accuracy: 0.7500 - val_auc: 0.8559 - 22s/epoch - 4s/step\n",
      "Epoch 2/100\n",
      "5/5 - 1s - loss: 0.4539 - accuracy: 0.8177 - auc: 0.8958 - val_loss: 0.2595 - val_accuracy: 0.8875 - val_auc: 0.9635 - 815ms/epoch - 163ms/step\n",
      "Epoch 3/100\n",
      "5/5 - 1s - loss: 0.3755 - accuracy: 0.8311 - auc: 0.9131 - val_loss: 0.2151 - val_accuracy: 0.9375 - val_auc: 0.9828 - 821ms/epoch - 164ms/step\n",
      "Epoch 4/100\n",
      "5/5 - 1s - loss: 0.3424 - accuracy: 0.8445 - auc: 0.9280 - val_loss: 0.1627 - val_accuracy: 0.9250 - val_auc: 0.9863 - 819ms/epoch - 164ms/step\n",
      "Epoch 5/100\n",
      "5/5 - 0s - loss: 0.2341 - accuracy: 0.9021 - auc: 0.9667 - val_loss: 0.1671 - val_accuracy: 0.9250 - val_auc: 0.9845 - 475ms/epoch - 95ms/step\n",
      "Epoch 6/100\n",
      "5/5 - 0s - loss: 0.2447 - accuracy: 0.9060 - auc: 0.9633 - val_loss: 0.1774 - val_accuracy: 0.9375 - val_auc: 0.9815 - 464ms/epoch - 93ms/step\n",
      "Epoch 7/100\n",
      "5/5 - 0s - loss: 0.2087 - accuracy: 0.9060 - auc: 0.9736 - val_loss: 0.1531 - val_accuracy: 0.9375 - val_auc: 0.9854 - 472ms/epoch - 94ms/step\n",
      "Epoch 8/100\n",
      "5/5 - 1s - loss: 0.1938 - accuracy: 0.9232 - auc: 0.9766 - val_loss: 0.1389 - val_accuracy: 0.9500 - val_auc: 0.9883 - 805ms/epoch - 161ms/step\n",
      "Epoch 9/100\n",
      "5/5 - 0s - loss: 0.2077 - accuracy: 0.9098 - auc: 0.9747 - val_loss: 0.1974 - val_accuracy: 0.9000 - val_auc: 0.9787 - 462ms/epoch - 92ms/step\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.1944 - accuracy: 0.9194 - auc: 0.9760 - val_loss: 0.1575 - val_accuracy: 0.9250 - val_auc: 0.9852 - 468ms/epoch - 94ms/step\n",
      "Epoch 11/100\n",
      "5/5 - 1s - loss: 0.1760 - accuracy: 0.9194 - auc: 0.9813 - val_loss: 0.1090 - val_accuracy: 0.9500 - val_auc: 0.9941 - 934ms/epoch - 187ms/step\n",
      "Epoch 12/100\n",
      "5/5 - 1s - loss: 0.1475 - accuracy: 0.9463 - auc: 0.9866 - val_loss: 0.1633 - val_accuracy: 0.9250 - val_auc: 0.9858 - 512ms/epoch - 102ms/step\n",
      "Epoch 13/100\n",
      "5/5 - 1s - loss: 0.1252 - accuracy: 0.9501 - auc: 0.9892 - val_loss: 0.1562 - val_accuracy: 0.9375 - val_auc: 0.9866 - 513ms/epoch - 103ms/step\n",
      "Epoch 14/100\n",
      "5/5 - 1s - loss: 0.0989 - accuracy: 0.9597 - auc: 0.9942 - val_loss: 0.0778 - val_accuracy: 0.9625 - val_auc: 0.9969 - 907ms/epoch - 181ms/step\n",
      "Epoch 15/100\n",
      "5/5 - 1s - loss: 0.0790 - accuracy: 0.9731 - auc: 0.9964 - val_loss: 0.0773 - val_accuracy: 0.9625 - val_auc: 0.9977 - 904ms/epoch - 181ms/step\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.0626 - accuracy: 0.9789 - auc: 0.9975 - val_loss: 0.1311 - val_accuracy: 0.9500 - val_auc: 0.9906 - 477ms/epoch - 95ms/step\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.0576 - accuracy: 0.9750 - auc: 0.9981 - val_loss: 0.2957 - val_accuracy: 0.9125 - val_auc: 0.9815 - 465ms/epoch - 93ms/step\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.1197 - accuracy: 0.9635 - auc: 0.9887 - val_loss: 0.1492 - val_accuracy: 0.9375 - val_auc: 0.9809 - 461ms/epoch - 92ms/step\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.0768 - accuracy: 0.9712 - auc: 0.9954 - val_loss: 0.1178 - val_accuracy: 0.9625 - val_auc: 0.9935 - 476ms/epoch - 95ms/step\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.0652 - accuracy: 0.9808 - auc: 0.9970 - val_loss: 0.1692 - val_accuracy: 0.9250 - val_auc: 0.9897 - 471ms/epoch - 94ms/step\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.0610 - accuracy: 0.9731 - auc: 0.9978 - val_loss: 0.0984 - val_accuracy: 0.9500 - val_auc: 0.9939 - 465ms/epoch - 93ms/step\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.0637 - accuracy: 0.9770 - auc: 0.9974 - val_loss: 0.1267 - val_accuracy: 0.9375 - val_auc: 0.9908 - 466ms/epoch - 93ms/step\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.0555 - accuracy: 0.9770 - auc: 0.9984 - val_loss: 0.1895 - val_accuracy: 0.9250 - val_auc: 0.9847 - 465ms/epoch - 93ms/step\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.0463 - accuracy: 0.9770 - auc: 0.9989 - val_loss: 0.1747 - val_accuracy: 0.9250 - val_auc: 0.9903 - 467ms/epoch - 93ms/step\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.0259 - accuracy: 0.9904 - auc: 0.9996 - val_loss: 0.1536 - val_accuracy: 0.9500 - val_auc: 0.9920 - 473ms/epoch - 95ms/step\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.0292 - accuracy: 0.9904 - auc: 0.9995 - val_loss: 0.1155 - val_accuracy: 0.9500 - val_auc: 0.9937 - 469ms/epoch - 94ms/step\n",
      "Epoch 27/100\n",
      "5/5 - 0s - loss: 0.0109 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9500 - val_auc: 0.9934 - 467ms/epoch - 93ms/step\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.0099 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9250 - val_auc: 0.9919 - 463ms/epoch - 93ms/step\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9500 - val_auc: 0.9923 - 469ms/epoch - 94ms/step\n",
      "Epoch 30/100\n",
      "5/5 - 0s - loss: 0.0219 - accuracy: 0.9962 - auc: 0.9979 - val_loss: 0.1158 - val_accuracy: 0.9625 - val_auc: 0.9959 - 473ms/epoch - 95ms/step\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 0.0037 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9375 - val_auc: 0.9812 - 468ms/epoch - 94ms/step\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.0051 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9375 - val_auc: 0.9795 - 462ms/epoch - 92ms/step\n",
      "Epoch 33/100\n",
      "5/5 - 0s - loss: 0.0086 - accuracy: 0.9962 - auc: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9625 - val_auc: 0.9964 - 470ms/epoch - 94ms/step\n",
      "Epoch 34/100\n",
      "5/5 - 0s - loss: 0.0165 - accuracy: 0.9942 - auc: 0.9999 - val_loss: 0.2047 - val_accuracy: 0.9250 - val_auc: 0.9823 - 463ms/epoch - 93ms/step\n",
      "Epoch 35/100\n",
      "5/5 - 0s - loss: 0.0142 - accuracy: 0.9981 - auc: 0.9998 - val_loss: 0.3704 - val_accuracy: 0.9125 - val_auc: 0.9559 - 467ms/epoch - 93ms/step\n",
      "Epoch 36/100\n",
      "5/5 - 0s - loss: 0.0061 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9125 - val_auc: 0.9784 - 465ms/epoch - 93ms/step\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.0054 - accuracy: 0.9981 - auc: 1.0000 - val_loss: 0.2976 - val_accuracy: 0.9125 - val_auc: 0.9781 - 466ms/epoch - 93ms/step\n",
      "Epoch 38/100\n",
      "5/5 - 0s - loss: 0.0065 - accuracy: 0.9962 - auc: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9375 - val_auc: 0.9809 - 468ms/epoch - 94ms/step\n",
      "Epoch 39/100\n",
      "5/5 - 0s - loss: 0.0047 - accuracy: 0.9962 - auc: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9500 - val_auc: 0.9852 - 467ms/epoch - 93ms/step\n",
      "Epoch 40/100\n",
      "5/5 - 0s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9750 - val_auc: 0.9859 - 464ms/epoch - 93ms/step\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9625 - val_auc: 0.9852 - 461ms/epoch - 92ms/step\n",
      "Epoch 42/100\n",
      "5/5 - 0s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1669 - val_accuracy: 0.9625 - val_auc: 0.9847 - 467ms/epoch - 93ms/step\n",
      "Epoch 43/100\n",
      "5/5 - 0s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9500 - val_auc: 0.9825 - 460ms/epoch - 92ms/step\n",
      "Epoch 44/100\n",
      "5/5 - 0s - loss: 4.8038e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9500 - val_auc: 0.9705 - 469ms/epoch - 94ms/step\n",
      "Epoch 45/100\n",
      "5/5 - 0s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2839 - val_accuracy: 0.9500 - val_auc: 0.9703 - 469ms/epoch - 94ms/step\n",
      "Epoch 46/100\n",
      "5/5 - 0s - loss: 4.3576e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9500 - val_auc: 0.9590 - 468ms/epoch - 94ms/step\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 6.5007e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2764 - val_accuracy: 0.9500 - val_auc: 0.9587 - 471ms/epoch - 94ms/step\n",
      "Epoch 48/100\n",
      "5/5 - 0s - loss: 4.1251e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9500 - val_auc: 0.9703 - 468ms/epoch - 94ms/step\n",
      "Epoch 49/100\n",
      "5/5 - 0s - loss: 6.7378e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9500 - val_auc: 0.9816 - 463ms/epoch - 93ms/step\n",
      "Epoch 50/100\n",
      "5/5 - 0s - loss: 2.4812e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9375 - val_auc: 0.9812 - 465ms/epoch - 93ms/step\n",
      "Epoch 51/100\n",
      "5/5 - 0s - loss: 1.6673e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9375 - val_auc: 0.9811 - 465ms/epoch - 93ms/step\n",
      "Epoch 52/100\n",
      "5/5 - 0s - loss: 1.9433e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2468 - val_accuracy: 0.9375 - val_auc: 0.9811 - 459ms/epoch - 92ms/step\n",
      "Epoch 53/100\n",
      "5/5 - 0s - loss: 3.6250e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9375 - val_auc: 0.9811 - 465ms/epoch - 93ms/step\n",
      "Epoch 54/100\n",
      "5/5 - 0s - loss: 2.2719e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9375 - val_auc: 0.9870 - 466ms/epoch - 93ms/step\n",
      "Epoch 55/100\n",
      "5/5 - 0s - loss: 2.7727e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2203 - val_accuracy: 0.9375 - val_auc: 0.9927 - 471ms/epoch - 94ms/step\n",
      "Epoch 56/100\n",
      "5/5 - 0s - loss: 2.0934e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2125 - val_accuracy: 0.9375 - val_auc: 0.9878 - 467ms/epoch - 93ms/step\n",
      "Epoch 57/100\n",
      "5/5 - 0s - loss: 2.0347e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9375 - val_auc: 0.9823 - 474ms/epoch - 95ms/step\n",
      "Epoch 58/100\n",
      "5/5 - 0s - loss: 3.2786e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9375 - val_auc: 0.9823 - 467ms/epoch - 93ms/step\n",
      "Epoch 59/100\n",
      "5/5 - 0s - loss: 1.5704e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9500 - val_auc: 0.9825 - 466ms/epoch - 93ms/step\n",
      "Epoch 60/100\n",
      "5/5 - 0s - loss: 1.8729e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2067 - val_accuracy: 0.9500 - val_auc: 0.9825 - 458ms/epoch - 92ms/step\n",
      "Epoch 61/100\n",
      "5/5 - 0s - loss: 1.7149e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9500 - val_auc: 0.9825 - 465ms/epoch - 93ms/step\n",
      "Epoch 62/100\n",
      "5/5 - 0s - loss: 2.0351e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2109 - val_accuracy: 0.9500 - val_auc: 0.9825 - 464ms/epoch - 93ms/step\n",
      "Epoch 63/100\n",
      "5/5 - 0s - loss: 1.0785e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9375 - val_auc: 0.9823 - 471ms/epoch - 94ms/step\n",
      "Epoch 64/100\n",
      "5/5 - 0s - loss: 1.1769e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9375 - val_auc: 0.9822 - 467ms/epoch - 93ms/step\n",
      "Epoch 65/100\n",
      "5/5 - 0s - loss: 1.1110e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2356 - val_accuracy: 0.9375 - val_auc: 0.9820 - 478ms/epoch - 96ms/step\n",
      "Epoch 66/100\n",
      "5/5 - 0s - loss: 1.0873e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9375 - val_auc: 0.9820 - 467ms/epoch - 93ms/step\n",
      "Epoch 67/100\n",
      "5/5 - 0s - loss: 1.1562e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2383 - val_accuracy: 0.9375 - val_auc: 0.9820 - 472ms/epoch - 94ms/step\n",
      "Epoch 68/100\n",
      "5/5 - 0s - loss: 3.4860e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9375 - val_auc: 0.9822 - 466ms/epoch - 93ms/step\n",
      "Epoch 69/100\n",
      "5/5 - 0s - loss: 1.3800e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9375 - val_auc: 0.9820 - 463ms/epoch - 93ms/step\n",
      "Epoch 70/100\n",
      "5/5 - 0s - loss: 1.0725e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9375 - val_auc: 0.9708 - 472ms/epoch - 94ms/step\n",
      "Epoch 71/100\n",
      "5/5 - 0s - loss: 2.1000e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2603 - val_accuracy: 0.9375 - val_auc: 0.9708 - 489ms/epoch - 98ms/step\n",
      "Epoch 72/100\n",
      "5/5 - 0s - loss: 1.6226e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9375 - val_auc: 0.9706 - 485ms/epoch - 97ms/step\n",
      "Epoch 73/100\n",
      "5/5 - 0s - loss: 1.1540e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9375 - val_auc: 0.9705 - 468ms/epoch - 94ms/step\n",
      "Epoch 74/100\n",
      "5/5 - 0s - loss: 9.8775e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2690 - val_accuracy: 0.9375 - val_auc: 0.9702 - 474ms/epoch - 95ms/step\n",
      "Epoch 75/100\n",
      "5/5 - 0s - loss: 1.8285e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2671 - val_accuracy: 0.9375 - val_auc: 0.9705 - 472ms/epoch - 94ms/step\n",
      "Epoch 76/100\n",
      "5/5 - 0s - loss: 1.0627e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9375 - val_auc: 0.9705 - 469ms/epoch - 94ms/step\n",
      "Epoch 77/100\n",
      "5/5 - 0s - loss: 6.8154e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2644 - val_accuracy: 0.9375 - val_auc: 0.9705 - 472ms/epoch - 94ms/step\n",
      "Epoch 78/100\n",
      "5/5 - 0s - loss: 2.6962e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9375 - val_auc: 0.9817 - 468ms/epoch - 94ms/step\n",
      "Epoch 79/100\n",
      "5/5 - 0s - loss: 8.2335e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9375 - val_auc: 0.9818 - 474ms/epoch - 95ms/step\n",
      "Epoch 80/100\n",
      "5/5 - 0s - loss: 7.8754e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9375 - val_auc: 0.9823 - 469ms/epoch - 94ms/step\n",
      "Epoch 81/100\n",
      "5/5 - 0s - loss: 1.0258e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9375 - val_auc: 0.9828 - 466ms/epoch - 93ms/step\n",
      "Epoch 82/100\n",
      "5/5 - 0s - loss: 1.1875e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9375 - val_auc: 0.9830 - 476ms/epoch - 95ms/step\n",
      "Epoch 83/100\n",
      "5/5 - 0s - loss: 9.5335e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9375 - val_auc: 0.9830 - 470ms/epoch - 94ms/step\n",
      "Epoch 84/100\n",
      "5/5 - 0s - loss: 6.2304e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2422 - val_accuracy: 0.9375 - val_auc: 0.9830 - 478ms/epoch - 96ms/step\n",
      "Epoch 85/100\n",
      "5/5 - 0s - loss: 6.4305e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9375 - val_auc: 0.9831 - 463ms/epoch - 93ms/step\n",
      "Epoch 86/100\n",
      "5/5 - 0s - loss: 5.8354e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9375 - val_auc: 0.9831 - 479ms/epoch - 96ms/step\n",
      "Epoch 87/100\n",
      "5/5 - 0s - loss: 6.8725e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9375 - val_auc: 0.9830 - 464ms/epoch - 93ms/step\n",
      "Epoch 88/100\n",
      "5/5 - 0s - loss: 9.2084e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9375 - val_auc: 0.9830 - 479ms/epoch - 96ms/step\n",
      "Epoch 89/100\n",
      "5/5 - 0s - loss: 1.0044e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9375 - val_auc: 0.9830 - 466ms/epoch - 93ms/step\n",
      "Epoch 90/100\n",
      "5/5 - 0s - loss: 8.1508e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2473 - val_accuracy: 0.9375 - val_auc: 0.9830 - 468ms/epoch - 94ms/step\n",
      "Epoch 91/100\n",
      "5/5 - 0s - loss: 1.4907e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2344 - val_accuracy: 0.9375 - val_auc: 0.9834 - 471ms/epoch - 94ms/step\n",
      "Epoch 92/100\n",
      "5/5 - 0s - loss: 5.5886e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2164 - val_accuracy: 0.9375 - val_auc: 0.9836 - 465ms/epoch - 93ms/step\n",
      "Epoch 93/100\n",
      "5/5 - 0s - loss: 8.6330e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2064 - val_accuracy: 0.9375 - val_auc: 0.9836 - 471ms/epoch - 94ms/step\n",
      "Epoch 94/100\n",
      "5/5 - 0s - loss: 4.6533e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9500 - val_auc: 0.9837 - 466ms/epoch - 93ms/step\n",
      "Epoch 95/100\n",
      "5/5 - 0s - loss: 7.7769e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9500 - val_auc: 0.9836 - 469ms/epoch - 94ms/step\n",
      "Epoch 96/100\n",
      "5/5 - 0s - loss: 5.1510e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2008 - val_accuracy: 0.9500 - val_auc: 0.9836 - 468ms/epoch - 94ms/step\n",
      "Epoch 97/100\n",
      "5/5 - 0s - loss: 1.1088e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9500 - val_auc: 0.9838 - 484ms/epoch - 97ms/step\n",
      "Epoch 98/100\n",
      "5/5 - 0s - loss: 9.0587e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9375 - val_auc: 0.9837 - 456ms/epoch - 91ms/step\n",
      "Epoch 99/100\n",
      "5/5 - 0s - loss: 8.1360e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9375 - val_auc: 0.9836 - 454ms/epoch - 91ms/step\n",
      "Epoch 100/100\n",
      "5/5 - 0s - loss: 6.0897e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9375 - val_auc: 0.9834 - 439ms/epoch - 88ms/step\n",
      "3/3 [==============================] - 2s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95        32\n",
      "           1       0.98      0.96      0.97        48\n",
      "\n",
      "    accuracy                           0.96        80\n",
      "   macro avg       0.96      0.96      0.96        80\n",
      "weighted avg       0.96      0.96      0.96        80\n",
      "\n",
      "Roc 0.998046875\n",
      "Confusion Matrix\n",
      "[[31  1]\n",
      " [ 2 46]]\n",
      "{'0': {'precision': 0.44, 'recall': 0.5789473684210527, 'f1-score': 0.5, 'support': 38.0}, '1': {'precision': 0.7647058823529411, 'recall': 0.65, 'f1-score': 0.7027027027027027, 'support': 80.0}, 'accuracy': 0.6271186440677966, 'macro avg': {'precision': 0.6023529411764705, 'recall': 0.6144736842105263, 'f1-score': 0.6013513513513513, 'support': 118.0}, 'weighted avg': {'precision': 0.6601395812562313, 'recall': 0.6271186440677966, 'f1-score': 0.6374255611543748, 'support': 118.0}}\n",
      "{'0': {'precision': 0.4657534246575342, 'recall': 0.7727272727272727, 'f1-score': 0.5811965811965812, 'support': 44.0}, '1': {'precision': 0.8412698412698413, 'recall': 0.5760869565217391, 'f1-score': 0.6838709677419355, 'support': 92.0}, 'accuracy': 0.6397058823529411, 'macro avg': {'precision': 0.6535116329636877, 'recall': 0.6744071146245059, 'f1-score': 0.6325337744692583, 'support': 136.0}, 'weighted avg': {'precision': 0.7197792358952713, 'recall': 0.6397058823529411, 'f1-score': 0.650652783859615, 'support': 136.0}}\n",
      "{'0': {'precision': 0.5, 'recall': 0.34210526315789475, 'f1-score': 0.40625000000000006, 'support': 38.0}, '1': {'precision': 0.6621621621621622, 'recall': 0.7903225806451613, 'f1-score': 0.7205882352941176, 'support': 62.0}, 'accuracy': 0.62, 'macro avg': {'precision': 0.5810810810810811, 'recall': 0.566213921901528, 'f1-score': 0.5634191176470589, 'support': 100.0}, 'weighted avg': {'precision': 0.6005405405405405, 'recall': 0.62, 'f1-score': 0.601139705882353, 'support': 100.0}}\n",
      "{'0': {'precision': 0.52, 'recall': 0.6842105263157895, 'f1-score': 0.5909090909090909, 'support': 38.0}, '1': {'precision': 0.7272727272727273, 'recall': 0.5714285714285714, 'f1-score': 0.64, 'support': 56.0}, 'accuracy': 0.6170212765957447, 'macro avg': {'precision': 0.6236363636363637, 'recall': 0.6278195488721805, 'f1-score': 0.6154545454545455, 'support': 94.0}, 'weighted avg': {'precision': 0.6434816247582205, 'recall': 0.6170212765957447, 'f1-score': 0.6201547388781432, 'support': 94.0}}\n",
      "{'0': {'precision': 0.47435897435897434, 'recall': 0.5522388059701493, 'f1-score': 0.5103448275862068, 'support': 67.0}, '1': {'precision': 0.6703296703296703, 'recall': 0.5980392156862745, 'f1-score': 0.6321243523316062, 'support': 102.0}, 'accuracy': 0.5798816568047337, 'macro avg': {'precision': 0.5723443223443223, 'recall': 0.575139010828212, 'f1-score': 0.5712345899589065, 'support': 169.0}, 'weighted avg': {'precision': 0.5926371458915837, 'recall': 0.5798816568047337, 'f1-score': 0.5838448957757378, 'support': 169.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38.0}}\n",
      "{'0': {'precision': 0.8653846153846154, 'recall': 0.9375, 'f1-score': 0.9, 'support': 48.0}, '1': {'precision': 0.9482758620689655, 'recall': 0.8870967741935484, 'f1-score': 0.9166666666666667, 'support': 62.0}, 'accuracy': 0.9090909090909091, 'macro avg': {'precision': 0.9068302387267905, 'recall': 0.9122983870967742, 'f1-score': 0.9083333333333334, 'support': 110.0}, 'weighted avg': {'precision': 0.9121051362430673, 'recall': 0.9090909090909091, 'f1-score': 0.9093939393939394, 'support': 110.0}}\n",
      "{'0': {'precision': 0.8947368421052632, 'recall': 0.9714285714285714, 'f1-score': 0.9315068493150684, 'support': 35.0}, '1': {'precision': 0.9777777777777777, 'recall': 0.9166666666666666, 'f1-score': 0.946236559139785, 'support': 48.0}, 'accuracy': 0.9397590361445783, 'macro avg': {'precision': 0.9362573099415205, 'recall': 0.944047619047619, 'f1-score': 0.9388717042274267, 'support': 83.0}, 'weighted avg': {'precision': 0.9427605157471993, 'recall': 0.9397590361445783, 'f1-score': 0.9400252357197237, 'support': 83.0}}\n",
      "{'0': {'precision': 0.8947368421052632, 'recall': 0.8947368421052632, 'f1-score': 0.8947368421052632, 'support': 19.0}, '1': {'precision': 0.9583333333333334, 'recall': 0.9583333333333334, 'f1-score': 0.9583333333333334, 'support': 48.0}, 'accuracy': 0.9402985074626866, 'macro avg': {'precision': 0.9265350877192983, 'recall': 0.9265350877192983, 'f1-score': 0.9265350877192983, 'support': 67.0}, 'weighted avg': {'precision': 0.9402985074626866, 'recall': 0.9402985074626866, 'f1-score': 0.9402985074626866, 'support': 67.0}}\n",
      "{'0': {'precision': 0.9393939393939394, 'recall': 0.96875, 'f1-score': 0.9538461538461539, 'support': 32.0}, '1': {'precision': 0.9787234042553191, 'recall': 0.9583333333333334, 'f1-score': 0.968421052631579, 'support': 48.0}, 'accuracy': 0.9625, 'macro avg': {'precision': 0.9590586718246292, 'recall': 0.9635416666666667, 'f1-score': 0.9611336032388664, 'support': 80.0}, 'weighted avg': {'precision': 0.9629916183107673, 'recall': 0.9625, 'f1-score': 0.962591093117409, 'support': 80.0}}\n",
      "Mean accuracy 0.7835375912519391\n",
      "Mean precision 0.7974733906105568\n",
      "Mean recall 0.7835375912519391\n",
      "Mean F1 0.7845526461243982\n",
      "None\n",
      "AUC\n",
      "0.8150760532753054\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "#from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow\n",
    "\n",
    "def concilie_per_patient_res(predx, y_test, usercodes):\n",
    "    new_pred = []\n",
    "    new_y_test = []\n",
    "     \n",
    "    #print('Prediced shape')\n",
    "    #print(predx.shape)\n",
    "    \n",
    "    if y_test.shape[-1] < 2:\n",
    "      y_test = to_categorical(y_test)\n",
    "    patient = {}\n",
    "    for i in range(len(y_test)):\n",
    "      if not usercodes[i] in patient:\n",
    "        patient[usercodes[i]] = {}\n",
    "        patient[usercodes[i]]['predicted'] = []\n",
    "        patient[usercodes[i]]['y_test'] = []               \n",
    "      patient[usercodes[i]]['predicted'].append(predx[i])\n",
    "      patient[usercodes[i]]['y_test'].append(y_test[i])\n",
    "      #print(patient[usercodes[i]]['predicted'])\n",
    "    keys = list(patient.keys())\n",
    "    for key in keys:\n",
    "       predi = patient[key]['predicted']\n",
    "       yi = patient[key]['y_test']\n",
    "       mean_pred = np.asarray(predi).mean(axis=0)\n",
    "       mean_y = np.asarray(yi).mean(axis=0)\n",
    "       #print('Mean pred shape '+str(mean_pred.shape))\n",
    "       #print('Mean y shape '+str(mean_y.shape))\n",
    "       new_pred.append(mean_pred)\n",
    "       new_y_test.append(mean_y)\n",
    "\n",
    "    new_pred = np.asarray(new_pred)\n",
    "    #print(new_pred.shape)\n",
    "    new_y_test = np.asarray(new_y_test)\n",
    "    #print(new_y_test.shape)\n",
    "\n",
    "    return new_pred, new_y_test\n",
    "    \n",
    " \n",
    "\n",
    "def report_average(reports):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for report in reports:\n",
    "        print(report)\n",
    "        accuracy.append(report['accuracy'])\n",
    "        precision.append(report['weighted avg']['precision'])\n",
    "        recall.append(report['weighted avg']['recall'])\n",
    "        f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "    print('Mean accuracy '+str(np.mean(accuracy)))\n",
    "    print('Mean precision ' + str(np.mean(precision)))\n",
    "    print('Mean recall ' + str(np.mean(recall)))\n",
    "    print('Mean F1 ' + str(np.mean(f1)))\n",
    "\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    " \n",
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "          \n",
    " \n",
    "for i in range(5):\n",
    "    #K.clear_session()#puliamo la ram della GPU \n",
    "    tf.keras.backend.clear_session()\n",
    " \n",
    "    y_new = np.asarray(y,dtype=np.float32)\n",
    "    X_new = np.asarray(X,dtype=np.float32)\n",
    "    y_size = 0\n",
    "\n",
    "    \n",
    "    if True:\n",
    "      #while y_size < int(len(X_new)*0.05):\n",
    "     \n",
    "      X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.1)\n",
    "      cd = np.where(y_train == to_categorical([1.0]))\n",
    "      cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
    "      y_size = len(cd2[0])\n",
    "      print('y size',y_size)\n",
    "      print('other size',len(cd[0]))\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    "    print(test_usercodes)\n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    "\n",
    "    input_shape = (1, X_train[0].shape[1])\n",
    "    #report_standard_algo(X_train.copy(),X_test.copy(),y_train.copy(),y_test.copy(),train_usercodes,test_usercodes)\n",
    "\n",
    "\n",
    "    \n",
    "     \n",
    "    for k in range(1):\n",
    "      model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='vision_transformer'+str(i)+'.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "      strategy = tf.distribute.MirroredStrategy()\n",
    "      with strategy.scope():\n",
    "          # Everything that creates variables should be under the strategy scope.\n",
    "          # In general this is only model construction & `compile()`.\n",
    "          model = AudioVisionTransformer(2)\n",
    "          model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                          loss=\"categorical_crossentropy\",\n",
    "                           metrics=['accuracy','AUC'])\n",
    "      \n",
    "      \n",
    "      history = model.fit(X_train,y_train, epochs=100, batch_size=128,  validation_data = (X_test,y_test), \n",
    "                                callbacks=[model_checkpoint_callback], verbose=2)\n",
    "      model2 = model\n",
    "          \n",
    "          \n",
    "          \n",
    "      if model2 != None:\n",
    "        model2.load_weights('vision_transformer'+str(i)+'.h5')\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        \n",
    "        new_pred = y_pred\n",
    "        new_y_test = y_test\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "        aa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "        aucs.append(roc_auc)\n",
    "        # Plot non-normalized confusion matrix\n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "\n",
    "\n",
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.44, 'recall': 0.5789473684210527, 'f1-score': 0.5, 'support': 38.0}, '1': {'precision': 0.7647058823529411, 'recall': 0.65, 'f1-score': 0.7027027027027027, 'support': 80.0}, 'accuracy': 0.6271186440677966, 'macro avg': {'precision': 0.6023529411764705, 'recall': 0.6144736842105263, 'f1-score': 0.6013513513513513, 'support': 118.0}, 'weighted avg': {'precision': 0.6601395812562313, 'recall': 0.6271186440677966, 'f1-score': 0.6374255611543748, 'support': 118.0}}\n",
      "{'0': {'precision': 0.4657534246575342, 'recall': 0.7727272727272727, 'f1-score': 0.5811965811965812, 'support': 44.0}, '1': {'precision': 0.8412698412698413, 'recall': 0.5760869565217391, 'f1-score': 0.6838709677419355, 'support': 92.0}, 'accuracy': 0.6397058823529411, 'macro avg': {'precision': 0.6535116329636877, 'recall': 0.6744071146245059, 'f1-score': 0.6325337744692583, 'support': 136.0}, 'weighted avg': {'precision': 0.7197792358952713, 'recall': 0.6397058823529411, 'f1-score': 0.650652783859615, 'support': 136.0}}\n",
      "{'0': {'precision': 0.5, 'recall': 0.34210526315789475, 'f1-score': 0.40625000000000006, 'support': 38.0}, '1': {'precision': 0.6621621621621622, 'recall': 0.7903225806451613, 'f1-score': 0.7205882352941176, 'support': 62.0}, 'accuracy': 0.62, 'macro avg': {'precision': 0.5810810810810811, 'recall': 0.566213921901528, 'f1-score': 0.5634191176470589, 'support': 100.0}, 'weighted avg': {'precision': 0.6005405405405405, 'recall': 0.62, 'f1-score': 0.601139705882353, 'support': 100.0}}\n",
      "{'0': {'precision': 0.52, 'recall': 0.6842105263157895, 'f1-score': 0.5909090909090909, 'support': 38.0}, '1': {'precision': 0.7272727272727273, 'recall': 0.5714285714285714, 'f1-score': 0.64, 'support': 56.0}, 'accuracy': 0.6170212765957447, 'macro avg': {'precision': 0.6236363636363637, 'recall': 0.6278195488721805, 'f1-score': 0.6154545454545455, 'support': 94.0}, 'weighted avg': {'precision': 0.6434816247582205, 'recall': 0.6170212765957447, 'f1-score': 0.6201547388781432, 'support': 94.0}}\n",
      "{'0': {'precision': 0.47435897435897434, 'recall': 0.5522388059701493, 'f1-score': 0.5103448275862068, 'support': 67.0}, '1': {'precision': 0.6703296703296703, 'recall': 0.5980392156862745, 'f1-score': 0.6321243523316062, 'support': 102.0}, 'accuracy': 0.5798816568047337, 'macro avg': {'precision': 0.5723443223443223, 'recall': 0.575139010828212, 'f1-score': 0.5712345899589065, 'support': 169.0}, 'weighted avg': {'precision': 0.5926371458915837, 'recall': 0.5798816568047337, 'f1-score': 0.5838448957757378, 'support': 169.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 6.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38.0}}\n",
      "{'0': {'precision': 0.8653846153846154, 'recall': 0.9375, 'f1-score': 0.9, 'support': 48.0}, '1': {'precision': 0.9482758620689655, 'recall': 0.8870967741935484, 'f1-score': 0.9166666666666667, 'support': 62.0}, 'accuracy': 0.9090909090909091, 'macro avg': {'precision': 0.9068302387267905, 'recall': 0.9122983870967742, 'f1-score': 0.9083333333333334, 'support': 110.0}, 'weighted avg': {'precision': 0.9121051362430673, 'recall': 0.9090909090909091, 'f1-score': 0.9093939393939394, 'support': 110.0}}\n",
      "{'0': {'precision': 0.8947368421052632, 'recall': 0.9714285714285714, 'f1-score': 0.9315068493150684, 'support': 35.0}, '1': {'precision': 0.9777777777777777, 'recall': 0.9166666666666666, 'f1-score': 0.946236559139785, 'support': 48.0}, 'accuracy': 0.9397590361445783, 'macro avg': {'precision': 0.9362573099415205, 'recall': 0.944047619047619, 'f1-score': 0.9388717042274267, 'support': 83.0}, 'weighted avg': {'precision': 0.9427605157471993, 'recall': 0.9397590361445783, 'f1-score': 0.9400252357197237, 'support': 83.0}}\n",
      "{'0': {'precision': 0.8947368421052632, 'recall': 0.8947368421052632, 'f1-score': 0.8947368421052632, 'support': 19.0}, '1': {'precision': 0.9583333333333334, 'recall': 0.9583333333333334, 'f1-score': 0.9583333333333334, 'support': 48.0}, 'accuracy': 0.9402985074626866, 'macro avg': {'precision': 0.9265350877192983, 'recall': 0.9265350877192983, 'f1-score': 0.9265350877192983, 'support': 67.0}, 'weighted avg': {'precision': 0.9402985074626866, 'recall': 0.9402985074626866, 'f1-score': 0.9402985074626866, 'support': 67.0}}\n",
      "{'0': {'precision': 0.9393939393939394, 'recall': 0.96875, 'f1-score': 0.9538461538461539, 'support': 32.0}, '1': {'precision': 0.9787234042553191, 'recall': 0.9583333333333334, 'f1-score': 0.968421052631579, 'support': 48.0}, 'accuracy': 0.9625, 'macro avg': {'precision': 0.9590586718246292, 'recall': 0.9635416666666667, 'f1-score': 0.9611336032388664, 'support': 80.0}, 'weighted avg': {'precision': 0.9629916183107673, 'recall': 0.9625, 'f1-score': 0.962591093117409, 'support': 80.0}}\n",
      "Mean accuracy 0.7835375912519391\n",
      "Mean precision 0.7974733906105568\n",
      "Mean recall 0.7835375912519391\n",
      "Mean F1 0.7845526461243982\n",
      "None\n",
      "AUC\n",
      "0.8150760532753054\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class HilbertHuangTransformSVD(Layer):\n",
    "    def __init__(self, num_splits = 100, max_imf = 5, **kwargs):\n",
    "        super(HilbertHuangTransformSVD, self).__init__(**kwargs)\n",
    "        #self.W1 = tf.keras.layers.Dense(units)\n",
    "        #self.W2 = tf.keras.layers.Dense(units)\n",
    "        #self.V = tf.keras.layers.Dense(1)\n",
    "        self.max_imfs = max_imf\n",
    "        self.multiheaded = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=8)\n",
    "        self.attention = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        kernelsize = int(SAMPLING_RATE*0.01)#100ms)\n",
    "        self.conv = tf.keras.layers.Conv1D(128, kernel_size=kernelsize, activation='elu', padding='same')\n",
    "        \n",
    "        # Encoding layers\n",
    "        self.conv1 = tf.keras.layers.Conv1D(64, kernel_size=3 , activation='elu', padding='same')\n",
    "        self.maxpool1 =  tf.keras.layers.MaxPooling1D(2, padding='same')\n",
    "        self.conv2 =  tf.keras.layers.Conv1D(32, 3, activation='elu', padding='same')\n",
    "        self.encoder = tf.keras.layers.MaxPooling1D(2, padding='same')\n",
    "\n",
    "        # Decoding layers\n",
    "        self.conv3 = tf.keras.layers.Conv1D(32, 3, activation='elu', padding='same')\n",
    "        self.up1 = tf.keras.layers.UpSampling1D(2)\n",
    "        self.conv4 = tf.keras.layers.Conv1D(64, 3, activation='elu', padding='same')\n",
    "        self.up2 = tf.keras.layers.UpSampling1D(2)\n",
    "        self.num_splits = num_splits\n",
    "        \n",
    "        self.conv5 = tf.keras.layers.Conv1D(1, 3, activation='sigmoid', padding='same')\n",
    "    \n",
    "   \n",
    "    def sifting(self, tensor, max_iters=100, threshold=1e-4):\n",
    "        tensor = tf.expand_dims(tensor, axis=1)\n",
    "        for _ in tf.range(max_iters):\n",
    "            local_min = tf.keras.layers.AveragePooling1D(3, strides=1, padding='same')(tensor)\n",
    "            local_max = tf.keras.layers.MaxPooling1D(3, strides=1, padding='same')(tensor)\n",
    "\n",
    "            env_mean = (local_min + local_max) / 2\n",
    "            deviation = tf.reduce_mean(tf.abs(env_mean - tensor))\n",
    "\n",
    "            if deviation < threshold:\n",
    "                break\n",
    "\n",
    "            tensor = tensor - env_mean\n",
    "        tensor = tf.squeeze(tensor, axis=1)\n",
    "        return tensor\n",
    "\n",
    "    def emd(self, tensor):\n",
    "        imfs = []\n",
    "        residual = tensor\n",
    "\n",
    "        for _ in range(self.max_imfs):\n",
    "            imf = self.sifting(residual)\n",
    "            residual = residual - imf\n",
    "            imfs.append(imf)\n",
    "\n",
    "        return tf.stack(imfs, axis=-1)\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "    def call(self, x):\n",
    "        splits = tf.split(x, self.num_splits, axis=1)\n",
    "        # now we have a list of tensors each of shape (batch_size, 2205, 1)\n",
    "        \n",
    "        outputs = []\n",
    "        for xi in splits:\n",
    "            # replace this with your actual operation\n",
    "            \n",
    "            xi = self.conv1(xi)\n",
    "            xi = self.maxpool1(xi)\n",
    "            xi = self.conv2(xi)\n",
    "            xi = self.encoder(xi)\n",
    "            \n",
    "            #xi = self.conv3(xi)\n",
    "            #xi = self.up1(xi)\n",
    "            #xi = self.conv4(xi)\n",
    "            #xi = self.up2(xi)\n",
    "            xi = self.conv5(xi)\n",
    "            #after last conv5 (None, 550, 1)\n",
    "            #imfs shape (None, 550, 1, 5)\n",
    "            #print('after last conv5',xi.shape)\n",
    "            #\n",
    "            imfs = tf.map_fn(self.emd, xi, fn_output_signature=tf.TensorSpec(shape=(None, None, self.max_imfs), dtype=tf.float32))\n",
    "            \n",
    "            #imfs = tf.reshape(imfs, (-1, imfs.shape[1]*imfs.shape[3], 1))\n",
    "            #imfs = tf.reshape(imfs, (None, tf.shape(imfs)[1]*tf.shape(imfs)[2]),1)\n",
    "            #imfs = tf.squeeze(imfs, axis=-1)\n",
    "            #print('imfs shape',imfs.shape)\n",
    "            analytic_signal = hilbert_transform_orig(imfs)\n",
    "            \n",
    "            #print('after hilbert',analytic_signal.shape)\n",
    "            \n",
    "            magnitude = tf.math.real(analytic_signal)\n",
    "            #magnitude = self.multiheaded(magnitude,magnitude)\n",
    "            outputs.append(magnitude)\n",
    "            \n",
    "        # concatenate outputs back into a single tensor\n",
    "        magnitude = tf.concat(outputs, axis=1)\n",
    "        \n",
    "        \n",
    "        magnitude = self.conv(magnitude)\n",
    "        #magnitude = self.multiheaded(magnitude, magnitude)\n",
    "        return magnitude\n",
    "\n",
    "\n",
    "    def hilbert_transform(self, x):\n",
    "        #x = tf.squeeze(x, axis=-1)\n",
    "        fft_x = tf.signal.fft(tf.cast(x, tf.complex64))\n",
    "        h = tf.zeros_like(fft_x)\n",
    "        h_len = tf.shape(h)[-1] // 2\n",
    "        h = tf.concat([tf.ones(h_len), tf.zeros(1), tf.zeros(h_len - 1)], axis=0)\n",
    "        hilbert_x = tf.signal.ifft(fft_x * tf.cast(h, tf.complex64))\n",
    "        analytic_signal = tf.expand_dims(hilbert_x, axis=-1)\n",
    "        return analytic_signal\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(HilbertHuangTransformSVD, self).get_config()\n",
    "        config.update({'num_splits': self.num_splits})\n",
    "        return config\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hilbert_transform_orig(tensor):\n",
    "    N = tensor.shape[-2]\n",
    "    tensor_fft = tf.signal.fft(tf.cast(tensor, tf.complex64))\n",
    "    h = tf.concat([tf.ones((N + 1) // 2, dtype=tf.complex64), tf.zeros(N // 2, dtype=tf.complex64)], axis=0)\n",
    "    return tf.signal.ifft(tensor_fft * h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "def residual_block(x, s, i, activation, nb_filters, kernel_size, dropout_rate=0.0):\n",
    "    original_x = x\n",
    "    conv = Conv1D(filters=nb_filters, kernel_size=kernel_size, dilation_rate=2**i, padding='causal')(x)\n",
    "    if dropout_rate != 0.0:\n",
    "        conv = Dropout(rate=dropout_rate)(conv)\n",
    "    x = Activation(activation)(conv)\n",
    "    x = Conv1D(filters=nb_filters, kernel_size=kernel_size, dilation_rate=2**i, padding='causal')(x)\n",
    "    if dropout_rate != 0.0:\n",
    "        x = Dropout(rate=dropout_rate)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    out = Multiply()([conv, x])\n",
    "    if original_x.shape[-1] != nb_filters:\n",
    "        original_x = Conv1D(nb_filters, 1, padding='same')(original_x)\n",
    "    out = Add()([original_x, out])\n",
    "    return out\n",
    "\n",
    "def tcn(input_shape, num_classes, nb_filters, kernel_size, nb_stacks, max_blocks, activation=tf.nn.swish, dropout_rate=0.0):\n",
    "    input_layer = Input(shape=input_shape[1:], name='input_layer')\n",
    "    x = input_layer\n",
    "    for s in range(nb_stacks):\n",
    "        for i in range(max_blocks):  # Using a fixed number of blocks\n",
    "            x = residual_block(x, s, i, activation, nb_filters, kernel_size, dropout_rate)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU\n",
    "\n",
    "def lightweight_residual_block(x, i, nb_filters, kernel_size):\n",
    "    \"\"\"\n",
    "    Defines a simplified residual block for the lightweight TCN\n",
    "    \"\"\"\n",
    "    original_x = x\n",
    "    x = Conv1D(filters=nb_filters, kernel_size=kernel_size, dilation_rate=2**i, padding='causal')(x)\n",
    "    x = ReLU()(x)\n",
    "    if original_x.shape[-1] != nb_filters:\n",
    "        original_x = Conv1D(nb_filters, 1, padding='same')(original_x)\n",
    "    x = Add()([original_x, x])\n",
    "    return x\n",
    "\n",
    "def lightweight_tcn(input_shape, num_classes, nb_filters=32, kernel_size=3, max_blocks=3):\n",
    "    \"\"\"\n",
    "    Creates the lightweight TCN\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=input_shape[1:], name='input_layer')\n",
    "    x = input_layer\n",
    "    for i in range(max_blocks):\n",
    "        x = lightweight_residual_block(x, i, nb_filters, kernel_size)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "def build_tdnn(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # TDNN layers with increasing dilation rates to capture wider context\n",
    "    x = Conv1D(64, 5, padding='same', dilation_rate=1)(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv1D(128, 7, padding='same', dilation_rate=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    x = Conv1D(256, 9, padding='same', dilation_rate=4)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    # Flatten and fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, ReLU, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "def build_samplecnn(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # SampleCNN layers with filter size of 3 and stride of 3 for down-sampling\n",
    "    x = Conv1D(128, 3, strides=3, padding='valid', activation='relu')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv1D(128, 3, strides=3, padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(256, 3, strides=3, padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(256, 3, strides=3, padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(512, 3, strides=3, padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(512, 3, strides=3, padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv1D(1024, 3, strides=3, padding='valid', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Global average pooling and fully connected layer\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "aa = []\n",
    "saucs = []\n",
    "saa = []\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-07 14:58:30.362211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.362406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.362496: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.362613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.362687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.362755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-07 14:58:30.363614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.363738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.363826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.363912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.363983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-07 14:58:30.364037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n",
      "minority class [1.]\n",
      "minority people 22\n",
      "y size 0\n",
      "other size 810\n",
      "['LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'LUIGI P', 'Davide M', 'Davide M', 'Davide M', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Giulia P', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B', 'Mario B']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4079609347.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 - 12s - loss: 0.4670 - accuracy: 0.7818 - auc: 0.8614 - val_loss: 0.6966 - val_accuracy: 0.6275 - val_auc: 0.6421 - 12s/epoch - 152ms/step\n",
      "Epoch 2/100\n",
      "77/77 - 6s - loss: 0.2954 - accuracy: 0.8632 - auc: 0.9489 - val_loss: 0.6852 - val_accuracy: 0.6275 - val_auc: 0.8185 - 6s/epoch - 82ms/step\n",
      "Epoch 3/100\n",
      "77/77 - 6s - loss: 0.2127 - accuracy: 0.9121 - auc: 0.9728 - val_loss: 2.3675 - val_accuracy: 0.6275 - val_auc: 0.6275 - 6s/epoch - 82ms/step\n",
      "Epoch 4/100\n",
      "77/77 - 6s - loss: 0.2189 - accuracy: 0.9235 - auc: 0.9707 - val_loss: 1.8289 - val_accuracy: 0.6275 - val_auc: 0.6275 - 6s/epoch - 82ms/step\n",
      "Epoch 5/100\n",
      "77/77 - 6s - loss: 0.1923 - accuracy: 0.9267 - auc: 0.9782 - val_loss: 2.2879 - val_accuracy: 0.6275 - val_auc: 0.6275 - 6s/epoch - 81ms/step\n",
      "Epoch 6/100\n",
      "77/77 - 6s - loss: 0.1075 - accuracy: 0.9642 - auc: 0.9938 - val_loss: 3.0565 - val_accuracy: 0.6275 - val_auc: 0.6275 - 6s/epoch - 81ms/step\n",
      "Epoch 7/100\n",
      "77/77 - 6s - loss: 0.1367 - accuracy: 0.9544 - auc: 0.9886 - val_loss: 2.4163 - val_accuracy: 0.6275 - val_auc: 0.6275 - 6s/epoch - 81ms/step\n",
      "Epoch 8/100\n",
      "77/77 - 6s - loss: 0.0950 - accuracy: 0.9707 - auc: 0.9940 - val_loss: 0.9005 - val_accuracy: 0.6275 - val_auc: 0.8439 - 6s/epoch - 82ms/step\n",
      "Epoch 9/100\n",
      "77/77 - 6s - loss: 0.1263 - accuracy: 0.9495 - auc: 0.9899 - val_loss: 1.3709 - val_accuracy: 0.6275 - val_auc: 0.8585 - 6s/epoch - 82ms/step\n",
      "Epoch 10/100\n",
      "77/77 - 6s - loss: 0.0908 - accuracy: 0.9723 - auc: 0.9960 - val_loss: 0.4304 - val_accuracy: 0.7843 - val_auc: 0.9200 - 6s/epoch - 82ms/step\n",
      "Epoch 11/100\n",
      "77/77 - 6s - loss: 0.0766 - accuracy: 0.9707 - auc: 0.9963 - val_loss: 0.5082 - val_accuracy: 0.8431 - val_auc: 0.9204 - 6s/epoch - 82ms/step\n",
      "Epoch 12/100\n",
      "77/77 - 6s - loss: 0.1326 - accuracy: 0.9528 - auc: 0.9895 - val_loss: 0.0813 - val_accuracy: 0.9608 - val_auc: 0.9969 - 6s/epoch - 82ms/step\n",
      "Epoch 13/100\n",
      "77/77 - 6s - loss: 0.1023 - accuracy: 0.9658 - auc: 0.9943 - val_loss: 0.6236 - val_accuracy: 0.7647 - val_auc: 0.8620 - 6s/epoch - 81ms/step\n",
      "Epoch 14/100\n",
      "77/77 - 6s - loss: 0.0674 - accuracy: 0.9707 - auc: 0.9972 - val_loss: 2.5005 - val_accuracy: 0.5882 - val_auc: 0.6196 - 6s/epoch - 82ms/step\n",
      "Epoch 15/100\n",
      "77/77 - 6s - loss: 0.0758 - accuracy: 0.9739 - auc: 0.9971 - val_loss: 0.0781 - val_accuracy: 0.9608 - val_auc: 0.9969 - 6s/epoch - 82ms/step\n",
      "Epoch 16/100\n",
      "77/77 - 6s - loss: 0.0509 - accuracy: 0.9870 - auc: 0.9973 - val_loss: 0.3526 - val_accuracy: 0.8235 - val_auc: 0.9287 - 6s/epoch - 82ms/step\n",
      "Epoch 17/100\n",
      "77/77 - 6s - loss: 0.0660 - accuracy: 0.9805 - auc: 0.9978 - val_loss: 12.0835 - val_accuracy: 0.5686 - val_auc: 0.5517 - 6s/epoch - 82ms/step\n",
      "Epoch 18/100\n",
      "77/77 - 6s - loss: 0.0433 - accuracy: 0.9902 - auc: 0.9989 - val_loss: 0.0753 - val_accuracy: 0.9608 - val_auc: 0.9977 - 6s/epoch - 82ms/step\n",
      "Epoch 19/100\n",
      "77/77 - 6s - loss: 0.0153 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000 - val_auc: 1.0000 - 6s/epoch - 82ms/step\n",
      "Epoch 20/100\n",
      "77/77 - 6s - loss: 0.0440 - accuracy: 0.9837 - auc: 0.9991 - val_loss: 0.1798 - val_accuracy: 0.9216 - val_auc: 0.9850 - 6s/epoch - 82ms/step\n",
      "Epoch 21/100\n",
      "77/77 - 6s - loss: 0.0522 - accuracy: 0.9837 - auc: 0.9983 - val_loss: 0.4121 - val_accuracy: 0.8431 - val_auc: 0.9220 - 6s/epoch - 82ms/step\n",
      "Epoch 22/100\n",
      "77/77 - 6s - loss: 0.0825 - accuracy: 0.9674 - auc: 0.9959 - val_loss: 0.7011 - val_accuracy: 0.7843 - val_auc: 0.8750 - 6s/epoch - 83ms/step\n",
      "Epoch 23/100\n",
      "77/77 - 7s - loss: 0.0272 - accuracy: 0.9951 - auc: 0.9996 - val_loss: 8.5386 - val_accuracy: 0.5490 - val_auc: 0.5513 - 7s/epoch - 86ms/step\n",
      "Epoch 24/100\n",
      "77/77 - 7s - loss: 0.0664 - accuracy: 0.9837 - auc: 0.9960 - val_loss: 0.2541 - val_accuracy: 0.8824 - val_auc: 0.9592 - 7s/epoch - 91ms/step\n",
      "Epoch 25/100\n",
      "77/77 - 7s - loss: 0.0461 - accuracy: 0.9853 - auc: 0.9987 - val_loss: 0.2049 - val_accuracy: 0.9216 - val_auc: 0.9831 - 7s/epoch - 91ms/step\n",
      "Epoch 26/100\n",
      "77/77 - 7s - loss: 0.0637 - accuracy: 0.9788 - auc: 0.9974 - val_loss: 0.3227 - val_accuracy: 0.8824 - val_auc: 0.9550 - 7s/epoch - 91ms/step\n",
      "Epoch 27/100\n",
      "77/77 - 7s - loss: 0.0667 - accuracy: 0.9788 - auc: 0.9960 - val_loss: 0.1492 - val_accuracy: 0.9608 - val_auc: 0.9846 - 7s/epoch - 91ms/step\n",
      "Epoch 28/100\n",
      "77/77 - 7s - loss: 0.0548 - accuracy: 0.9805 - auc: 0.9984 - val_loss: 0.0442 - val_accuracy: 0.9804 - val_auc: 0.9996 - 7s/epoch - 91ms/step\n",
      "Epoch 29/100\n",
      "77/77 - 7s - loss: 0.0415 - accuracy: 0.9870 - auc: 0.9993 - val_loss: 0.1125 - val_accuracy: 0.9608 - val_auc: 0.9923 - 7s/epoch - 91ms/step\n",
      "Epoch 30/100\n",
      "77/77 - 7s - loss: 0.0577 - accuracy: 0.9837 - auc: 0.9975 - val_loss: 0.0620 - val_accuracy: 0.9804 - val_auc: 0.9988 - 7s/epoch - 91ms/step\n",
      "Epoch 31/100\n",
      "77/77 - 7s - loss: 0.0654 - accuracy: 0.9707 - auc: 0.9976 - val_loss: 1.1730 - val_accuracy: 0.7059 - val_auc: 0.8062 - 7s/epoch - 92ms/step\n",
      "Epoch 32/100\n",
      "77/77 - 7s - loss: 0.0458 - accuracy: 0.9837 - auc: 0.9989 - val_loss: 0.1284 - val_accuracy: 0.9412 - val_auc: 0.9950 - 7s/epoch - 92ms/step\n",
      "Epoch 33/100\n",
      "77/77 - 7s - loss: 0.0674 - accuracy: 0.9772 - auc: 0.9972 - val_loss: 0.4961 - val_accuracy: 0.7647 - val_auc: 0.8943 - 7s/epoch - 92ms/step\n",
      "Epoch 34/100\n",
      "77/77 - 7s - loss: 0.0210 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 0.2676 - val_accuracy: 0.9020 - val_auc: 0.9758 - 7s/epoch - 92ms/step\n",
      "Epoch 35/100\n",
      "77/77 - 7s - loss: 0.0736 - accuracy: 0.9756 - auc: 0.9949 - val_loss: 0.0218 - val_accuracy: 1.0000 - val_auc: 1.0000 - 7s/epoch - 92ms/step\n",
      "Epoch 36/100\n",
      "77/77 - 7s - loss: 0.0474 - accuracy: 0.9788 - auc: 0.9989 - val_loss: 0.6338 - val_accuracy: 0.8235 - val_auc: 0.9100 - 7s/epoch - 92ms/step\n",
      "Epoch 37/100\n",
      "77/77 - 8s - loss: 0.0374 - accuracy: 0.9870 - auc: 0.9991 - val_loss: 0.1706 - val_accuracy: 0.9216 - val_auc: 0.9842 - 8s/epoch - 101ms/step\n",
      "Epoch 38/100\n",
      "77/77 - 7s - loss: 0.0629 - accuracy: 0.9772 - auc: 0.9967 - val_loss: 1.3191 - val_accuracy: 0.7059 - val_auc: 0.7978 - 7s/epoch - 97ms/step\n",
      "Epoch 39/100\n",
      "77/77 - 8s - loss: 0.0431 - accuracy: 0.9821 - auc: 0.9988 - val_loss: 0.0452 - val_accuracy: 0.9804 - val_auc: 0.9988 - 8s/epoch - 98ms/step\n",
      "Epoch 40/100\n",
      "77/77 - 8s - loss: 0.0189 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.1706 - val_accuracy: 0.9608 - val_auc: 0.9915 - 8s/epoch - 109ms/step\n",
      "Epoch 41/100\n",
      "77/77 - 8s - loss: 0.0639 - accuracy: 0.9788 - auc: 0.9967 - val_loss: 0.1491 - val_accuracy: 0.9412 - val_auc: 0.9889 - 8s/epoch - 106ms/step\n",
      "Epoch 42/100\n",
      "77/77 - 8s - loss: 0.0293 - accuracy: 0.9951 - auc: 0.9996 - val_loss: 0.1229 - val_accuracy: 0.9412 - val_auc: 0.9896 - 8s/epoch - 104ms/step\n",
      "Epoch 43/100\n",
      "77/77 - 9s - loss: 0.0530 - accuracy: 0.9870 - auc: 0.9973 - val_loss: 0.0934 - val_accuracy: 0.9804 - val_auc: 0.9965 - 9s/epoch - 112ms/step\n",
      "Epoch 44/100\n",
      "77/77 - 8s - loss: 0.0477 - accuracy: 0.9837 - auc: 0.9977 - val_loss: 0.3790 - val_accuracy: 0.8627 - val_auc: 0.9396 - 8s/epoch - 109ms/step\n",
      "Epoch 45/100\n",
      "77/77 - 8s - loss: 0.0444 - accuracy: 0.9886 - auc: 0.9985 - val_loss: 0.0465 - val_accuracy: 0.9804 - val_auc: 0.9996 - 8s/epoch - 105ms/step\n",
      "Epoch 46/100\n",
      "77/77 - 9s - loss: 0.0578 - accuracy: 0.9886 - auc: 0.9949 - val_loss: 0.0104 - val_accuracy: 1.0000 - val_auc: 1.0000 - 9s/epoch - 113ms/step\n",
      "Epoch 47/100\n",
      "77/77 - 8s - loss: 0.0319 - accuracy: 0.9821 - auc: 0.9995 - val_loss: 0.3873 - val_accuracy: 0.8824 - val_auc: 0.9491 - 8s/epoch - 105ms/step\n",
      "Epoch 48/100\n",
      "77/77 - 8s - loss: 0.0123 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 0.4461 - val_accuracy: 0.8627 - val_auc: 0.9362 - 8s/epoch - 108ms/step\n",
      "Epoch 49/100\n",
      "77/77 - 8s - loss: 0.0264 - accuracy: 0.9902 - auc: 0.9997 - val_loss: 0.0538 - val_accuracy: 1.0000 - val_auc: 1.0000 - 8s/epoch - 107ms/step\n",
      "Epoch 50/100\n",
      "77/77 - 9s - loss: 0.0936 - accuracy: 0.9674 - auc: 0.9921 - val_loss: 0.3905 - val_accuracy: 0.7843 - val_auc: 0.9146 - 9s/epoch - 123ms/step\n",
      "Epoch 51/100\n",
      "77/77 - 9s - loss: 0.0225 - accuracy: 0.9919 - auc: 0.9998 - val_loss: 0.0984 - val_accuracy: 0.9608 - val_auc: 0.9977 - 9s/epoch - 118ms/step\n",
      "Epoch 52/100\n",
      "77/77 - 9s - loss: 0.0402 - accuracy: 0.9870 - auc: 0.9975 - val_loss: 0.8894 - val_accuracy: 0.7647 - val_auc: 0.8393 - 9s/epoch - 112ms/step\n",
      "Epoch 53/100\n",
      "77/77 - 9s - loss: 0.0342 - accuracy: 0.9902 - auc: 0.9993 - val_loss: 0.0464 - val_accuracy: 0.9804 - val_auc: 0.9996 - 9s/epoch - 122ms/step\n",
      "Epoch 54/100\n",
      "77/77 - 9s - loss: 0.0414 - accuracy: 0.9886 - auc: 0.9986 - val_loss: 0.0640 - val_accuracy: 0.9804 - val_auc: 0.9988 - 9s/epoch - 119ms/step\n",
      "Epoch 55/100\n",
      "77/77 - 9s - loss: 0.0303 - accuracy: 0.9902 - auc: 0.9997 - val_loss: 0.0487 - val_accuracy: 0.9804 - val_auc: 0.9988 - 9s/epoch - 122ms/step\n",
      "Epoch 56/100\n",
      "77/77 - 9s - loss: 0.0099 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9412 - val_auc: 0.9773 - 9s/epoch - 122ms/step\n",
      "Epoch 57/100\n",
      "77/77 - 9s - loss: 0.0399 - accuracy: 0.9935 - auc: 0.9959 - val_loss: 0.0707 - val_accuracy: 0.9608 - val_auc: 0.9985 - 9s/epoch - 122ms/step\n",
      "Epoch 58/100\n",
      "77/77 - 9s - loss: 0.0178 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.0988 - val_accuracy: 0.9608 - val_auc: 0.9958 - 9s/epoch - 121ms/step\n",
      "Epoch 59/100\n",
      "77/77 - 9s - loss: 0.0175 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.2642 - val_accuracy: 0.9412 - val_auc: 0.9685 - 9s/epoch - 113ms/step\n",
      "Epoch 60/100\n",
      "77/77 - 9s - loss: 0.0292 - accuracy: 0.9870 - auc: 0.9995 - val_loss: 0.4175 - val_accuracy: 0.9216 - val_auc: 0.9439 - 9s/epoch - 112ms/step\n",
      "Epoch 61/100\n",
      "77/77 - 9s - loss: 0.0054 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.0283 - val_accuracy: 1.0000 - val_auc: 1.0000 - 9s/epoch - 118ms/step\n",
      "Epoch 62/100\n",
      "77/77 - 9s - loss: 0.0233 - accuracy: 0.9902 - auc: 0.9997 - val_loss: 0.0197 - val_accuracy: 1.0000 - val_auc: 1.0000 - 9s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "77/77 - 9s - loss: 0.0565 - accuracy: 0.9853 - auc: 0.9972 - val_loss: 0.5714 - val_accuracy: 0.8824 - val_auc: 0.9239 - 9s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "77/77 - 9s - loss: 0.0573 - accuracy: 0.9756 - auc: 0.9981 - val_loss: 0.0582 - val_accuracy: 0.9608 - val_auc: 0.9985 - 9s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "77/77 - 10s - loss: 0.0353 - accuracy: 0.9886 - auc: 0.9992 - val_loss: 0.0288 - val_accuracy: 1.0000 - val_auc: 1.0000 - 10s/epoch - 126ms/step\n",
      "Epoch 66/100\n",
      "77/77 - 10s - loss: 0.0360 - accuracy: 0.9837 - auc: 0.9994 - val_loss: 0.0608 - val_accuracy: 0.9608 - val_auc: 0.9985 - 10s/epoch - 130ms/step\n",
      "Epoch 67/100\n",
      "77/77 - 10s - loss: 0.0195 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.1529 - val_accuracy: 0.9608 - val_auc: 0.9908 - 10s/epoch - 130ms/step\n",
      "Epoch 68/100\n",
      "77/77 - 10s - loss: 0.0165 - accuracy: 0.9919 - auc: 0.9999 - val_loss: 0.0671 - val_accuracy: 0.9608 - val_auc: 0.9969 - 10s/epoch - 129ms/step\n",
      "Epoch 69/100\n",
      "77/77 - 9s - loss: 0.0250 - accuracy: 0.9935 - auc: 0.9994 - val_loss: 1.2383 - val_accuracy: 0.8039 - val_auc: 0.8397 - 9s/epoch - 117ms/step\n",
      "Epoch 70/100\n",
      "77/77 - 9s - loss: 0.0259 - accuracy: 0.9935 - auc: 0.9996 - val_loss: 0.0515 - val_accuracy: 0.9804 - val_auc: 0.9988 - 9s/epoch - 119ms/step\n",
      "Epoch 71/100\n",
      "77/77 - 9s - loss: 0.0227 - accuracy: 0.9935 - auc: 0.9997 - val_loss: 0.0218 - val_accuracy: 1.0000 - val_auc: 1.0000 - 9s/epoch - 120ms/step\n",
      "Epoch 72/100\n",
      "77/77 - 9s - loss: 0.0774 - accuracy: 0.9805 - auc: 0.9952 - val_loss: 0.1843 - val_accuracy: 0.9216 - val_auc: 0.9877 - 9s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "77/77 - 9s - loss: 0.0384 - accuracy: 0.9870 - auc: 0.9990 - val_loss: 1.0865 - val_accuracy: 0.7647 - val_auc: 0.8497 - 9s/epoch - 122ms/step\n",
      "Epoch 74/100\n",
      "77/77 - 9s - loss: 0.0602 - accuracy: 0.9853 - auc: 0.9950 - val_loss: 0.1090 - val_accuracy: 0.9608 - val_auc: 0.9931 - 9s/epoch - 122ms/step\n",
      "Epoch 75/100\n",
      "77/77 - 9s - loss: 0.0334 - accuracy: 0.9853 - auc: 0.9994 - val_loss: 0.0706 - val_accuracy: 0.9608 - val_auc: 0.9985 - 9s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "77/77 - 9s - loss: 0.0177 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 0.3446 - val_accuracy: 0.9020 - val_auc: 0.9485 - 9s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "77/77 - 9s - loss: 0.0157 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.0383 - val_accuracy: 0.9804 - val_auc: 0.9996 - 9s/epoch - 123ms/step\n",
      "Epoch 78/100\n",
      "77/77 - 9s - loss: 0.0101 - accuracy: 0.9951 - auc: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9608 - val_auc: 0.9937 - 9s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "77/77 - 9s - loss: 0.0391 - accuracy: 0.9886 - auc: 0.9976 - val_loss: 0.6024 - val_accuracy: 0.8627 - val_auc: 0.9246 - 9s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "77/77 - 10s - loss: 0.0293 - accuracy: 0.9919 - auc: 0.9995 - val_loss: 0.4582 - val_accuracy: 0.8824 - val_auc: 0.9377 - 10s/epoch - 128ms/step\n",
      "Epoch 81/100\n",
      "77/77 - 10s - loss: 0.0141 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.0361 - val_accuracy: 1.0000 - val_auc: 1.0000 - 10s/epoch - 127ms/step\n",
      "Epoch 82/100\n",
      "77/77 - 10s - loss: 0.0169 - accuracy: 0.9935 - auc: 0.9998 - val_loss: 0.4906 - val_accuracy: 0.8431 - val_auc: 0.9323 - 10s/epoch - 135ms/step\n",
      "Epoch 83/100\n",
      "77/77 - 10s - loss: 0.0213 - accuracy: 0.9902 - auc: 0.9998 - val_loss: 1.0318 - val_accuracy: 0.8039 - val_auc: 0.8643 - 10s/epoch - 135ms/step\n",
      "Epoch 84/100\n",
      "77/77 - 9s - loss: 0.0380 - accuracy: 0.9919 - auc: 0.9974 - val_loss: 0.0757 - val_accuracy: 0.9608 - val_auc: 0.9962 - 9s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "77/77 - 9s - loss: 0.0119 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 0.2748 - val_accuracy: 0.8824 - val_auc: 0.9575 - 9s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "77/77 - 9s - loss: 0.0045 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9608 - val_auc: 0.9977 - 9s/epoch - 123ms/step\n",
      "Epoch 87/100\n",
      "77/77 - 10s - loss: 0.0060 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2035 - val_accuracy: 0.9608 - val_auc: 0.9881 - 10s/epoch - 129ms/step\n",
      "Epoch 88/100\n",
      "77/77 - 10s - loss: 0.0074 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000 - val_auc: 1.0000 - 10s/epoch - 126ms/step\n",
      "Epoch 89/100\n",
      "77/77 - 10s - loss: 0.0200 - accuracy: 0.9919 - auc: 0.9998 - val_loss: 0.7345 - val_accuracy: 0.7843 - val_auc: 0.8941 - 10s/epoch - 128ms/step\n",
      "Epoch 90/100\n",
      "77/77 - 10s - loss: 0.0204 - accuracy: 0.9902 - auc: 0.9997 - val_loss: 0.2727 - val_accuracy: 0.8824 - val_auc: 0.9639 - 10s/epoch - 127ms/step\n",
      "Epoch 91/100\n",
      "77/77 - 10s - loss: 0.0249 - accuracy: 0.9902 - auc: 0.9996 - val_loss: 0.5771 - val_accuracy: 0.8235 - val_auc: 0.9064 - 10s/epoch - 127ms/step\n",
      "Epoch 92/100\n",
      "77/77 - 10s - loss: 0.0332 - accuracy: 0.9902 - auc: 0.9979 - val_loss: 1.3175 - val_accuracy: 0.7843 - val_auc: 0.8343 - 10s/epoch - 133ms/step\n",
      "Epoch 93/100\n",
      "77/77 - 11s - loss: 0.0176 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.1616 - val_accuracy: 0.9608 - val_auc: 0.9908 - 11s/epoch - 145ms/step\n",
      "Epoch 94/100\n",
      "77/77 - 11s - loss: 0.0223 - accuracy: 0.9967 - auc: 0.9980 - val_loss: 2.1813 - val_accuracy: 0.6863 - val_auc: 0.7186 - 11s/epoch - 142ms/step\n",
      "Epoch 95/100\n",
      "77/77 - 11s - loss: 0.0140 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.0741 - val_accuracy: 0.9608 - val_auc: 0.9977 - 11s/epoch - 141ms/step\n",
      "Epoch 96/100\n",
      "77/77 - 11s - loss: 0.0620 - accuracy: 0.9821 - auc: 0.9965 - val_loss: 0.8747 - val_accuracy: 0.8039 - val_auc: 0.8931 - 11s/epoch - 138ms/step\n",
      "Epoch 97/100\n",
      "77/77 - 11s - loss: 0.0409 - accuracy: 0.9870 - auc: 0.9975 - val_loss: 0.7828 - val_accuracy: 0.8039 - val_auc: 0.8885 - 11s/epoch - 137ms/step\n",
      "Epoch 98/100\n",
      "77/77 - 10s - loss: 0.0314 - accuracy: 0.9935 - auc: 0.9992 - val_loss: 0.6437 - val_accuracy: 0.8431 - val_auc: 0.9146 - 10s/epoch - 124ms/step\n",
      "Epoch 99/100\n",
      "77/77 - 9s - loss: 0.0806 - accuracy: 0.9723 - auc: 0.9939 - val_loss: 0.4448 - val_accuracy: 0.8431 - val_auc: 0.9239 - 9s/epoch - 123ms/step\n",
      "Epoch 100/100\n",
      "77/77 - 10s - loss: 0.0404 - accuracy: 0.9870 - auc: 0.9989 - val_loss: 0.0540 - val_accuracy: 0.9804 - val_auc: 0.9996 - 10s/epoch - 126ms/step\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d2c6b412520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00        51\n",
      "   macro avg       1.00      1.00      1.00        51\n",
      "weighted avg       1.00      1.00      1.00        51\n",
      "\n",
      "Roc 1.0\n",
      "Confusion Matrix\n",
      "[[19  0]\n",
      " [ 0 32]]\n",
      "minority class [1.]\n",
      "minority people 20\n",
      "y size 0\n",
      "other size 682\n",
      "['Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'Giovanni N', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'PORCELLI A', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto L', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'Roberto R', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4079609347.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 - 12s - loss: 0.5105 - accuracy: 0.7689 - auc: 0.8423 - val_loss: 0.7038 - val_accuracy: 0.4286 - val_auc: 0.4286 - 12s/epoch - 197ms/step\n",
      "Epoch 2/100\n",
      "63/63 - 7s - loss: 0.3665 - accuracy: 0.8446 - auc: 0.9174 - val_loss: 0.6860 - val_accuracy: 0.5714 - val_auc: 0.6489 - 7s/epoch - 114ms/step\n",
      "Epoch 3/100\n",
      "63/63 - 8s - loss: 0.2463 - accuracy: 0.8964 - auc: 0.9636 - val_loss: 1.2828 - val_accuracy: 0.4286 - val_auc: 0.5051 - 8s/epoch - 126ms/step\n",
      "Epoch 4/100\n",
      "63/63 - 8s - loss: 0.1799 - accuracy: 0.9323 - auc: 0.9831 - val_loss: 0.7158 - val_accuracy: 0.5714 - val_auc: 0.6658 - 8s/epoch - 134ms/step\n",
      "Epoch 5/100\n",
      "63/63 - 8s - loss: 0.1745 - accuracy: 0.9462 - auc: 0.9825 - val_loss: 0.6824 - val_accuracy: 0.5357 - val_auc: 0.6257 - 8s/epoch - 134ms/step\n",
      "Epoch 6/100\n",
      "63/63 - 8s - loss: 0.1093 - accuracy: 0.9701 - auc: 0.9946 - val_loss: 2.6780 - val_accuracy: 0.4286 - val_auc: 0.5244 - 8s/epoch - 134ms/step\n",
      "Epoch 7/100\n",
      "63/63 - 9s - loss: 0.1429 - accuracy: 0.9502 - auc: 0.9858 - val_loss: 0.5975 - val_accuracy: 0.8214 - val_auc: 0.8950 - 9s/epoch - 135ms/step\n",
      "Epoch 8/100\n",
      "63/63 - 8s - loss: 0.1295 - accuracy: 0.9343 - auc: 0.9907 - val_loss: 0.6362 - val_accuracy: 0.5714 - val_auc: 0.7476 - 8s/epoch - 135ms/step\n",
      "Epoch 9/100\n",
      "63/63 - 9s - loss: 0.1304 - accuracy: 0.9542 - auc: 0.9894 - val_loss: 0.6376 - val_accuracy: 0.5982 - val_auc: 0.7176 - 9s/epoch - 136ms/step\n",
      "Epoch 10/100\n",
      "63/63 - 9s - loss: 0.0775 - accuracy: 0.9721 - auc: 0.9976 - val_loss: 0.6984 - val_accuracy: 0.5982 - val_auc: 0.7018 - 9s/epoch - 136ms/step\n",
      "Epoch 11/100\n",
      "63/63 - 9s - loss: 0.0578 - accuracy: 0.9841 - auc: 0.9981 - val_loss: 0.3123 - val_accuracy: 0.8482 - val_auc: 0.9422 - 9s/epoch - 136ms/step\n",
      "Epoch 12/100\n",
      "63/63 - 8s - loss: 0.0785 - accuracy: 0.9801 - auc: 0.9962 - val_loss: 0.2998 - val_accuracy: 0.8929 - val_auc: 0.9475 - 8s/epoch - 135ms/step\n",
      "Epoch 13/100\n",
      "63/63 - 9s - loss: 0.1043 - accuracy: 0.9602 - auc: 0.9952 - val_loss: 0.1636 - val_accuracy: 0.9286 - val_auc: 0.9855 - 9s/epoch - 144ms/step\n",
      "Epoch 14/100\n",
      "63/63 - 9s - loss: 0.0744 - accuracy: 0.9821 - auc: 0.9979 - val_loss: 0.1515 - val_accuracy: 0.9375 - val_auc: 0.9892 - 9s/epoch - 137ms/step\n",
      "Epoch 15/100\n",
      "63/63 - 9s - loss: 0.0700 - accuracy: 0.9761 - auc: 0.9982 - val_loss: 0.8903 - val_accuracy: 0.7857 - val_auc: 0.8518 - 9s/epoch - 137ms/step\n",
      "Epoch 16/100\n",
      "63/63 - 9s - loss: 0.0609 - accuracy: 0.9781 - auc: 0.9981 - val_loss: 1.4167 - val_accuracy: 0.6429 - val_auc: 0.7598 - 9s/epoch - 137ms/step\n",
      "Epoch 17/100\n",
      "63/63 - 9s - loss: 0.0328 - accuracy: 0.9960 - auc: 0.9998 - val_loss: 0.1008 - val_accuracy: 0.9464 - val_auc: 0.9942 - 9s/epoch - 138ms/step\n",
      "Epoch 18/100\n",
      "63/63 - 9s - loss: 0.0555 - accuracy: 0.9841 - auc: 0.9987 - val_loss: 0.1188 - val_accuracy: 0.9554 - val_auc: 0.9921 - 9s/epoch - 137ms/step\n",
      "Epoch 19/100\n",
      "63/63 - 9s - loss: 0.0477 - accuracy: 0.9781 - auc: 0.9988 - val_loss: 1.3568 - val_accuracy: 0.7143 - val_auc: 0.7849 - 9s/epoch - 150ms/step\n",
      "Epoch 20/100\n",
      "63/63 - 9s - loss: 0.0475 - accuracy: 0.9880 - auc: 0.9994 - val_loss: 1.3022 - val_accuracy: 0.7500 - val_auc: 0.7820 - 9s/epoch - 150ms/step\n",
      "Epoch 21/100\n",
      "63/63 - 9s - loss: 0.0511 - accuracy: 0.9821 - auc: 0.9992 - val_loss: 2.4831 - val_accuracy: 0.5804 - val_auc: 0.6852 - 9s/epoch - 139ms/step\n",
      "Epoch 22/100\n",
      "63/63 - 9s - loss: 0.0321 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9821 - val_auc: 0.9987 - 9s/epoch - 139ms/step\n",
      "Epoch 23/100\n",
      "63/63 - 9s - loss: 0.0227 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.2362 - val_accuracy: 0.8839 - val_auc: 0.9750 - 9s/epoch - 138ms/step\n",
      "Epoch 24/100\n",
      "63/63 - 9s - loss: 0.0572 - accuracy: 0.9821 - auc: 0.9984 - val_loss: 0.1755 - val_accuracy: 0.9196 - val_auc: 0.9834 - 9s/epoch - 138ms/step\n",
      "Epoch 25/100\n",
      "63/63 - 9s - loss: 0.0834 - accuracy: 0.9701 - auc: 0.9935 - val_loss: 0.0775 - val_accuracy: 0.9732 - val_auc: 0.9982 - 9s/epoch - 138ms/step\n",
      "Epoch 26/100\n",
      "63/63 - 9s - loss: 0.1255 - accuracy: 0.9562 - auc: 0.9898 - val_loss: 0.9595 - val_accuracy: 0.7857 - val_auc: 0.8650 - 9s/epoch - 139ms/step\n",
      "Epoch 27/100\n",
      "63/63 - 9s - loss: 0.0292 - accuracy: 0.9920 - auc: 0.9999 - val_loss: 0.0657 - val_accuracy: 0.9732 - val_auc: 0.9985 - 9s/epoch - 150ms/step\n",
      "Epoch 28/100\n",
      "63/63 - 9s - loss: 0.0289 - accuracy: 0.9920 - auc: 0.9998 - val_loss: 0.8197 - val_accuracy: 0.8214 - val_auc: 0.8773 - 9s/epoch - 149ms/step\n",
      "Epoch 29/100\n",
      "63/63 - 9s - loss: 0.0453 - accuracy: 0.9821 - auc: 0.9989 - val_loss: 0.3884 - val_accuracy: 0.8482 - val_auc: 0.9443 - 9s/epoch - 148ms/step\n",
      "Epoch 30/100\n",
      "63/63 - 9s - loss: 0.0329 - accuracy: 0.9900 - auc: 0.9995 - val_loss: 0.0791 - val_accuracy: 0.9732 - val_auc: 0.9966 - 9s/epoch - 148ms/step\n",
      "Epoch 31/100\n",
      "63/63 - 9s - loss: 0.0415 - accuracy: 0.9880 - auc: 0.9988 - val_loss: 5.6795 - val_accuracy: 0.5804 - val_auc: 0.6042 - 9s/epoch - 148ms/step\n",
      "Epoch 32/100\n",
      "63/63 - 9s - loss: 0.0292 - accuracy: 0.9900 - auc: 0.9999 - val_loss: 0.1389 - val_accuracy: 0.9286 - val_auc: 0.9886 - 9s/epoch - 148ms/step\n",
      "Epoch 33/100\n",
      "63/63 - 9s - loss: 0.0481 - accuracy: 0.9861 - auc: 0.9969 - val_loss: 2.0731 - val_accuracy: 0.7589 - val_auc: 0.7792 - 9s/epoch - 148ms/step\n",
      "Epoch 34/100\n",
      "63/63 - 9s - loss: 0.0260 - accuracy: 0.9940 - auc: 0.9998 - val_loss: 0.2157 - val_accuracy: 0.8929 - val_auc: 0.9755 - 9s/epoch - 148ms/step\n",
      "Epoch 35/100\n",
      "63/63 - 9s - loss: 0.0446 - accuracy: 0.9821 - auc: 0.9989 - val_loss: 3.0912 - val_accuracy: 0.6250 - val_auc: 0.6987 - 9s/epoch - 145ms/step\n",
      "Epoch 36/100\n",
      "63/63 - 10s - loss: 0.0417 - accuracy: 0.9841 - auc: 0.9993 - val_loss: 0.1092 - val_accuracy: 0.9375 - val_auc: 0.9919 - 10s/epoch - 154ms/step\n",
      "Epoch 37/100\n",
      "63/63 - 10s - loss: 0.0277 - accuracy: 0.9920 - auc: 0.9995 - val_loss: 0.0642 - val_accuracy: 0.9821 - val_auc: 0.9981 - 10s/epoch - 155ms/step\n",
      "Epoch 38/100\n",
      "63/63 - 9s - loss: 0.0331 - accuracy: 0.9940 - auc: 0.9985 - val_loss: 0.9960 - val_accuracy: 0.7321 - val_auc: 0.8123 - 9s/epoch - 146ms/step\n",
      "Epoch 39/100\n",
      "63/63 - 8s - loss: 0.0151 - accuracy: 0.9980 - auc: 0.9999 - val_loss: 0.1365 - val_accuracy: 0.9196 - val_auc: 0.9876 - 8s/epoch - 129ms/step\n",
      "Epoch 40/100\n",
      "63/63 - 10s - loss: 0.0111 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9732 - val_auc: 0.9975 - 10s/epoch - 155ms/step\n",
      "Epoch 41/100\n",
      "63/63 - 10s - loss: 0.0800 - accuracy: 0.9701 - auc: 0.9947 - val_loss: 1.2878 - val_accuracy: 0.7321 - val_auc: 0.7856 - 10s/epoch - 152ms/step\n",
      "Epoch 42/100\n",
      "63/63 - 9s - loss: 0.0511 - accuracy: 0.9741 - auc: 0.9985 - val_loss: 8.8334 - val_accuracy: 0.5625 - val_auc: 0.5596 - 9s/epoch - 142ms/step\n",
      "Epoch 43/100\n",
      "63/63 - 9s - loss: 0.0159 - accuracy: 0.9980 - auc: 0.9999 - val_loss: 0.1708 - val_accuracy: 0.9107 - val_auc: 0.9839 - 9s/epoch - 141ms/step\n",
      "Epoch 44/100\n",
      "63/63 - 9s - loss: 0.0377 - accuracy: 0.9880 - auc: 0.9992 - val_loss: 3.7225 - val_accuracy: 0.5804 - val_auc: 0.6678 - 9s/epoch - 141ms/step\n",
      "Epoch 45/100\n",
      "63/63 - 9s - loss: 0.0344 - accuracy: 0.9960 - auc: 0.9975 - val_loss: 0.1158 - val_accuracy: 0.9464 - val_auc: 0.9925 - 9s/epoch - 142ms/step\n",
      "Epoch 46/100\n",
      "63/63 - 9s - loss: 0.0269 - accuracy: 0.9920 - auc: 0.9997 - val_loss: 0.0744 - val_accuracy: 0.9643 - val_auc: 0.9965 - 9s/epoch - 142ms/step\n",
      "Epoch 47/100\n",
      "63/63 - 9s - loss: 0.0635 - accuracy: 0.9821 - auc: 0.9962 - val_loss: 0.2552 - val_accuracy: 0.8839 - val_auc: 0.9697 - 9s/epoch - 143ms/step\n",
      "Epoch 48/100\n",
      "63/63 - 9s - loss: 0.0212 - accuracy: 0.9900 - auc: 0.9998 - val_loss: 0.1205 - val_accuracy: 0.9554 - val_auc: 0.9921 - 9s/epoch - 143ms/step\n",
      "Epoch 49/100\n",
      "63/63 - 9s - loss: 0.0230 - accuracy: 0.9940 - auc: 0.9996 - val_loss: 0.1098 - val_accuracy: 0.9375 - val_auc: 0.9921 - 9s/epoch - 150ms/step\n",
      "Epoch 50/100\n",
      "63/63 - 9s - loss: 0.0399 - accuracy: 0.9861 - auc: 0.9988 - val_loss: 0.6960 - val_accuracy: 0.8036 - val_auc: 0.8933 - 9s/epoch - 149ms/step\n",
      "Epoch 51/100\n",
      "63/63 - 9s - loss: 0.0339 - accuracy: 0.9880 - auc: 0.9993 - val_loss: 0.1516 - val_accuracy: 0.9286 - val_auc: 0.9877 - 9s/epoch - 149ms/step\n",
      "Epoch 52/100\n",
      "63/63 - 9s - loss: 0.0202 - accuracy: 0.9900 - auc: 0.9999 - val_loss: 0.1997 - val_accuracy: 0.8929 - val_auc: 0.9777 - 9s/epoch - 148ms/step\n",
      "Epoch 53/100\n",
      "63/63 - 9s - loss: 0.0076 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.1748 - val_accuracy: 0.9107 - val_auc: 0.9836 - 9s/epoch - 147ms/step\n",
      "Epoch 54/100\n",
      "63/63 - 9s - loss: 0.0086 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9732 - val_auc: 0.9955 - 9s/epoch - 148ms/step\n",
      "Epoch 55/100\n",
      "63/63 - 9s - loss: 0.0339 - accuracy: 0.9900 - auc: 0.9994 - val_loss: 1.1848 - val_accuracy: 0.7500 - val_auc: 0.8268 - 9s/epoch - 151ms/step\n",
      "Epoch 56/100\n",
      "63/63 - 9s - loss: 0.0147 - accuracy: 0.9960 - auc: 0.9999 - val_loss: 0.1432 - val_accuracy: 0.9464 - val_auc: 0.9888 - 9s/epoch - 146ms/step\n",
      "Epoch 57/100\n",
      "63/63 - 9s - loss: 0.0386 - accuracy: 0.9821 - auc: 0.9992 - val_loss: 1.4617 - val_accuracy: 0.7679 - val_auc: 0.8064 - 9s/epoch - 147ms/step\n",
      "Epoch 58/100\n",
      "63/63 - 9s - loss: 0.0122 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9821 - val_auc: 0.9957 - 9s/epoch - 149ms/step\n",
      "Epoch 59/100\n",
      "63/63 - 9s - loss: 0.0194 - accuracy: 0.9940 - auc: 0.9999 - val_loss: 7.4328 - val_accuracy: 0.5714 - val_auc: 0.5934 - 9s/epoch - 149ms/step\n",
      "Epoch 60/100\n",
      "63/63 - 9s - loss: 0.0507 - accuracy: 0.9880 - auc: 0.9970 - val_loss: 0.7391 - val_accuracy: 0.8125 - val_auc: 0.9090 - 9s/epoch - 149ms/step\n",
      "Epoch 61/100\n",
      "63/63 - 9s - loss: 0.0078 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9643 - val_auc: 0.9976 - 9s/epoch - 146ms/step\n",
      "Epoch 62/100\n",
      "63/63 - 9s - loss: 0.0230 - accuracy: 0.9940 - auc: 0.9996 - val_loss: 3.8319 - val_accuracy: 0.5982 - val_auc: 0.6742 - 9s/epoch - 144ms/step\n",
      "Epoch 63/100\n",
      "63/63 - 9s - loss: 0.0170 - accuracy: 0.9960 - auc: 0.9998 - val_loss: 0.1237 - val_accuracy: 0.9375 - val_auc: 0.9923 - 9s/epoch - 146ms/step\n",
      "Epoch 64/100\n",
      "63/63 - 9s - loss: 0.0056 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9196 - val_auc: 0.9807 - 9s/epoch - 147ms/step\n",
      "Epoch 65/100\n",
      "63/63 - 9s - loss: 0.0068 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9732 - val_auc: 0.9982 - 9s/epoch - 146ms/step\n",
      "Epoch 66/100\n",
      "63/63 - 9s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9554 - val_auc: 0.9951 - 9s/epoch - 146ms/step\n",
      "Epoch 67/100\n",
      "63/63 - 9s - loss: 0.0917 - accuracy: 0.9861 - auc: 0.9970 - val_loss: 0.1173 - val_accuracy: 0.9554 - val_auc: 0.9929 - 9s/epoch - 143ms/step\n",
      "Epoch 68/100\n",
      "63/63 - 9s - loss: 0.1132 - accuracy: 0.9761 - auc: 0.9894 - val_loss: 0.5639 - val_accuracy: 0.8482 - val_auc: 0.8976 - 9s/epoch - 148ms/step\n",
      "Epoch 69/100\n",
      "63/63 - 9s - loss: 0.0222 - accuracy: 0.9940 - auc: 0.9998 - val_loss: 0.1497 - val_accuracy: 0.9375 - val_auc: 0.9877 - 9s/epoch - 148ms/step\n",
      "Epoch 70/100\n",
      "63/63 - 9s - loss: 0.0696 - accuracy: 0.9781 - auc: 0.9959 - val_loss: 4.6602 - val_accuracy: 0.6250 - val_auc: 0.6588 - 9s/epoch - 136ms/step\n",
      "Epoch 71/100\n",
      "63/63 - 9s - loss: 0.0204 - accuracy: 0.9960 - auc: 0.9997 - val_loss: 0.4600 - val_accuracy: 0.8482 - val_auc: 0.9461 - 9s/epoch - 138ms/step\n",
      "Epoch 72/100\n",
      "63/63 - 9s - loss: 0.0212 - accuracy: 0.9940 - auc: 0.9998 - val_loss: 0.1496 - val_accuracy: 0.9464 - val_auc: 0.9883 - 9s/epoch - 137ms/step\n",
      "Epoch 73/100\n",
      "63/63 - 9s - loss: 0.0307 - accuracy: 0.9880 - auc: 0.9993 - val_loss: 0.2170 - val_accuracy: 0.9196 - val_auc: 0.9737 - 9s/epoch - 139ms/step\n",
      "Epoch 74/100\n",
      "63/63 - 10s - loss: 0.0260 - accuracy: 0.9900 - auc: 0.9997 - val_loss: 0.1114 - val_accuracy: 0.9375 - val_auc: 0.9931 - 10s/epoch - 156ms/step\n",
      "Epoch 75/100\n",
      "63/63 - 10s - loss: 0.0187 - accuracy: 0.9960 - auc: 0.9999 - val_loss: 0.1281 - val_accuracy: 0.9375 - val_auc: 0.9908 - 10s/epoch - 155ms/step\n",
      "Epoch 76/100\n",
      "63/63 - 10s - loss: 0.0118 - accuracy: 0.9980 - auc: 0.9999 - val_loss: 0.0757 - val_accuracy: 0.9643 - val_auc: 0.9963 - 10s/epoch - 156ms/step\n",
      "Epoch 77/100\n",
      "63/63 - 9s - loss: 0.0384 - accuracy: 0.9861 - auc: 0.9992 - val_loss: 0.2061 - val_accuracy: 0.9107 - val_auc: 0.9798 - 9s/epoch - 144ms/step\n",
      "Epoch 78/100\n",
      "63/63 - 9s - loss: 0.0159 - accuracy: 0.9940 - auc: 0.9999 - val_loss: 0.2884 - val_accuracy: 0.8750 - val_auc: 0.9674 - 9s/epoch - 142ms/step\n",
      "Epoch 79/100\n",
      "63/63 - 9s - loss: 0.0112 - accuracy: 0.9980 - auc: 0.9998 - val_loss: 1.7913 - val_accuracy: 0.7768 - val_auc: 0.8022 - 9s/epoch - 141ms/step\n",
      "Epoch 80/100\n",
      "63/63 - 9s - loss: 0.0306 - accuracy: 0.9841 - auc: 0.9994 - val_loss: 0.7366 - val_accuracy: 0.7768 - val_auc: 0.8894 - 9s/epoch - 141ms/step\n",
      "Epoch 81/100\n",
      "63/63 - 9s - loss: 0.0210 - accuracy: 0.9940 - auc: 0.9996 - val_loss: 0.2042 - val_accuracy: 0.9018 - val_auc: 0.9821 - 9s/epoch - 141ms/step\n",
      "Epoch 82/100\n",
      "63/63 - 9s - loss: 0.0209 - accuracy: 0.9900 - auc: 0.9998 - val_loss: 5.1012 - val_accuracy: 0.5625 - val_auc: 0.6189 - 9s/epoch - 141ms/step\n",
      "Epoch 83/100\n",
      "63/63 - 9s - loss: 0.0092 - accuracy: 0.9960 - auc: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9107 - val_auc: 0.9754 - 9s/epoch - 142ms/step\n",
      "Epoch 84/100\n",
      "63/63 - 9s - loss: 0.0047 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.8750 - val_auc: 0.9624 - 9s/epoch - 142ms/step\n",
      "Epoch 85/100\n",
      "63/63 - 9s - loss: 0.0099 - accuracy: 0.9980 - auc: 0.9999 - val_loss: 0.1239 - val_accuracy: 0.9375 - val_auc: 0.9909 - 9s/epoch - 142ms/step\n",
      "Epoch 86/100\n",
      "63/63 - 9s - loss: 0.0042 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9464 - val_auc: 0.9931 - 9s/epoch - 141ms/step\n",
      "Epoch 87/100\n",
      "63/63 - 9s - loss: 0.0063 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9643 - val_auc: 0.9963 - 9s/epoch - 142ms/step\n",
      "Epoch 88/100\n",
      "63/63 - 10s - loss: 0.0108 - accuracy: 0.9960 - auc: 1.0000 - val_loss: 2.9433 - val_accuracy: 0.7411 - val_auc: 0.7413 - 10s/epoch - 153ms/step\n",
      "Epoch 89/100\n",
      "63/63 - 10s - loss: 0.0156 - accuracy: 0.9940 - auc: 0.9999 - val_loss: 0.4369 - val_accuracy: 0.8750 - val_auc: 0.9416 - 10s/epoch - 163ms/step\n",
      "Epoch 90/100\n",
      "63/63 - 9s - loss: 0.0107 - accuracy: 0.9960 - auc: 1.0000 - val_loss: 1.2148 - val_accuracy: 0.8125 - val_auc: 0.8539 - 9s/epoch - 148ms/step\n",
      "Epoch 91/100\n",
      "63/63 - 9s - loss: 0.0103 - accuracy: 0.9960 - auc: 1.0000 - val_loss: 2.5592 - val_accuracy: 0.7143 - val_auc: 0.7369 - 9s/epoch - 137ms/step\n",
      "Epoch 92/100\n",
      "63/63 - 9s - loss: 0.0452 - accuracy: 0.9841 - auc: 0.9987 - val_loss: 0.4760 - val_accuracy: 0.8571 - val_auc: 0.9365 - 9s/epoch - 148ms/step\n",
      "Epoch 93/100\n",
      "63/63 - 9s - loss: 0.0366 - accuracy: 0.9861 - auc: 0.9992 - val_loss: 0.0803 - val_accuracy: 0.9821 - val_auc: 0.9957 - 9s/epoch - 150ms/step\n",
      "Epoch 94/100\n",
      "63/63 - 9s - loss: 0.0160 - accuracy: 0.9940 - auc: 0.9999 - val_loss: 0.9294 - val_accuracy: 0.7768 - val_auc: 0.8583 - 9s/epoch - 148ms/step\n",
      "Epoch 95/100\n",
      "63/63 - 9s - loss: 0.0096 - accuracy: 0.9960 - auc: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8482 - val_auc: 0.9476 - 9s/epoch - 149ms/step\n",
      "Epoch 96/100\n",
      "63/63 - 9s - loss: 0.0113 - accuracy: 0.9980 - auc: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.8929 - val_auc: 0.9725 - 9s/epoch - 148ms/step\n",
      "Epoch 97/100\n",
      "63/63 - 9s - loss: 0.0108 - accuracy: 0.9980 - auc: 0.9999 - val_loss: 0.2306 - val_accuracy: 0.9107 - val_auc: 0.9743 - 9s/epoch - 148ms/step\n",
      "Epoch 98/100\n",
      "63/63 - 9s - loss: 0.0531 - accuracy: 0.9861 - auc: 0.9965 - val_loss: 0.8308 - val_accuracy: 0.7321 - val_auc: 0.8208 - 9s/epoch - 147ms/step\n",
      "Epoch 99/100\n",
      "63/63 - 10s - loss: 0.1970 - accuracy: 0.9542 - auc: 0.9816 - val_loss: 9.4698 - val_accuracy: 0.6250 - val_auc: 0.6600 - 10s/epoch - 156ms/step\n",
      "Epoch 100/100\n",
      "63/63 - 10s - loss: 0.0237 - accuracy: 0.9940 - auc: 0.9996 - val_loss: 3.0586 - val_accuracy: 0.7411 - val_auc: 0.7693 - 10s/epoch - 154ms/step\n",
      "4/4 [==============================] - 1s 337ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        48\n",
      "           1       0.97      1.00      0.98        64\n",
      "\n",
      "    accuracy                           0.98       112\n",
      "   macro avg       0.98      0.98      0.98       112\n",
      "weighted avg       0.98      0.98      0.98       112\n",
      "\n",
      "Roc 0.9993489583333333\n",
      "Confusion Matrix\n",
      "[[46  2]\n",
      " [ 0 64]]\n",
      "minority class [1.]\n",
      "minority people 21\n",
      "y size 0\n",
      "other size 748\n",
      "['Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Lucia R', 'Domenico T', 'Domenico T', 'Domenico T', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'ANTONIETTA P', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A', 'VITO A']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4079609347.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "76/76 - 14s - loss: 0.5066 - accuracy: 0.7695 - auc: 0.8478 - val_loss: 0.6751 - val_accuracy: 0.6429 - val_auc: 0.6429 - 14s/epoch - 189ms/step\n",
      "Epoch 2/100\n",
      "76/76 - 9s - loss: 0.2446 - accuracy: 0.9005 - auc: 0.9634 - val_loss: 1.1815 - val_accuracy: 0.6429 - val_auc: 0.6429 - 9s/epoch - 117ms/step\n",
      "Epoch 3/100\n",
      "76/76 - 10s - loss: 0.2650 - accuracy: 0.8955 - auc: 0.9584 - val_loss: 0.7142 - val_accuracy: 0.6429 - val_auc: 0.7752 - 10s/epoch - 133ms/step\n",
      "Epoch 4/100\n",
      "76/76 - 10s - loss: 0.1541 - accuracy: 0.9403 - auc: 0.9861 - val_loss: 0.6995 - val_accuracy: 0.6429 - val_auc: 0.8100 - 10s/epoch - 134ms/step\n",
      "Epoch 5/100\n",
      "76/76 - 11s - loss: 0.1645 - accuracy: 0.9403 - auc: 0.9824 - val_loss: 0.8056 - val_accuracy: 0.4388 - val_auc: 0.5748 - 11s/epoch - 140ms/step\n",
      "Epoch 6/100\n",
      "76/76 - 11s - loss: 0.1353 - accuracy: 0.9536 - auc: 0.9877 - val_loss: 0.8543 - val_accuracy: 0.3776 - val_auc: 0.4957 - 11s/epoch - 141ms/step\n",
      "Epoch 7/100\n",
      "76/76 - 11s - loss: 0.1487 - accuracy: 0.9502 - auc: 0.9865 - val_loss: 1.1500 - val_accuracy: 0.6429 - val_auc: 0.8306 - 11s/epoch - 141ms/step\n",
      "Epoch 8/100\n",
      "76/76 - 11s - loss: 0.1346 - accuracy: 0.9453 - auc: 0.9880 - val_loss: 1.8538 - val_accuracy: 0.6429 - val_auc: 0.7460 - 11s/epoch - 140ms/step\n",
      "Epoch 9/100\n",
      "76/76 - 11s - loss: 0.0865 - accuracy: 0.9701 - auc: 0.9965 - val_loss: 0.5041 - val_accuracy: 0.7959 - val_auc: 0.9150 - 11s/epoch - 141ms/step\n",
      "Epoch 10/100\n",
      "76/76 - 11s - loss: 0.1156 - accuracy: 0.9569 - auc: 0.9914 - val_loss: 0.4041 - val_accuracy: 0.8367 - val_auc: 0.9145 - 11s/epoch - 142ms/step\n",
      "Epoch 11/100\n",
      "76/76 - 11s - loss: 0.0759 - accuracy: 0.9701 - auc: 0.9962 - val_loss: 0.2192 - val_accuracy: 0.9286 - val_auc: 0.9716 - 11s/epoch - 143ms/step\n",
      "Epoch 12/100\n",
      "76/76 - 11s - loss: 0.0929 - accuracy: 0.9569 - auc: 0.9955 - val_loss: 0.1671 - val_accuracy: 0.9694 - val_auc: 0.9808 - 11s/epoch - 142ms/step\n",
      "Epoch 13/100\n",
      "76/76 - 11s - loss: 0.0934 - accuracy: 0.9685 - auc: 0.9950 - val_loss: 0.2285 - val_accuracy: 0.9286 - val_auc: 0.9652 - 11s/epoch - 141ms/step\n",
      "Epoch 14/100\n",
      "76/76 - 11s - loss: 0.0655 - accuracy: 0.9801 - auc: 0.9977 - val_loss: 0.3732 - val_accuracy: 0.8469 - val_auc: 0.9487 - 11s/epoch - 142ms/step\n",
      "Epoch 15/100\n",
      "76/76 - 11s - loss: 0.0517 - accuracy: 0.9834 - auc: 0.9985 - val_loss: 0.2210 - val_accuracy: 0.9184 - val_auc: 0.9741 - 11s/epoch - 142ms/step\n",
      "Epoch 16/100\n",
      "76/76 - 11s - loss: 0.0895 - accuracy: 0.9685 - auc: 0.9937 - val_loss: 0.4786 - val_accuracy: 0.8367 - val_auc: 0.9144 - 11s/epoch - 143ms/step\n",
      "Epoch 17/100\n",
      "76/76 - 11s - loss: 0.0645 - accuracy: 0.9801 - auc: 0.9964 - val_loss: 0.4464 - val_accuracy: 0.8061 - val_auc: 0.9272 - 11s/epoch - 143ms/step\n",
      "Epoch 18/100\n",
      "76/76 - 11s - loss: 0.0409 - accuracy: 0.9851 - auc: 0.9993 - val_loss: 0.3677 - val_accuracy: 0.8878 - val_auc: 0.9606 - 11s/epoch - 141ms/step\n",
      "Epoch 19/100\n",
      "76/76 - 11s - loss: 0.0364 - accuracy: 0.9867 - auc: 0.9991 - val_loss: 0.2390 - val_accuracy: 0.8980 - val_auc: 0.9691 - 11s/epoch - 141ms/step\n",
      "Epoch 20/100\n",
      "76/76 - 11s - loss: 0.0561 - accuracy: 0.9818 - auc: 0.9980 - val_loss: 0.2643 - val_accuracy: 0.9184 - val_auc: 0.9624 - 11s/epoch - 142ms/step\n",
      "Epoch 21/100\n",
      "76/76 - 11s - loss: 0.0514 - accuracy: 0.9867 - auc: 0.9978 - val_loss: 0.2892 - val_accuracy: 0.9388 - val_auc: 0.9449 - 11s/epoch - 141ms/step\n",
      "Epoch 22/100\n",
      "76/76 - 11s - loss: 0.0507 - accuracy: 0.9834 - auc: 0.9987 - val_loss: 0.2574 - val_accuracy: 0.9592 - val_auc: 0.9628 - 11s/epoch - 141ms/step\n",
      "Epoch 23/100\n",
      "76/76 - 11s - loss: 0.0826 - accuracy: 0.9768 - auc: 0.9945 - val_loss: 0.2827 - val_accuracy: 0.9286 - val_auc: 0.9549 - 11s/epoch - 141ms/step\n",
      "Epoch 24/100\n",
      "76/76 - 11s - loss: 0.0612 - accuracy: 0.9768 - auc: 0.9980 - val_loss: 0.3726 - val_accuracy: 0.8673 - val_auc: 0.9442 - 11s/epoch - 142ms/step\n",
      "Epoch 25/100\n",
      "76/76 - 11s - loss: 0.0433 - accuracy: 0.9851 - auc: 0.9988 - val_loss: 0.2046 - val_accuracy: 0.8776 - val_auc: 0.9783 - 11s/epoch - 142ms/step\n",
      "Epoch 26/100\n",
      "76/76 - 11s - loss: 0.0468 - accuracy: 0.9851 - auc: 0.9988 - val_loss: 0.2110 - val_accuracy: 0.9082 - val_auc: 0.9748 - 11s/epoch - 143ms/step\n",
      "Epoch 27/100\n",
      "76/76 - 11s - loss: 0.0675 - accuracy: 0.9751 - auc: 0.9971 - val_loss: 0.1956 - val_accuracy: 0.9184 - val_auc: 0.9741 - 11s/epoch - 144ms/step\n",
      "Epoch 28/100\n",
      "76/76 - 11s - loss: 0.0281 - accuracy: 0.9884 - auc: 0.9997 - val_loss: 0.4120 - val_accuracy: 0.8469 - val_auc: 0.9353 - 11s/epoch - 143ms/step\n",
      "Epoch 29/100\n",
      "76/76 - 11s - loss: 0.0776 - accuracy: 0.9701 - auc: 0.9960 - val_loss: 7.8292 - val_accuracy: 0.4490 - val_auc: 0.4745 - 11s/epoch - 142ms/step\n",
      "Epoch 30/100\n",
      "76/76 - 11s - loss: 0.0935 - accuracy: 0.9685 - auc: 0.9932 - val_loss: 0.2953 - val_accuracy: 0.9184 - val_auc: 0.9569 - 11s/epoch - 143ms/step\n",
      "Epoch 31/100\n",
      "76/76 - 11s - loss: 0.0791 - accuracy: 0.9784 - auc: 0.9942 - val_loss: 0.1396 - val_accuracy: 0.9694 - val_auc: 0.9824 - 11s/epoch - 143ms/step\n",
      "Epoch 32/100\n",
      "76/76 - 11s - loss: 0.0230 - accuracy: 0.9950 - auc: 0.9999 - val_loss: 1.4927 - val_accuracy: 0.6020 - val_auc: 0.6931 - 11s/epoch - 143ms/step\n",
      "Epoch 33/100\n",
      "76/76 - 11s - loss: 0.0169 - accuracy: 0.9917 - auc: 0.9999 - val_loss: 0.3127 - val_accuracy: 0.8673 - val_auc: 0.9573 - 11s/epoch - 141ms/step\n",
      "Epoch 34/100\n",
      "76/76 - 11s - loss: 0.0233 - accuracy: 0.9934 - auc: 0.9999 - val_loss: 0.2764 - val_accuracy: 0.8878 - val_auc: 0.9664 - 11s/epoch - 142ms/step\n",
      "Epoch 35/100\n",
      "76/76 - 11s - loss: 0.0651 - accuracy: 0.9751 - auc: 0.9974 - val_loss: 1.2268 - val_accuracy: 0.7041 - val_auc: 0.7981 - 11s/epoch - 142ms/step\n",
      "Epoch 36/100\n",
      "76/76 - 11s - loss: 0.0502 - accuracy: 0.9818 - auc: 0.9985 - val_loss: 0.2898 - val_accuracy: 0.9082 - val_auc: 0.9586 - 11s/epoch - 143ms/step\n",
      "Epoch 37/100\n",
      "76/76 - 11s - loss: 0.0560 - accuracy: 0.9801 - auc: 0.9980 - val_loss: 0.2511 - val_accuracy: 0.9286 - val_auc: 0.9673 - 11s/epoch - 141ms/step\n",
      "Epoch 38/100\n",
      "76/76 - 11s - loss: 0.0328 - accuracy: 0.9950 - auc: 0.9976 - val_loss: 0.2154 - val_accuracy: 0.9082 - val_auc: 0.9689 - 11s/epoch - 142ms/step\n",
      "Epoch 39/100\n",
      "76/76 - 11s - loss: 0.0376 - accuracy: 0.9917 - auc: 0.9978 - val_loss: 0.2608 - val_accuracy: 0.9388 - val_auc: 0.9724 - 11s/epoch - 142ms/step\n",
      "Epoch 40/100\n",
      "76/76 - 11s - loss: 0.0260 - accuracy: 0.9917 - auc: 0.9997 - val_loss: 0.5026 - val_accuracy: 0.8469 - val_auc: 0.9328 - 11s/epoch - 141ms/step\n",
      "Epoch 41/100\n",
      "76/76 - 11s - loss: 0.0329 - accuracy: 0.9884 - auc: 0.9994 - val_loss: 0.1952 - val_accuracy: 0.8980 - val_auc: 0.9810 - 11s/epoch - 142ms/step\n",
      "Epoch 42/100\n",
      "76/76 - 11s - loss: 0.0195 - accuracy: 0.9934 - auc: 0.9999 - val_loss: 0.2110 - val_accuracy: 0.9694 - val_auc: 0.9689 - 11s/epoch - 143ms/step\n",
      "Epoch 43/100\n",
      "76/76 - 11s - loss: 0.0297 - accuracy: 0.9917 - auc: 0.9994 - val_loss: 1.3891 - val_accuracy: 0.7347 - val_auc: 0.7980 - 11s/epoch - 141ms/step\n",
      "Epoch 44/100\n",
      "76/76 - 11s - loss: 0.0549 - accuracy: 0.9818 - auc: 0.9968 - val_loss: 0.7310 - val_accuracy: 0.7857 - val_auc: 0.8623 - 11s/epoch - 141ms/step\n",
      "Epoch 45/100\n",
      "76/76 - 11s - loss: 0.0477 - accuracy: 0.9784 - auc: 0.9986 - val_loss: 0.4272 - val_accuracy: 0.8367 - val_auc: 0.9461 - 11s/epoch - 141ms/step\n",
      "Epoch 46/100\n",
      "76/76 - 11s - loss: 0.0470 - accuracy: 0.9851 - auc: 0.9975 - val_loss: 5.5993 - val_accuracy: 0.5510 - val_auc: 0.5877 - 11s/epoch - 141ms/step\n",
      "Epoch 47/100\n",
      "76/76 - 11s - loss: 0.0439 - accuracy: 0.9801 - auc: 0.9988 - val_loss: 0.1689 - val_accuracy: 0.9286 - val_auc: 0.9831 - 11s/epoch - 142ms/step\n",
      "Epoch 48/100\n",
      "76/76 - 11s - loss: 0.0400 - accuracy: 0.9884 - auc: 0.9988 - val_loss: 1.0895 - val_accuracy: 0.7347 - val_auc: 0.8198 - 11s/epoch - 142ms/step\n",
      "Epoch 49/100\n",
      "76/76 - 11s - loss: 0.0496 - accuracy: 0.9851 - auc: 0.9972 - val_loss: 0.1998 - val_accuracy: 0.9490 - val_auc: 0.9822 - 11s/epoch - 143ms/step\n",
      "Epoch 50/100\n",
      "76/76 - 11s - loss: 0.0334 - accuracy: 0.9917 - auc: 0.9978 - val_loss: 0.2032 - val_accuracy: 0.9184 - val_auc: 0.9730 - 11s/epoch - 143ms/step\n",
      "Epoch 51/100\n",
      "76/76 - 11s - loss: 0.0330 - accuracy: 0.9900 - auc: 0.9994 - val_loss: 0.7260 - val_accuracy: 0.8367 - val_auc: 0.8832 - 11s/epoch - 143ms/step\n",
      "Epoch 52/100\n",
      "76/76 - 11s - loss: 0.0577 - accuracy: 0.9801 - auc: 0.9980 - val_loss: 6.5289 - val_accuracy: 0.5102 - val_auc: 0.5190 - 11s/epoch - 143ms/step\n",
      "Epoch 53/100\n",
      "76/76 - 11s - loss: 0.0208 - accuracy: 0.9917 - auc: 0.9998 - val_loss: 0.1314 - val_accuracy: 0.9592 - val_auc: 0.9855 - 11s/epoch - 143ms/step\n",
      "Epoch 54/100\n",
      "76/76 - 11s - loss: 0.0409 - accuracy: 0.9884 - auc: 0.9975 - val_loss: 6.3803 - val_accuracy: 0.4694 - val_auc: 0.4737 - 11s/epoch - 142ms/step\n",
      "Epoch 55/100\n",
      "76/76 - 11s - loss: 0.0622 - accuracy: 0.9851 - auc: 0.9949 - val_loss: 0.4711 - val_accuracy: 0.8980 - val_auc: 0.9336 - 11s/epoch - 142ms/step\n",
      "Epoch 56/100\n",
      "76/76 - 11s - loss: 0.0670 - accuracy: 0.9851 - auc: 0.9967 - val_loss: 0.3200 - val_accuracy: 0.9082 - val_auc: 0.9588 - 11s/epoch - 143ms/step\n",
      "Epoch 57/100\n",
      "76/76 - 11s - loss: 0.0205 - accuracy: 0.9983 - auc: 0.9998 - val_loss: 3.0875 - val_accuracy: 0.5000 - val_auc: 0.5761 - 11s/epoch - 143ms/step\n",
      "Epoch 58/100\n",
      "76/76 - 11s - loss: 0.1187 - accuracy: 0.9668 - auc: 0.9885 - val_loss: 1.4576 - val_accuracy: 0.6735 - val_auc: 0.7442 - 11s/epoch - 143ms/step\n",
      "Epoch 59/100\n",
      "76/76 - 11s - loss: 0.0523 - accuracy: 0.9768 - auc: 0.9983 - val_loss: 2.0176 - val_accuracy: 0.5714 - val_auc: 0.6447 - 11s/epoch - 144ms/step\n",
      "Epoch 60/100\n",
      "76/76 - 11s - loss: 0.0901 - accuracy: 0.9735 - auc: 0.9935 - val_loss: 0.2055 - val_accuracy: 0.9082 - val_auc: 0.9774 - 11s/epoch - 143ms/step\n",
      "Epoch 61/100\n",
      "76/76 - 11s - loss: 0.0608 - accuracy: 0.9784 - auc: 0.9963 - val_loss: 0.2663 - val_accuracy: 0.9082 - val_auc: 0.9724 - 11s/epoch - 143ms/step\n",
      "Epoch 62/100\n",
      "76/76 - 11s - loss: 0.0563 - accuracy: 0.9768 - auc: 0.9982 - val_loss: 0.1125 - val_accuracy: 0.9796 - val_auc: 0.9909 - 11s/epoch - 143ms/step\n",
      "Epoch 63/100\n",
      "76/76 - 11s - loss: 0.0285 - accuracy: 0.9884 - auc: 0.9997 - val_loss: 0.4551 - val_accuracy: 0.8265 - val_auc: 0.9223 - 11s/epoch - 142ms/step\n",
      "Epoch 64/100\n",
      "76/76 - 11s - loss: 0.0318 - accuracy: 0.9934 - auc: 0.9992 - val_loss: 0.3060 - val_accuracy: 0.8878 - val_auc: 0.9564 - 11s/epoch - 143ms/step\n",
      "Epoch 65/100\n",
      "76/76 - 11s - loss: 0.0208 - accuracy: 0.9900 - auc: 0.9998 - val_loss: 0.2752 - val_accuracy: 0.8776 - val_auc: 0.9607 - 11s/epoch - 148ms/step\n",
      "Epoch 66/100\n",
      "76/76 - 11s - loss: 0.0331 - accuracy: 0.9900 - auc: 0.9994 - val_loss: 0.3465 - val_accuracy: 0.9388 - val_auc: 0.9527 - 11s/epoch - 142ms/step\n",
      "Epoch 67/100\n",
      "76/76 - 11s - loss: 0.0107 - accuracy: 0.9983 - auc: 0.9999 - val_loss: 0.2277 - val_accuracy: 0.9388 - val_auc: 0.9809 - 11s/epoch - 142ms/step\n",
      "Epoch 68/100\n",
      "76/76 - 11s - loss: 0.0581 - accuracy: 0.9751 - auc: 0.9968 - val_loss: 0.6088 - val_accuracy: 0.8367 - val_auc: 0.8963 - 11s/epoch - 143ms/step\n",
      "Epoch 69/100\n",
      "76/76 - 11s - loss: 0.0371 - accuracy: 0.9917 - auc: 0.9978 - val_loss: 0.4685 - val_accuracy: 0.9082 - val_auc: 0.9627 - 11s/epoch - 143ms/step\n",
      "Epoch 70/100\n",
      "76/76 - 11s - loss: 0.0179 - accuracy: 0.9934 - auc: 0.9999 - val_loss: 0.1424 - val_accuracy: 0.9694 - val_auc: 0.9857 - 11s/epoch - 143ms/step\n",
      "Epoch 71/100\n",
      "76/76 - 11s - loss: 0.0245 - accuracy: 0.9934 - auc: 0.9997 - val_loss: 0.1023 - val_accuracy: 0.9898 - val_auc: 0.9925 - 11s/epoch - 144ms/step\n",
      "Epoch 72/100\n",
      "76/76 - 11s - loss: 0.0360 - accuracy: 0.9851 - auc: 0.9991 - val_loss: 0.3652 - val_accuracy: 0.8878 - val_auc: 0.9511 - 11s/epoch - 143ms/step\n",
      "Epoch 73/100\n",
      "76/76 - 11s - loss: 0.0124 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.2416 - val_accuracy: 0.9082 - val_auc: 0.9769 - 11s/epoch - 143ms/step\n",
      "Epoch 74/100\n",
      "76/76 - 11s - loss: 0.0083 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1770 - val_accuracy: 0.9592 - val_auc: 0.9811 - 11s/epoch - 143ms/step\n",
      "Epoch 75/100\n",
      "76/76 - 11s - loss: 0.0500 - accuracy: 0.9867 - auc: 0.9969 - val_loss: 1.9898 - val_accuracy: 0.6122 - val_auc: 0.6737 - 11s/epoch - 144ms/step\n",
      "Epoch 76/100\n",
      "76/76 - 11s - loss: 0.0357 - accuracy: 0.9834 - auc: 0.9993 - val_loss: 0.1929 - val_accuracy: 0.9592 - val_auc: 0.9815 - 11s/epoch - 143ms/step\n",
      "Epoch 77/100\n",
      "76/76 - 12s - loss: 0.0230 - accuracy: 0.9967 - auc: 0.9981 - val_loss: 0.2259 - val_accuracy: 0.9286 - val_auc: 0.9790 - 12s/epoch - 164ms/step\n",
      "Epoch 78/100\n",
      "76/76 - 12s - loss: 0.0348 - accuracy: 0.9818 - auc: 0.9994 - val_loss: 0.3394 - val_accuracy: 0.8673 - val_auc: 0.9691 - 12s/epoch - 155ms/step\n",
      "Epoch 79/100\n",
      "76/76 - 11s - loss: 0.0107 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9490 - val_auc: 0.9793 - 11s/epoch - 148ms/step\n",
      "Epoch 80/100\n",
      "76/76 - 11s - loss: 0.0482 - accuracy: 0.9851 - auc: 0.9972 - val_loss: 0.2300 - val_accuracy: 0.8980 - val_auc: 0.9687 - 11s/epoch - 149ms/step\n",
      "Epoch 81/100\n",
      "76/76 - 11s - loss: 0.0104 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9490 - val_auc: 0.9887 - 11s/epoch - 148ms/step\n",
      "Epoch 82/100\n",
      "76/76 - 11s - loss: 0.0273 - accuracy: 0.9917 - auc: 0.9994 - val_loss: 0.2056 - val_accuracy: 0.9082 - val_auc: 0.9788 - 11s/epoch - 147ms/step\n",
      "Epoch 83/100\n",
      "76/76 - 11s - loss: 0.0215 - accuracy: 0.9950 - auc: 0.9996 - val_loss: 0.7250 - val_accuracy: 0.7653 - val_auc: 0.8720 - 11s/epoch - 147ms/step\n",
      "Epoch 84/100\n",
      "76/76 - 11s - loss: 0.0086 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9490 - val_auc: 0.9796 - 11s/epoch - 148ms/step\n",
      "Epoch 85/100\n",
      "76/76 - 11s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.9286 - val_auc: 0.9717 - 11s/epoch - 145ms/step\n",
      "Epoch 86/100\n",
      "76/76 - 11s - loss: 0.0146 - accuracy: 0.9934 - auc: 0.9999 - val_loss: 0.9678 - val_accuracy: 0.7551 - val_auc: 0.8374 - 11s/epoch - 147ms/step\n",
      "Epoch 87/100\n",
      "76/76 - 10s - loss: 0.0657 - accuracy: 0.9818 - auc: 0.9959 - val_loss: 0.8788 - val_accuracy: 0.7755 - val_auc: 0.8375 - 10s/epoch - 136ms/step\n",
      "Epoch 88/100\n",
      "76/76 - 10s - loss: 0.0176 - accuracy: 0.9950 - auc: 0.9999 - val_loss: 0.4347 - val_accuracy: 0.8980 - val_auc: 0.9605 - 10s/epoch - 137ms/step\n",
      "Epoch 89/100\n",
      "76/76 - 11s - loss: 0.0305 - accuracy: 0.9900 - auc: 0.9995 - val_loss: 16.2082 - val_accuracy: 0.4490 - val_auc: 0.4593 - 11s/epoch - 141ms/step\n",
      "Epoch 90/100\n",
      "76/76 - 12s - loss: 0.0197 - accuracy: 0.9917 - auc: 0.9998 - val_loss: 0.1635 - val_accuracy: 0.9286 - val_auc: 0.9806 - 12s/epoch - 151ms/step\n",
      "Epoch 91/100\n",
      "76/76 - 11s - loss: 0.0219 - accuracy: 0.9934 - auc: 0.9997 - val_loss: 0.2272 - val_accuracy: 0.9388 - val_auc: 0.9747 - 11s/epoch - 148ms/step\n",
      "Epoch 92/100\n",
      "76/76 - 11s - loss: 0.0355 - accuracy: 0.9934 - auc: 0.9977 - val_loss: 0.2036 - val_accuracy: 0.8878 - val_auc: 0.9702 - 11s/epoch - 144ms/step\n",
      "Epoch 93/100\n",
      "76/76 - 11s - loss: 0.0041 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9388 - val_auc: 0.9707 - 11s/epoch - 145ms/step\n",
      "Epoch 94/100\n",
      "76/76 - 11s - loss: 0.0276 - accuracy: 0.9917 - auc: 0.9995 - val_loss: 0.1747 - val_accuracy: 0.9592 - val_auc: 0.9828 - 11s/epoch - 145ms/step\n",
      "Epoch 95/100\n",
      "76/76 - 11s - loss: 0.0119 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8571 - val_auc: 0.9408 - 11s/epoch - 143ms/step\n",
      "Epoch 96/100\n",
      "76/76 - 11s - loss: 0.0169 - accuracy: 0.9917 - auc: 0.9999 - val_loss: 0.2440 - val_accuracy: 0.8980 - val_auc: 0.9709 - 11s/epoch - 148ms/step\n",
      "Epoch 97/100\n",
      "76/76 - 11s - loss: 0.0332 - accuracy: 0.9867 - auc: 0.9994 - val_loss: 0.3762 - val_accuracy: 0.8571 - val_auc: 0.9579 - 11s/epoch - 147ms/step\n",
      "Epoch 98/100\n",
      "76/76 - 11s - loss: 0.0380 - accuracy: 0.9851 - auc: 0.9992 - val_loss: 0.1328 - val_accuracy: 0.9592 - val_auc: 0.9840 - 11s/epoch - 143ms/step\n",
      "Epoch 99/100\n",
      "76/76 - 11s - loss: 0.0269 - accuracy: 0.9900 - auc: 0.9996 - val_loss: 0.2011 - val_accuracy: 0.9490 - val_auc: 0.9809 - 11s/epoch - 147ms/step\n",
      "Epoch 100/100\n",
      "76/76 - 11s - loss: 0.0150 - accuracy: 0.9950 - auc: 0.9998 - val_loss: 0.5147 - val_accuracy: 0.8571 - val_auc: 0.9297 - 11s/epoch - 148ms/step\n",
      "4/4 [==============================] - 0s 82ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       1.00      0.98      0.99        63\n",
      "\n",
      "    accuracy                           0.99        98\n",
      "   macro avg       0.99      0.99      0.99        98\n",
      "weighted avg       0.99      0.99      0.99        98\n",
      "\n",
      "Roc 0.9945578231292517\n",
      "Confusion Matrix\n",
      "[[35  0]\n",
      " [ 1 62]]\n",
      "minority class [1.]\n",
      "minority people 22\n",
      "y size 0\n",
      "other size 778\n",
      "['NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Felicetta C', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'Nicola S', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P', 'MARIACRISTINA P']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4079609347.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 - 15s - loss: 0.5087 - accuracy: 0.7724 - auc: 0.8484 - val_loss: 0.7602 - val_accuracy: 0.4000 - val_auc: 0.5088 - 15s/epoch - 182ms/step\n",
      "Epoch 2/100\n",
      "80/80 - 9s - loss: 0.2923 - accuracy: 0.9011 - auc: 0.9484 - val_loss: 0.7331 - val_accuracy: 0.4375 - val_auc: 0.5647 - 9s/epoch - 116ms/step\n",
      "Epoch 3/100\n",
      "80/80 - 11s - loss: 0.2160 - accuracy: 0.9121 - auc: 0.9714 - val_loss: 1.8172 - val_accuracy: 0.6000 - val_auc: 0.5550 - 11s/epoch - 134ms/step\n",
      "Epoch 4/100\n",
      "80/80 - 11s - loss: 0.2139 - accuracy: 0.9294 - auc: 0.9706 - val_loss: 0.7507 - val_accuracy: 0.6000 - val_auc: 0.6541 - 11s/epoch - 141ms/step\n",
      "Epoch 5/100\n",
      "80/80 - 11s - loss: 0.1638 - accuracy: 0.9419 - auc: 0.9829 - val_loss: 0.4961 - val_accuracy: 0.7625 - val_auc: 0.9146 - 11s/epoch - 142ms/step\n",
      "Epoch 6/100\n",
      "80/80 - 11s - loss: 0.1515 - accuracy: 0.9529 - auc: 0.9853 - val_loss: 0.6478 - val_accuracy: 0.7375 - val_auc: 0.8073 - 11s/epoch - 142ms/step\n",
      "Epoch 7/100\n",
      "80/80 - 11s - loss: 0.1407 - accuracy: 0.9482 - auc: 0.9871 - val_loss: 2.9936 - val_accuracy: 0.5750 - val_auc: 0.5750 - 11s/epoch - 142ms/step\n",
      "Epoch 8/100\n",
      "80/80 - 11s - loss: 0.1174 - accuracy: 0.9608 - auc: 0.9909 - val_loss: 1.7257 - val_accuracy: 0.5625 - val_auc: 0.7029 - 11s/epoch - 142ms/step\n",
      "Epoch 9/100\n",
      "80/80 - 11s - loss: 0.0940 - accuracy: 0.9655 - auc: 0.9950 - val_loss: 1.2867 - val_accuracy: 0.6875 - val_auc: 0.7773 - 11s/epoch - 142ms/step\n",
      "Epoch 10/100\n",
      "80/80 - 11s - loss: 0.1008 - accuracy: 0.9686 - auc: 0.9933 - val_loss: 8.4641 - val_accuracy: 0.5125 - val_auc: 0.4875 - 11s/epoch - 142ms/step\n",
      "Epoch 11/100\n",
      "80/80 - 11s - loss: 0.0694 - accuracy: 0.9780 - auc: 0.9972 - val_loss: 2.0991 - val_accuracy: 0.8250 - val_auc: 0.8102 - 11s/epoch - 142ms/step\n",
      "Epoch 12/100\n",
      "80/80 - 11s - loss: 0.0935 - accuracy: 0.9749 - auc: 0.9927 - val_loss: 2.3732 - val_accuracy: 0.6500 - val_auc: 0.7077 - 11s/epoch - 143ms/step\n",
      "Epoch 13/100\n",
      "80/80 - 11s - loss: 0.0953 - accuracy: 0.9608 - auc: 0.9948 - val_loss: 1.7939 - val_accuracy: 0.8250 - val_auc: 0.7769 - 11s/epoch - 142ms/step\n",
      "Epoch 14/100\n",
      "80/80 - 11s - loss: 0.0572 - accuracy: 0.9843 - auc: 0.9969 - val_loss: 6.5289 - val_accuracy: 0.5000 - val_auc: 0.4879 - 11s/epoch - 143ms/step\n",
      "Epoch 15/100\n",
      "80/80 - 11s - loss: 0.1448 - accuracy: 0.9372 - auc: 0.9872 - val_loss: 1.3917 - val_accuracy: 0.8250 - val_auc: 0.8333 - 11s/epoch - 143ms/step\n",
      "Epoch 16/100\n",
      "80/80 - 11s - loss: 0.0677 - accuracy: 0.9749 - auc: 0.9973 - val_loss: 2.0620 - val_accuracy: 0.7375 - val_auc: 0.7484 - 11s/epoch - 142ms/step\n",
      "Epoch 17/100\n",
      "80/80 - 11s - loss: 0.1032 - accuracy: 0.9608 - auc: 0.9922 - val_loss: 4.3731 - val_accuracy: 0.5125 - val_auc: 0.5711 - 11s/epoch - 144ms/step\n",
      "Epoch 18/100\n",
      "80/80 - 12s - loss: 0.1277 - accuracy: 0.9639 - auc: 0.9889 - val_loss: 1.4688 - val_accuracy: 0.7625 - val_auc: 0.7473 - 12s/epoch - 144ms/step\n",
      "Epoch 19/100\n",
      "80/80 - 11s - loss: 0.0725 - accuracy: 0.9670 - auc: 0.9970 - val_loss: 1.4472 - val_accuracy: 0.8250 - val_auc: 0.8239 - 11s/epoch - 143ms/step\n",
      "Epoch 20/100\n",
      "80/80 - 11s - loss: 0.0532 - accuracy: 0.9843 - auc: 0.9981 - val_loss: 2.6223 - val_accuracy: 0.8250 - val_auc: 0.8247 - 11s/epoch - 143ms/step\n",
      "Epoch 21/100\n",
      "80/80 - 11s - loss: 0.0310 - accuracy: 0.9906 - auc: 0.9996 - val_loss: 3.0586 - val_accuracy: 0.7500 - val_auc: 0.7625 - 11s/epoch - 143ms/step\n",
      "Epoch 22/100\n",
      "80/80 - 11s - loss: 0.0708 - accuracy: 0.9780 - auc: 0.9969 - val_loss: 1.8439 - val_accuracy: 0.7125 - val_auc: 0.7414 - 11s/epoch - 142ms/step\n",
      "Epoch 23/100\n",
      "80/80 - 11s - loss: 0.0504 - accuracy: 0.9859 - auc: 0.9986 - val_loss: 1.5019 - val_accuracy: 0.8250 - val_auc: 0.7938 - 11s/epoch - 143ms/step\n",
      "Epoch 24/100\n",
      "80/80 - 11s - loss: 0.0697 - accuracy: 0.9780 - auc: 0.9957 - val_loss: 1.9846 - val_accuracy: 0.7500 - val_auc: 0.7956 - 11s/epoch - 144ms/step\n",
      "Epoch 25/100\n",
      "80/80 - 11s - loss: 0.0814 - accuracy: 0.9780 - auc: 0.9953 - val_loss: 5.3414 - val_accuracy: 0.5125 - val_auc: 0.5355 - 11s/epoch - 143ms/step\n",
      "Epoch 26/100\n",
      "80/80 - 11s - loss: 0.0857 - accuracy: 0.9749 - auc: 0.9957 - val_loss: 3.2892 - val_accuracy: 0.5375 - val_auc: 0.6003 - 11s/epoch - 143ms/step\n",
      "Epoch 27/100\n",
      "80/80 - 11s - loss: 0.0493 - accuracy: 0.9843 - auc: 0.9982 - val_loss: 2.0116 - val_accuracy: 0.6750 - val_auc: 0.6980 - 11s/epoch - 143ms/step\n",
      "Epoch 28/100\n",
      "80/80 - 11s - loss: 0.0574 - accuracy: 0.9780 - auc: 0.9971 - val_loss: 1.7254 - val_accuracy: 0.7375 - val_auc: 0.7791 - 11s/epoch - 144ms/step\n",
      "Epoch 29/100\n",
      "80/80 - 11s - loss: 0.0716 - accuracy: 0.9733 - auc: 0.9964 - val_loss: 1.4625 - val_accuracy: 0.7750 - val_auc: 0.7870 - 11s/epoch - 142ms/step\n",
      "Epoch 30/100\n",
      "80/80 - 11s - loss: 0.0224 - accuracy: 0.9953 - auc: 0.9998 - val_loss: 1.5911 - val_accuracy: 0.8125 - val_auc: 0.8039 - 11s/epoch - 143ms/step\n",
      "Epoch 31/100\n",
      "80/80 - 11s - loss: 0.0595 - accuracy: 0.9717 - auc: 0.9979 - val_loss: 2.0782 - val_accuracy: 0.8250 - val_auc: 0.8195 - 11s/epoch - 143ms/step\n",
      "Epoch 32/100\n",
      "80/80 - 12s - loss: 0.0582 - accuracy: 0.9812 - auc: 0.9965 - val_loss: 1.6827 - val_accuracy: 0.8375 - val_auc: 0.8379 - 12s/epoch - 144ms/step\n",
      "Epoch 33/100\n",
      "80/80 - 11s - loss: 0.1190 - accuracy: 0.9639 - auc: 0.9901 - val_loss: 2.1115 - val_accuracy: 0.8000 - val_auc: 0.8308 - 11s/epoch - 143ms/step\n",
      "Epoch 34/100\n",
      "80/80 - 11s - loss: 0.0811 - accuracy: 0.9780 - auc: 0.9956 - val_loss: 2.2880 - val_accuracy: 0.5875 - val_auc: 0.6708 - 11s/epoch - 144ms/step\n",
      "Epoch 35/100\n",
      "80/80 - 11s - loss: 0.0345 - accuracy: 0.9874 - auc: 0.9995 - val_loss: 1.9246 - val_accuracy: 0.8250 - val_auc: 0.8190 - 11s/epoch - 143ms/step\n",
      "Epoch 36/100\n",
      "80/80 - 11s - loss: 0.0498 - accuracy: 0.9812 - auc: 0.9985 - val_loss: 8.7027 - val_accuracy: 0.5250 - val_auc: 0.5355 - 11s/epoch - 143ms/step\n",
      "Epoch 37/100\n",
      "80/80 - 11s - loss: 0.0489 - accuracy: 0.9890 - auc: 0.9973 - val_loss: 2.5085 - val_accuracy: 0.7875 - val_auc: 0.7972 - 11s/epoch - 144ms/step\n",
      "Epoch 38/100\n",
      "80/80 - 11s - loss: 0.0333 - accuracy: 0.9874 - auc: 0.9995 - val_loss: 1.5199 - val_accuracy: 0.7750 - val_auc: 0.8130 - 11s/epoch - 142ms/step\n",
      "Epoch 39/100\n",
      "80/80 - 11s - loss: 0.0302 - accuracy: 0.9890 - auc: 0.9994 - val_loss: 1.1678 - val_accuracy: 0.8000 - val_auc: 0.8500 - 11s/epoch - 142ms/step\n",
      "Epoch 40/100\n",
      "80/80 - 11s - loss: 0.0440 - accuracy: 0.9827 - auc: 0.9975 - val_loss: 33.2500 - val_accuracy: 0.4250 - val_auc: 0.4156 - 11s/epoch - 143ms/step\n",
      "Epoch 41/100\n",
      "80/80 - 11s - loss: 0.1023 - accuracy: 0.9608 - auc: 0.9928 - val_loss: 2.3017 - val_accuracy: 0.6000 - val_auc: 0.6516 - 11s/epoch - 143ms/step\n",
      "Epoch 42/100\n",
      "80/80 - 11s - loss: 0.0657 - accuracy: 0.9812 - auc: 0.9973 - val_loss: 1.4851 - val_accuracy: 0.7250 - val_auc: 0.7911 - 11s/epoch - 142ms/step\n",
      "Epoch 43/100\n",
      "80/80 - 11s - loss: 0.0670 - accuracy: 0.9765 - auc: 0.9963 - val_loss: 2.8087 - val_accuracy: 0.6500 - val_auc: 0.6764 - 11s/epoch - 143ms/step\n",
      "Epoch 44/100\n",
      "80/80 - 11s - loss: 0.0438 - accuracy: 0.9827 - auc: 0.9987 - val_loss: 1.1281 - val_accuracy: 0.8750 - val_auc: 0.8666 - 11s/epoch - 142ms/step\n",
      "Epoch 45/100\n",
      "80/80 - 11s - loss: 0.0300 - accuracy: 0.9859 - auc: 0.9995 - val_loss: 7.3920 - val_accuracy: 0.4875 - val_auc: 0.4992 - 11s/epoch - 143ms/step\n",
      "Epoch 46/100\n",
      "80/80 - 11s - loss: 0.0941 - accuracy: 0.9717 - auc: 0.9925 - val_loss: 1.6667 - val_accuracy: 0.7625 - val_auc: 0.7537 - 11s/epoch - 142ms/step\n",
      "Epoch 47/100\n",
      "80/80 - 11s - loss: 0.0176 - accuracy: 0.9969 - auc: 0.9999 - val_loss: 2.8071 - val_accuracy: 0.7375 - val_auc: 0.7559 - 11s/epoch - 143ms/step\n",
      "Epoch 48/100\n",
      "80/80 - 11s - loss: 0.0495 - accuracy: 0.9843 - auc: 0.9971 - val_loss: 1.9464 - val_accuracy: 0.8250 - val_auc: 0.8466 - 11s/epoch - 143ms/step\n",
      "Epoch 49/100\n",
      "80/80 - 11s - loss: 0.0711 - accuracy: 0.9686 - auc: 0.9968 - val_loss: 1.2017 - val_accuracy: 0.8625 - val_auc: 0.8862 - 11s/epoch - 143ms/step\n",
      "Epoch 50/100\n",
      "80/80 - 11s - loss: 0.0166 - accuracy: 0.9953 - auc: 0.9998 - val_loss: 2.5929 - val_accuracy: 0.7500 - val_auc: 0.7936 - 11s/epoch - 143ms/step\n",
      "Epoch 51/100\n",
      "80/80 - 11s - loss: 0.0348 - accuracy: 0.9827 - auc: 0.9994 - val_loss: 3.0910 - val_accuracy: 0.6500 - val_auc: 0.6884 - 11s/epoch - 144ms/step\n",
      "Epoch 52/100\n",
      "80/80 - 11s - loss: 0.0181 - accuracy: 0.9937 - auc: 0.9998 - val_loss: 4.9122 - val_accuracy: 0.7375 - val_auc: 0.7431 - 11s/epoch - 144ms/step\n",
      "Epoch 53/100\n",
      "80/80 - 11s - loss: 0.0118 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 1.7915 - val_accuracy: 0.8375 - val_auc: 0.8438 - 11s/epoch - 143ms/step\n",
      "Epoch 54/100\n",
      "80/80 - 11s - loss: 0.0168 - accuracy: 0.9953 - auc: 0.9999 - val_loss: 1.4924 - val_accuracy: 0.8250 - val_auc: 0.8095 - 11s/epoch - 143ms/step\n",
      "Epoch 55/100\n",
      "80/80 - 11s - loss: 0.0218 - accuracy: 0.9953 - auc: 0.9997 - val_loss: 2.0282 - val_accuracy: 0.8250 - val_auc: 0.8241 - 11s/epoch - 142ms/step\n",
      "Epoch 56/100\n",
      "80/80 - 11s - loss: 0.0257 - accuracy: 0.9906 - auc: 0.9996 - val_loss: 1.9179 - val_accuracy: 0.8250 - val_auc: 0.8273 - 11s/epoch - 143ms/step\n",
      "Epoch 57/100\n",
      "80/80 - 11s - loss: 0.0279 - accuracy: 0.9906 - auc: 0.9995 - val_loss: 2.2631 - val_accuracy: 0.8250 - val_auc: 0.8311 - 11s/epoch - 142ms/step\n",
      "Epoch 58/100\n",
      "80/80 - 11s - loss: 0.0390 - accuracy: 0.9827 - auc: 0.9992 - val_loss: 3.8162 - val_accuracy: 0.7125 - val_auc: 0.7223 - 11s/epoch - 142ms/step\n",
      "Epoch 59/100\n",
      "80/80 - 11s - loss: 0.0821 - accuracy: 0.9749 - auc: 0.9950 - val_loss: 3.4834 - val_accuracy: 0.6125 - val_auc: 0.6411 - 11s/epoch - 141ms/step\n",
      "Epoch 60/100\n",
      "80/80 - 11s - loss: 0.0202 - accuracy: 0.9922 - auc: 0.9998 - val_loss: 2.6722 - val_accuracy: 0.8250 - val_auc: 0.8333 - 11s/epoch - 142ms/step\n",
      "Epoch 61/100\n",
      "80/80 - 11s - loss: 0.0108 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 2.1633 - val_accuracy: 0.8375 - val_auc: 0.8302 - 11s/epoch - 142ms/step\n",
      "Epoch 62/100\n",
      "80/80 - 11s - loss: 0.0514 - accuracy: 0.9843 - auc: 0.9973 - val_loss: 2.0153 - val_accuracy: 0.7000 - val_auc: 0.7453 - 11s/epoch - 142ms/step\n",
      "Epoch 63/100\n",
      "80/80 - 11s - loss: 0.0551 - accuracy: 0.9843 - auc: 0.9970 - val_loss: 4.7007 - val_accuracy: 0.5375 - val_auc: 0.5842 - 11s/epoch - 141ms/step\n",
      "Epoch 64/100\n",
      "80/80 - 11s - loss: 0.0436 - accuracy: 0.9874 - auc: 0.9975 - val_loss: 5.2031 - val_accuracy: 0.5375 - val_auc: 0.5627 - 11s/epoch - 142ms/step\n",
      "Epoch 65/100\n",
      "80/80 - 11s - loss: 0.0408 - accuracy: 0.9859 - auc: 0.9974 - val_loss: 3.8361 - val_accuracy: 0.5375 - val_auc: 0.6147 - 11s/epoch - 143ms/step\n",
      "Epoch 66/100\n",
      "80/80 - 11s - loss: 0.0326 - accuracy: 0.9906 - auc: 0.9992 - val_loss: 1.0183 - val_accuracy: 0.8500 - val_auc: 0.8826 - 11s/epoch - 143ms/step\n",
      "Epoch 67/100\n",
      "80/80 - 11s - loss: 0.0241 - accuracy: 0.9890 - auc: 0.9997 - val_loss: 1.7966 - val_accuracy: 0.7625 - val_auc: 0.7959 - 11s/epoch - 143ms/step\n",
      "Epoch 68/100\n",
      "80/80 - 11s - loss: 0.0450 - accuracy: 0.9843 - auc: 0.9987 - val_loss: 2.8450 - val_accuracy: 0.8250 - val_auc: 0.8295 - 11s/epoch - 143ms/step\n",
      "Epoch 69/100\n",
      "80/80 - 12s - loss: 0.0452 - accuracy: 0.9874 - auc: 0.9961 - val_loss: 2.0042 - val_accuracy: 0.8375 - val_auc: 0.8234 - 12s/epoch - 144ms/step\n",
      "Epoch 70/100\n",
      "80/80 - 11s - loss: 0.0607 - accuracy: 0.9780 - auc: 0.9977 - val_loss: 3.3472 - val_accuracy: 0.6500 - val_auc: 0.6705 - 11s/epoch - 142ms/step\n",
      "Epoch 71/100\n",
      "80/80 - 11s - loss: 0.0247 - accuracy: 0.9937 - auc: 0.9995 - val_loss: 3.3709 - val_accuracy: 0.7500 - val_auc: 0.7848 - 11s/epoch - 142ms/step\n",
      "Epoch 72/100\n",
      "80/80 - 11s - loss: 0.0271 - accuracy: 0.9890 - auc: 0.9996 - val_loss: 5.7299 - val_accuracy: 0.8125 - val_auc: 0.7925 - 11s/epoch - 142ms/step\n",
      "Epoch 73/100\n",
      "80/80 - 11s - loss: 0.0454 - accuracy: 0.9796 - auc: 0.9988 - val_loss: 1.8474 - val_accuracy: 0.7250 - val_auc: 0.7886 - 11s/epoch - 143ms/step\n",
      "Epoch 74/100\n",
      "80/80 - 11s - loss: 0.0411 - accuracy: 0.9906 - auc: 0.9987 - val_loss: 1.0494 - val_accuracy: 0.8500 - val_auc: 0.8769 - 11s/epoch - 143ms/step\n",
      "Epoch 75/100\n",
      "80/80 - 11s - loss: 0.0366 - accuracy: 0.9859 - auc: 0.9992 - val_loss: 1.3343 - val_accuracy: 0.8375 - val_auc: 0.8537 - 11s/epoch - 143ms/step\n",
      "Epoch 76/100\n",
      "80/80 - 11s - loss: 0.0243 - accuracy: 0.9906 - auc: 0.9997 - val_loss: 1.9976 - val_accuracy: 0.8250 - val_auc: 0.8505 - 11s/epoch - 142ms/step\n",
      "Epoch 77/100\n",
      "80/80 - 11s - loss: 0.0180 - accuracy: 0.9922 - auc: 0.9998 - val_loss: 17.8797 - val_accuracy: 0.4625 - val_auc: 0.4719 - 11s/epoch - 142ms/step\n",
      "Epoch 78/100\n",
      "80/80 - 11s - loss: 0.0150 - accuracy: 0.9953 - auc: 0.9999 - val_loss: 1.0387 - val_accuracy: 0.8250 - val_auc: 0.8833 - 11s/epoch - 141ms/step\n",
      "Epoch 79/100\n",
      "80/80 - 11s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.8375 - val_auc: 0.8952 - 11s/epoch - 141ms/step\n",
      "Epoch 80/100\n",
      "80/80 - 11s - loss: 0.0048 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 1.6451 - val_accuracy: 0.7625 - val_auc: 0.7801 - 11s/epoch - 141ms/step\n",
      "Epoch 81/100\n",
      "80/80 - 11s - loss: 0.0662 - accuracy: 0.9780 - auc: 0.9961 - val_loss: 0.8005 - val_accuracy: 0.9000 - val_auc: 0.9303 - 11s/epoch - 142ms/step\n",
      "Epoch 82/100\n",
      "80/80 - 11s - loss: 0.0268 - accuracy: 0.9906 - auc: 0.9996 - val_loss: 1.6251 - val_accuracy: 0.8375 - val_auc: 0.8638 - 11s/epoch - 142ms/step\n",
      "Epoch 83/100\n",
      "80/80 - 11s - loss: 0.0436 - accuracy: 0.9827 - auc: 0.9976 - val_loss: 3.8954 - val_accuracy: 0.8250 - val_auc: 0.8288 - 11s/epoch - 141ms/step\n",
      "Epoch 84/100\n",
      "80/80 - 11s - loss: 0.0081 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 15.1891 - val_accuracy: 0.4750 - val_auc: 0.4906 - 11s/epoch - 141ms/step\n",
      "Epoch 85/100\n",
      "80/80 - 11s - loss: 0.0108 - accuracy: 0.9969 - auc: 1.0000 - val_loss: 1.3873 - val_accuracy: 0.8500 - val_auc: 0.8650 - 11s/epoch - 142ms/step\n",
      "Epoch 86/100\n",
      "80/80 - 11s - loss: 0.0502 - accuracy: 0.9827 - auc: 0.9983 - val_loss: 8.3195 - val_accuracy: 0.5125 - val_auc: 0.5092 - 11s/epoch - 143ms/step\n",
      "Epoch 87/100\n",
      "80/80 - 11s - loss: 0.0979 - accuracy: 0.9780 - auc: 0.9923 - val_loss: 15.2063 - val_accuracy: 0.4375 - val_auc: 0.4470 - 11s/epoch - 141ms/step\n",
      "Epoch 88/100\n",
      "80/80 - 11s - loss: 0.0378 - accuracy: 0.9874 - auc: 0.9977 - val_loss: 0.5964 - val_accuracy: 0.9125 - val_auc: 0.9384 - 11s/epoch - 143ms/step\n",
      "Epoch 89/100\n",
      "80/80 - 11s - loss: 0.0098 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.5924 - val_accuracy: 0.7375 - val_auc: 0.8119 - 11s/epoch - 142ms/step\n",
      "Epoch 90/100\n",
      "80/80 - 11s - loss: 0.0544 - accuracy: 0.9843 - auc: 0.9969 - val_loss: 8.7477 - val_accuracy: 0.5125 - val_auc: 0.5070 - 11s/epoch - 142ms/step\n",
      "Epoch 91/100\n",
      "80/80 - 11s - loss: 0.0442 - accuracy: 0.9843 - auc: 0.9988 - val_loss: 2.1390 - val_accuracy: 0.6875 - val_auc: 0.7217 - 11s/epoch - 141ms/step\n",
      "Epoch 92/100\n",
      "80/80 - 11s - loss: 0.0386 - accuracy: 0.9859 - auc: 0.9992 - val_loss: 15.8023 - val_accuracy: 0.4375 - val_auc: 0.4506 - 11s/epoch - 142ms/step\n",
      "Epoch 93/100\n",
      "80/80 - 11s - loss: 0.0423 - accuracy: 0.9812 - auc: 0.9989 - val_loss: 0.8384 - val_accuracy: 0.8500 - val_auc: 0.9006 - 11s/epoch - 142ms/step\n",
      "Epoch 94/100\n",
      "80/80 - 11s - loss: 0.0125 - accuracy: 0.9969 - auc: 1.0000 - val_loss: 1.0735 - val_accuracy: 0.8250 - val_auc: 0.8780 - 11s/epoch - 141ms/step\n",
      "Epoch 95/100\n",
      "80/80 - 11s - loss: 0.0141 - accuracy: 0.9937 - auc: 0.9999 - val_loss: 1.9183 - val_accuracy: 0.6625 - val_auc: 0.7230 - 11s/epoch - 143ms/step\n",
      "Epoch 96/100\n",
      "80/80 - 11s - loss: 0.0143 - accuracy: 0.9953 - auc: 0.9999 - val_loss: 4.8070 - val_accuracy: 0.5750 - val_auc: 0.5523 - 11s/epoch - 143ms/step\n",
      "Epoch 97/100\n",
      "80/80 - 12s - loss: 0.0819 - accuracy: 0.9796 - auc: 0.9958 - val_loss: 1.4997 - val_accuracy: 0.7000 - val_auc: 0.7573 - 12s/epoch - 144ms/step\n",
      "Epoch 98/100\n",
      "80/80 - 11s - loss: 0.0279 - accuracy: 0.9922 - auc: 0.9995 - val_loss: 15.5227 - val_accuracy: 0.4625 - val_auc: 0.4778 - 11s/epoch - 143ms/step\n",
      "Epoch 99/100\n",
      "80/80 - 11s - loss: 0.0567 - accuracy: 0.9859 - auc: 0.9942 - val_loss: 2.5500 - val_accuracy: 0.6375 - val_auc: 0.6944 - 11s/epoch - 142ms/step\n",
      "Epoch 100/100\n",
      "80/80 - 11s - loss: 0.0510 - accuracy: 0.9906 - auc: 0.9976 - val_loss: 1.8074 - val_accuracy: 0.8250 - val_auc: 0.8386 - 11s/epoch - 143ms/step\n",
      "3/3 [==============================] - 0s 81ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        32\n",
      "           1       0.98      0.88      0.92        48\n",
      "\n",
      "    accuracy                           0.91        80\n",
      "   macro avg       0.91      0.92      0.91        80\n",
      "weighted avg       0.92      0.91      0.91        80\n",
      "\n",
      "Roc 0.9424479166666668\n",
      "Confusion Matrix\n",
      "[[31  1]\n",
      " [ 6 42]]\n",
      "minority class [1.]\n",
      "minority people 22\n",
      "y size 0\n",
      "other size 812\n",
      "['TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'TERESA M', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'NICOLA P', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Luigi B', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L', 'Daria L']\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3602718/4079609347.py:115: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  cd2 = np.where(y_train ==  to_categorical([2.0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "77/77 - 15s - loss: 0.5213 - accuracy: 0.7647 - auc: 0.8397 - val_loss: 0.8534 - val_accuracy: 0.4921 - val_auc: 0.5485 - 15s/epoch - 199ms/step\n",
      "Epoch 2/100\n",
      "77/77 - 9s - loss: 0.2960 - accuracy: 0.8840 - auc: 0.9477 - val_loss: 0.9650 - val_accuracy: 0.4921 - val_auc: 0.6068 - 9s/epoch - 123ms/step\n",
      "Epoch 3/100\n",
      "77/77 - 10s - loss: 0.2268 - accuracy: 0.9167 - auc: 0.9701 - val_loss: 1.5217 - val_accuracy: 0.4921 - val_auc: 0.5697 - 10s/epoch - 131ms/step\n",
      "Epoch 4/100\n",
      "77/77 - 11s - loss: 0.2222 - accuracy: 0.9232 - auc: 0.9700 - val_loss: 3.8881 - val_accuracy: 0.4921 - val_auc: 0.4921 - 11s/epoch - 142ms/step\n",
      "Epoch 5/100\n",
      "77/77 - 10s - loss: 0.1653 - accuracy: 0.9297 - auc: 0.9841 - val_loss: 3.5554 - val_accuracy: 0.4921 - val_auc: 0.4921 - 10s/epoch - 129ms/step\n",
      "Epoch 6/100\n",
      "77/77 - 11s - loss: 0.1448 - accuracy: 0.9526 - auc: 0.9881 - val_loss: 1.6956 - val_accuracy: 0.4921 - val_auc: 0.6820 - 11s/epoch - 138ms/step\n",
      "Epoch 7/100\n",
      "77/77 - 10s - loss: 0.1530 - accuracy: 0.9428 - auc: 0.9859 - val_loss: 0.7265 - val_accuracy: 0.6667 - val_auc: 0.8031 - 10s/epoch - 135ms/step\n",
      "Epoch 8/100\n",
      "77/77 - 11s - loss: 0.1072 - accuracy: 0.9575 - auc: 0.9946 - val_loss: 3.5745 - val_accuracy: 0.4921 - val_auc: 0.4999 - 11s/epoch - 142ms/step\n",
      "Epoch 9/100\n",
      "77/77 - 12s - loss: 0.0900 - accuracy: 0.9657 - auc: 0.9959 - val_loss: 2.7864 - val_accuracy: 0.6349 - val_auc: 0.6861 - 12s/epoch - 152ms/step\n",
      "Epoch 10/100\n",
      "77/77 - 12s - loss: 0.0854 - accuracy: 0.9673 - auc: 0.9961 - val_loss: 0.5895 - val_accuracy: 0.7143 - val_auc: 0.8668 - 12s/epoch - 151ms/step\n",
      "Epoch 11/100\n",
      "77/77 - 9s - loss: 0.0534 - accuracy: 0.9853 - auc: 0.9988 - val_loss: 0.1695 - val_accuracy: 0.8889 - val_auc: 0.9841 - 9s/epoch - 115ms/step\n",
      "Epoch 12/100\n",
      "77/77 - 8s - loss: 0.1071 - accuracy: 0.9690 - auc: 0.9923 - val_loss: 0.2700 - val_accuracy: 0.9048 - val_auc: 0.9536 - 8s/epoch - 103ms/step\n",
      "Epoch 13/100\n",
      "77/77 - 8s - loss: 0.0962 - accuracy: 0.9706 - auc: 0.9942 - val_loss: 0.1752 - val_accuracy: 0.9206 - val_auc: 0.9836 - 8s/epoch - 98ms/step\n",
      "Epoch 14/100\n",
      "77/77 - 7s - loss: 0.0906 - accuracy: 0.9657 - auc: 0.9956 - val_loss: 0.1222 - val_accuracy: 0.9365 - val_auc: 0.9919 - 7s/epoch - 95ms/step\n",
      "Epoch 15/100\n",
      "77/77 - 7s - loss: 0.0795 - accuracy: 0.9755 - auc: 0.9965 - val_loss: 0.5414 - val_accuracy: 0.7937 - val_auc: 0.9191 - 7s/epoch - 94ms/step\n",
      "Epoch 16/100\n",
      "77/77 - 7s - loss: 0.0765 - accuracy: 0.9739 - auc: 0.9961 - val_loss: 0.1242 - val_accuracy: 0.9841 - val_auc: 0.9861 - 7s/epoch - 92ms/step\n",
      "Epoch 17/100\n",
      "77/77 - 7s - loss: 0.0770 - accuracy: 0.9722 - auc: 0.9969 - val_loss: 0.1274 - val_accuracy: 0.9841 - val_auc: 0.9877 - 7s/epoch - 92ms/step\n",
      "Epoch 18/100\n",
      "77/77 - 7s - loss: 0.0747 - accuracy: 0.9755 - auc: 0.9966 - val_loss: 0.1154 - val_accuracy: 0.9841 - val_auc: 0.9877 - 7s/epoch - 92ms/step\n",
      "Epoch 19/100\n",
      "77/77 - 7s - loss: 0.0352 - accuracy: 0.9886 - auc: 0.9997 - val_loss: 0.3576 - val_accuracy: 0.8254 - val_auc: 0.9410 - 7s/epoch - 92ms/step\n",
      "Epoch 20/100\n",
      "77/77 - 7s - loss: 0.0348 - accuracy: 0.9918 - auc: 0.9997 - val_loss: 0.1668 - val_accuracy: 0.9524 - val_auc: 0.9781 - 7s/epoch - 92ms/step\n",
      "Epoch 21/100\n",
      "77/77 - 7s - loss: 0.0716 - accuracy: 0.9755 - auc: 0.9964 - val_loss: 0.1416 - val_accuracy: 0.9365 - val_auc: 0.9894 - 7s/epoch - 92ms/step\n",
      "Epoch 22/100\n",
      "77/77 - 7s - loss: 0.0723 - accuracy: 0.9739 - auc: 0.9958 - val_loss: 1.2307 - val_accuracy: 0.7302 - val_auc: 0.8345 - 7s/epoch - 92ms/step\n",
      "Epoch 23/100\n",
      "77/77 - 7s - loss: 0.0856 - accuracy: 0.9690 - auc: 0.9943 - val_loss: 0.4202 - val_accuracy: 0.8571 - val_auc: 0.9083 - 7s/epoch - 92ms/step\n",
      "Epoch 24/100\n",
      "77/77 - 7s - loss: 0.0665 - accuracy: 0.9804 - auc: 0.9972 - val_loss: 1.1823 - val_accuracy: 0.6349 - val_auc: 0.7954 - 7s/epoch - 92ms/step\n",
      "Epoch 25/100\n",
      "77/77 - 7s - loss: 0.0653 - accuracy: 0.9690 - auc: 0.9974 - val_loss: 0.1578 - val_accuracy: 0.9365 - val_auc: 0.9861 - 7s/epoch - 92ms/step\n",
      "Epoch 26/100\n",
      "77/77 - 7s - loss: 0.0525 - accuracy: 0.9788 - auc: 0.9986 - val_loss: 0.0751 - val_accuracy: 0.9683 - val_auc: 0.9975 - 7s/epoch - 92ms/step\n",
      "Epoch 27/100\n",
      "77/77 - 7s - loss: 0.0356 - accuracy: 0.9869 - auc: 0.9992 - val_loss: 0.1040 - val_accuracy: 0.9524 - val_auc: 0.9946 - 7s/epoch - 92ms/step\n",
      "Epoch 28/100\n",
      "77/77 - 7s - loss: 0.0282 - accuracy: 0.9951 - auc: 0.9997 - val_loss: 0.1642 - val_accuracy: 0.9365 - val_auc: 0.9740 - 7s/epoch - 92ms/step\n",
      "Epoch 29/100\n",
      "77/77 - 7s - loss: 0.0251 - accuracy: 0.9967 - auc: 0.9997 - val_loss: 0.1670 - val_accuracy: 0.9365 - val_auc: 0.9831 - 7s/epoch - 92ms/step\n",
      "Epoch 30/100\n",
      "77/77 - 7s - loss: 0.0147 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.2944 - val_accuracy: 0.9048 - val_auc: 0.9588 - 7s/epoch - 92ms/step\n",
      "Epoch 31/100\n",
      "77/77 - 7s - loss: 0.0186 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 0.0958 - val_accuracy: 0.9841 - val_auc: 0.9927 - 7s/epoch - 92ms/step\n",
      "Epoch 32/100\n",
      "77/77 - 7s - loss: 0.0126 - accuracy: 0.9951 - auc: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.8730 - val_auc: 0.9713 - 7s/epoch - 92ms/step\n",
      "Epoch 33/100\n",
      "77/77 - 7s - loss: 0.0489 - accuracy: 0.9771 - auc: 0.9986 - val_loss: 0.8746 - val_accuracy: 0.7937 - val_auc: 0.8932 - 7s/epoch - 92ms/step\n",
      "Epoch 34/100\n",
      "77/77 - 7s - loss: 0.0752 - accuracy: 0.9706 - auc: 0.9957 - val_loss: 2.1673 - val_accuracy: 0.6349 - val_auc: 0.7463 - 7s/epoch - 92ms/step\n",
      "Epoch 35/100\n",
      "77/77 - 7s - loss: 0.1116 - accuracy: 0.9559 - auc: 0.9905 - val_loss: 1.8001 - val_accuracy: 0.7302 - val_auc: 0.7811 - 7s/epoch - 89ms/step\n",
      "Epoch 36/100\n",
      "77/77 - 7s - loss: 0.0747 - accuracy: 0.9820 - auc: 0.9936 - val_loss: 0.2049 - val_accuracy: 0.9048 - val_auc: 0.9748 - 7s/epoch - 89ms/step\n",
      "Epoch 37/100\n",
      "77/77 - 7s - loss: 0.0813 - accuracy: 0.9706 - auc: 0.9948 - val_loss: 1.7136 - val_accuracy: 0.6508 - val_auc: 0.7571 - 7s/epoch - 89ms/step\n",
      "Epoch 38/100\n",
      "77/77 - 7s - loss: 0.0524 - accuracy: 0.9837 - auc: 0.9983 - val_loss: 0.6254 - val_accuracy: 0.7619 - val_auc: 0.9269 - 7s/epoch - 89ms/step\n",
      "Epoch 39/100\n",
      "77/77 - 7s - loss: 0.0497 - accuracy: 0.9837 - auc: 0.9969 - val_loss: 0.0393 - val_accuracy: 1.0000 - val_auc: 1.0000 - 7s/epoch - 89ms/step\n",
      "Epoch 40/100\n",
      "77/77 - 7s - loss: 0.0350 - accuracy: 0.9869 - auc: 0.9995 - val_loss: 0.0469 - val_accuracy: 1.0000 - val_auc: 1.0000 - 7s/epoch - 89ms/step\n",
      "Epoch 41/100\n",
      "77/77 - 7s - loss: 0.0319 - accuracy: 0.9918 - auc: 0.9977 - val_loss: 7.0417 - val_accuracy: 0.6032 - val_auc: 0.6130 - 7s/epoch - 89ms/step\n",
      "Epoch 42/100\n",
      "77/77 - 7s - loss: 0.0313 - accuracy: 0.9935 - auc: 0.9992 - val_loss: 0.2483 - val_accuracy: 0.9206 - val_auc: 0.9715 - 7s/epoch - 89ms/step\n",
      "Epoch 43/100\n",
      "77/77 - 7s - loss: 0.0607 - accuracy: 0.9804 - auc: 0.9978 - val_loss: 0.1429 - val_accuracy: 0.9524 - val_auc: 0.9902 - 7s/epoch - 89ms/step\n",
      "Epoch 44/100\n",
      "77/77 - 7s - loss: 0.0538 - accuracy: 0.9771 - auc: 0.9983 - val_loss: 0.2524 - val_accuracy: 0.8730 - val_auc: 0.9718 - 7s/epoch - 89ms/step\n",
      "Epoch 45/100\n",
      "77/77 - 7s - loss: 0.0243 - accuracy: 0.9951 - auc: 0.9996 - val_loss: 0.0905 - val_accuracy: 0.9683 - val_auc: 0.9965 - 7s/epoch - 89ms/step\n",
      "Epoch 46/100\n",
      "77/77 - 7s - loss: 0.0765 - accuracy: 0.9706 - auc: 0.9954 - val_loss: 0.0819 - val_accuracy: 0.9841 - val_auc: 0.9977 - 7s/epoch - 88ms/step\n",
      "Epoch 47/100\n",
      "77/77 - 7s - loss: 0.0567 - accuracy: 0.9739 - auc: 0.9983 - val_loss: 0.2685 - val_accuracy: 0.8889 - val_auc: 0.9698 - 7s/epoch - 89ms/step\n",
      "Epoch 48/100\n",
      "77/77 - 7s - loss: 0.0608 - accuracy: 0.9722 - auc: 0.9978 - val_loss: 1.1227 - val_accuracy: 0.7302 - val_auc: 0.8493 - 7s/epoch - 89ms/step\n",
      "Epoch 49/100\n",
      "77/77 - 7s - loss: 0.0172 - accuracy: 0.9951 - auc: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9683 - val_auc: 0.9940 - 7s/epoch - 87ms/step\n",
      "Epoch 50/100\n",
      "77/77 - 7s - loss: 0.0152 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9683 - val_auc: 0.9990 - 7s/epoch - 88ms/step\n",
      "Epoch 51/100\n",
      "77/77 - 7s - loss: 0.0246 - accuracy: 0.9853 - auc: 0.9997 - val_loss: 0.1179 - val_accuracy: 0.9524 - val_auc: 0.9917 - 7s/epoch - 88ms/step\n",
      "Epoch 52/100\n",
      "77/77 - 7s - loss: 0.0105 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9841 - val_auc: 0.9982 - 7s/epoch - 87ms/step\n",
      "Epoch 53/100\n",
      "77/77 - 7s - loss: 0.0103 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.2418 - val_accuracy: 0.9048 - val_auc: 0.9683 - 7s/epoch - 88ms/step\n",
      "Epoch 54/100\n",
      "77/77 - 7s - loss: 0.0958 - accuracy: 0.9673 - auc: 0.9941 - val_loss: 3.6270 - val_accuracy: 0.6508 - val_auc: 0.6783 - 7s/epoch - 88ms/step\n",
      "Epoch 55/100\n",
      "77/77 - 7s - loss: 0.0189 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 1.2155 - val_accuracy: 0.7143 - val_auc: 0.8186 - 7s/epoch - 88ms/step\n",
      "Epoch 56/100\n",
      "77/77 - 7s - loss: 0.0251 - accuracy: 0.9935 - auc: 0.9997 - val_loss: 2.8148 - val_accuracy: 0.6984 - val_auc: 0.7133 - 7s/epoch - 87ms/step\n",
      "Epoch 57/100\n",
      "77/77 - 7s - loss: 0.0262 - accuracy: 0.9918 - auc: 0.9995 - val_loss: 0.0437 - val_accuracy: 0.9841 - val_auc: 0.9997 - 7s/epoch - 87ms/step\n",
      "Epoch 58/100\n",
      "77/77 - 7s - loss: 0.0314 - accuracy: 0.9918 - auc: 0.9994 - val_loss: 0.4747 - val_accuracy: 0.7619 - val_auc: 0.9122 - 7s/epoch - 87ms/step\n",
      "Epoch 59/100\n",
      "77/77 - 7s - loss: 0.0272 - accuracy: 0.9869 - auc: 0.9996 - val_loss: 0.1117 - val_accuracy: 0.9524 - val_auc: 0.9922 - 7s/epoch - 87ms/step\n",
      "Epoch 60/100\n",
      "77/77 - 7s - loss: 0.0436 - accuracy: 0.9837 - auc: 0.9989 - val_loss: 5.8235 - val_accuracy: 0.6349 - val_auc: 0.6485 - 7s/epoch - 86ms/step\n",
      "Epoch 61/100\n",
      "77/77 - 7s - loss: 0.0180 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 0.4531 - val_accuracy: 0.8254 - val_auc: 0.9342 - 7s/epoch - 87ms/step\n",
      "Epoch 62/100\n",
      "77/77 - 7s - loss: 0.0285 - accuracy: 0.9902 - auc: 0.9997 - val_loss: 0.1624 - val_accuracy: 0.9683 - val_auc: 0.9738 - 7s/epoch - 87ms/step\n",
      "Epoch 63/100\n",
      "77/77 - 7s - loss: 0.0147 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.1217 - val_accuracy: 0.9365 - val_auc: 0.9890 - 7s/epoch - 87ms/step\n",
      "Epoch 64/100\n",
      "77/77 - 7s - loss: 0.0229 - accuracy: 0.9886 - auc: 0.9998 - val_loss: 3.5619 - val_accuracy: 0.6825 - val_auc: 0.6863 - 7s/epoch - 87ms/step\n",
      "Epoch 65/100\n",
      "77/77 - 7s - loss: 0.0133 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.3074 - val_accuracy: 0.8571 - val_auc: 0.9562 - 7s/epoch - 87ms/step\n",
      "Epoch 66/100\n",
      "77/77 - 7s - loss: 0.0471 - accuracy: 0.9869 - auc: 0.9970 - val_loss: 0.1555 - val_accuracy: 0.9206 - val_auc: 0.9846 - 7s/epoch - 87ms/step\n",
      "Epoch 67/100\n",
      "77/77 - 7s - loss: 0.0098 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9365 - val_auc: 0.9929 - 7s/epoch - 87ms/step\n",
      "Epoch 68/100\n",
      "77/77 - 7s - loss: 0.0090 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.7817 - val_accuracy: 0.7937 - val_auc: 0.8883 - 7s/epoch - 86ms/step\n",
      "Epoch 69/100\n",
      "77/77 - 7s - loss: 0.0241 - accuracy: 0.9935 - auc: 0.9980 - val_loss: 2.7518 - val_accuracy: 0.6667 - val_auc: 0.7075 - 7s/epoch - 86ms/step\n",
      "Epoch 70/100\n",
      "77/77 - 7s - loss: 0.0583 - accuracy: 0.9788 - auc: 0.9967 - val_loss: 0.3636 - val_accuracy: 0.8730 - val_auc: 0.9504 - 7s/epoch - 87ms/step\n",
      "Epoch 71/100\n",
      "77/77 - 7s - loss: 0.0114 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 0.1745 - val_accuracy: 0.9206 - val_auc: 0.9843 - 7s/epoch - 86ms/step\n",
      "Epoch 72/100\n",
      "77/77 - 7s - loss: 0.0637 - accuracy: 0.9788 - auc: 0.9957 - val_loss: 1.0827 - val_accuracy: 0.6984 - val_auc: 0.8299 - 7s/epoch - 86ms/step\n",
      "Epoch 73/100\n",
      "77/77 - 7s - loss: 0.0149 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.2604 - val_accuracy: 0.9365 - val_auc: 0.9685 - 7s/epoch - 88ms/step\n",
      "Epoch 74/100\n",
      "77/77 - 7s - loss: 0.0409 - accuracy: 0.9902 - auc: 0.9978 - val_loss: 0.4213 - val_accuracy: 0.8095 - val_auc: 0.8977 - 7s/epoch - 86ms/step\n",
      "Epoch 75/100\n",
      "77/77 - 7s - loss: 0.0835 - accuracy: 0.9771 - auc: 0.9934 - val_loss: 0.1106 - val_accuracy: 0.9524 - val_auc: 0.9927 - 7s/epoch - 86ms/step\n",
      "Epoch 76/100\n",
      "77/77 - 7s - loss: 0.0126 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9841 - val_auc: 0.9945 - 7s/epoch - 88ms/step\n",
      "Epoch 77/100\n",
      "77/77 - 7s - loss: 0.0219 - accuracy: 0.9935 - auc: 0.9998 - val_loss: 0.0401 - val_accuracy: 0.9841 - val_auc: 0.9997 - 7s/epoch - 88ms/step\n",
      "Epoch 78/100\n",
      "77/77 - 7s - loss: 0.0353 - accuracy: 0.9902 - auc: 0.9961 - val_loss: 0.0684 - val_accuracy: 0.9683 - val_auc: 0.9982 - 7s/epoch - 86ms/step\n",
      "Epoch 79/100\n",
      "77/77 - 7s - loss: 0.0524 - accuracy: 0.9820 - auc: 0.9983 - val_loss: 0.2895 - val_accuracy: 0.8730 - val_auc: 0.9622 - 7s/epoch - 87ms/step\n",
      "Epoch 80/100\n",
      "77/77 - 7s - loss: 0.0288 - accuracy: 0.9918 - auc: 0.9993 - val_loss: 1.7729 - val_accuracy: 0.7302 - val_auc: 0.8143 - 7s/epoch - 87ms/step\n",
      "Epoch 81/100\n",
      "77/77 - 7s - loss: 0.0318 - accuracy: 0.9918 - auc: 0.9986 - val_loss: 0.0765 - val_accuracy: 0.9365 - val_auc: 0.9955 - 7s/epoch - 87ms/step\n",
      "Epoch 82/100\n",
      "77/77 - 7s - loss: 0.0232 - accuracy: 0.9935 - auc: 0.9981 - val_loss: 0.2562 - val_accuracy: 0.9365 - val_auc: 0.9680 - 7s/epoch - 87ms/step\n",
      "Epoch 83/100\n",
      "77/77 - 7s - loss: 0.0064 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9365 - val_auc: 0.9549 - 7s/epoch - 87ms/step\n",
      "Epoch 84/100\n",
      "77/77 - 7s - loss: 0.0169 - accuracy: 0.9951 - auc: 0.9996 - val_loss: 0.6085 - val_accuracy: 0.7460 - val_auc: 0.8996 - 7s/epoch - 87ms/step\n",
      "Epoch 85/100\n",
      "77/77 - 7s - loss: 0.0204 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 0.0817 - val_accuracy: 0.9841 - val_auc: 0.9960 - 7s/epoch - 86ms/step\n",
      "Epoch 86/100\n",
      "77/77 - 7s - loss: 0.0180 - accuracy: 0.9935 - auc: 0.9999 - val_loss: 2.9791 - val_accuracy: 0.6825 - val_auc: 0.7053 - 7s/epoch - 87ms/step\n",
      "Epoch 87/100\n",
      "77/77 - 7s - loss: 0.0117 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9365 - val_auc: 0.9635 - 7s/epoch - 87ms/step\n",
      "Epoch 88/100\n",
      "77/77 - 7s - loss: 0.0131 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 2.8999 - val_accuracy: 0.6984 - val_auc: 0.7065 - 7s/epoch - 87ms/step\n",
      "Epoch 89/100\n",
      "77/77 - 7s - loss: 0.0168 - accuracy: 0.9967 - auc: 0.9998 - val_loss: 0.3794 - val_accuracy: 0.9206 - val_auc: 0.9509 - 7s/epoch - 87ms/step\n",
      "Epoch 90/100\n",
      "77/77 - 7s - loss: 0.0192 - accuracy: 0.9935 - auc: 0.9998 - val_loss: 0.5392 - val_accuracy: 0.8095 - val_auc: 0.9365 - 7s/epoch - 86ms/step\n",
      "Epoch 91/100\n",
      "77/77 - 7s - loss: 0.0467 - accuracy: 0.9820 - auc: 0.9987 - val_loss: 0.1050 - val_accuracy: 0.9524 - val_auc: 0.9942 - 7s/epoch - 86ms/step\n",
      "Epoch 92/100\n",
      "77/77 - 7s - loss: 0.0287 - accuracy: 0.9886 - auc: 0.9995 - val_loss: 0.2219 - val_accuracy: 0.9206 - val_auc: 0.9723 - 7s/epoch - 86ms/step\n",
      "Epoch 93/100\n",
      "77/77 - 7s - loss: 0.0164 - accuracy: 0.9951 - auc: 0.9998 - val_loss: 0.1962 - val_accuracy: 0.9365 - val_auc: 0.9720 - 7s/epoch - 87ms/step\n",
      "Epoch 94/100\n",
      "77/77 - 7s - loss: 0.0404 - accuracy: 0.9869 - auc: 0.9988 - val_loss: 0.6408 - val_accuracy: 0.7619 - val_auc: 0.8894 - 7s/epoch - 87ms/step\n",
      "Epoch 95/100\n",
      "77/77 - 7s - loss: 0.0292 - accuracy: 0.9902 - auc: 0.9994 - val_loss: 0.3108 - val_accuracy: 0.8730 - val_auc: 0.9589 - 7s/epoch - 86ms/step\n",
      "Epoch 96/100\n",
      "77/77 - 7s - loss: 0.0123 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 1.8888 - val_accuracy: 0.7143 - val_auc: 0.7417 - 7s/epoch - 87ms/step\n",
      "Epoch 97/100\n",
      "77/77 - 7s - loss: 0.0158 - accuracy: 0.9951 - auc: 0.9999 - val_loss: 0.7644 - val_accuracy: 0.8095 - val_auc: 0.8770 - 7s/epoch - 87ms/step\n",
      "Epoch 98/100\n",
      "77/77 - 7s - loss: 0.0556 - accuracy: 0.9853 - auc: 0.9954 - val_loss: 0.4312 - val_accuracy: 0.8095 - val_auc: 0.9257 - 7s/epoch - 86ms/step\n",
      "Epoch 99/100\n",
      "77/77 - 7s - loss: 0.0139 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 5.1322 - val_accuracy: 0.6190 - val_auc: 0.6561 - 7s/epoch - 87ms/step\n",
      "Epoch 100/100\n",
      "77/77 - 7s - loss: 0.0382 - accuracy: 0.9902 - auc: 0.9976 - val_loss: 0.1829 - val_accuracy: 0.9365 - val_auc: 0.9748 - 7s/epoch - 86ms/step\n",
      "2/2 [==============================] - 1s 905ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00        63\n",
      "   macro avg       1.00      1.00      1.00        63\n",
      "weighted avg       1.00      1.00      1.00        63\n",
      "\n",
      "Roc 1.0\n",
      "Confusion Matrix\n",
      "[[32  0]\n",
      " [ 0 31]]\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 19.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 51.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 51.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9583333333333334, 'f1-score': 0.9787234042553191, 'support': 48.0}, '1': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 64.0}, 'accuracy': 0.9821428571428571, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.9791666666666667, 'f1-score': 0.9816693944353518, 'support': 112.0}, 'weighted avg': {'precision': 0.9826839826839827, 'recall': 0.9821428571428571, 'f1-score': 0.9820902501753566, 'support': 112.0}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35.0}, '1': {'precision': 1.0, 'recall': 0.9841269841269841, 'f1-score': 0.9919999999999999, 'support': 63.0}, 'accuracy': 0.9897959183673469, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9920634920634921, 'f1-score': 0.9889577464788731, 'support': 98.0}, 'weighted avg': {'precision': 0.990079365079365, 'recall': 0.9897959183673469, 'f1-score': 0.9898269617706237, 'support': 98.0}}\n",
      "{'0': {'precision': 0.8378378378378378, 'recall': 0.96875, 'f1-score': 0.8985507246376812, 'support': 32.0}, '1': {'precision': 0.9767441860465116, 'recall': 0.875, 'f1-score': 0.923076923076923, 'support': 48.0}, 'accuracy': 0.9125, 'macro avg': {'precision': 0.9072910119421747, 'recall': 0.921875, 'f1-score': 0.910813823857302, 'support': 80.0}, 'weighted avg': {'precision': 0.921181646763042, 'recall': 0.9125, 'f1-score': 0.9132664437012263, 'support': 80.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 63.0}}\n",
      "Mean accuracy 0.976887755102041\n",
      "Mean precision 0.9787889989052779\n",
      "Mean recall 0.976887755102041\n",
      "Mean F1 0.9770367311294412\n",
      "None\n",
      "AUC\n",
      "0.9872709396258503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "#from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow\n",
    "\n",
    "def concilie_per_patient_res(predx, y_test, usercodes):\n",
    "    new_pred = []\n",
    "    new_y_test = []\n",
    "     \n",
    "    #print('Prediced shape')\n",
    "    #print(predx.shape)\n",
    "    \n",
    "    if y_test.shape[-1] < 2:\n",
    "      y_test = to_categorical(y_test)\n",
    "    patient = {}\n",
    "    for i in range(len(y_test)):\n",
    "      if not usercodes[i] in patient:\n",
    "        patient[usercodes[i]] = {}\n",
    "        patient[usercodes[i]]['predicted'] = []\n",
    "        patient[usercodes[i]]['y_test'] = []               \n",
    "      patient[usercodes[i]]['predicted'].append(predx[i])\n",
    "      patient[usercodes[i]]['y_test'].append(y_test[i])\n",
    "      #print(patient[usercodes[i]]['predicted'])\n",
    "    keys = list(patient.keys())\n",
    "    for key in keys:\n",
    "       predi = patient[key]['predicted']\n",
    "       yi = patient[key]['y_test']\n",
    "       mean_pred = np.asarray(predi).mean(axis=0)\n",
    "       mean_y = np.asarray(yi).mean(axis=0)\n",
    "       #print('Mean pred shape '+str(mean_pred.shape))\n",
    "       #print('Mean y shape '+str(mean_y.shape))\n",
    "       new_pred.append(mean_pred)\n",
    "       new_y_test.append(mean_y)\n",
    "\n",
    "    new_pred = np.asarray(new_pred)\n",
    "    #print(new_pred.shape)\n",
    "    new_y_test = np.asarray(new_y_test)\n",
    "    #print(new_y_test.shape)\n",
    "\n",
    "    return new_pred, new_y_test\n",
    "    \n",
    " \n",
    "\n",
    "def report_average(reports):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for report in reports:\n",
    "        print(report)\n",
    "        accuracy.append(report['accuracy'])\n",
    "        precision.append(report['weighted avg']['precision'])\n",
    "        recall.append(report['weighted avg']['recall'])\n",
    "        f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "    print('Mean accuracy '+str(np.mean(accuracy)))\n",
    "    print('Mean precision ' + str(np.mean(precision)))\n",
    "    print('Mean recall ' + str(np.mean(recall)))\n",
    "    print('Mean F1 ' + str(np.mean(f1)))\n",
    "\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    " \n",
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "          \n",
    " \n",
    "for i in range(5):\n",
    "    #K.clear_session()#puliamo la ram della GPU \n",
    "    tf.keras.backend.clear_session()\n",
    " \n",
    "    y_new = np.asarray(y,dtype=np.float32)\n",
    "    X_new = np.asarray(X,dtype=np.float32)\n",
    "    y_size = 0\n",
    "\n",
    "    \n",
    "    if True:\n",
    "      #while y_size < int(len(X_new)*0.05):\n",
    "     \n",
    "      X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.1)\n",
    "      cd = np.where(y_train == to_categorical([1.0]))\n",
    "      cd2 = np.where(y_train ==  to_categorical([2.0]))\n",
    "      y_size = len(cd2[0])\n",
    "      print('y size',y_size)\n",
    "      print('other size',len(cd[0]))\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    "    print(test_usercodes)\n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    "\n",
    "    input_shape = (1, X_train[0].shape[1])\n",
    "    #report_standard_algo(X_train.copy(),X_test.copy(),y_train.copy(),y_test.copy(),train_usercodes,test_usercodes)\n",
    "\n",
    "\n",
    "    \n",
    "     \n",
    "    for k in range(1):\n",
    "      model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='vision_transformer'+str(i)+'.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "      strategy = tf.distribute.MirroredStrategy()\n",
    "      with strategy.scope():\n",
    "          # Everything that creates variables should be under the strategy scope.\n",
    "          # In general this is only model construction & `compile()`.\n",
    "            X_train = X_train.reshape(X_train.shape[0],X_train.shape[2],1)\n",
    "            X_test = X_test.reshape(X_test.shape[0],X_test.shape[2],1)\n",
    "            #Layer 1 =  13% , layer 2 = 11%, Layer 3 17%, Layer 4 10%, Layer 5 26%, Layer 6 22%\n",
    "            #input_shape = (X_train[0].shape[1:]) \n",
    "            input_signal = tensorflow.keras.layers.Input(shape=(X_train[0].shape[0], 1))\n",
    "\n",
    "            #input_signal = keras.layers.Input(input_shape)\n",
    "            vec = 10\n",
    "            encod_dim = int(X_train.shape[1]/1000)\n",
    "            \n",
    "            #print('Encoding dim',encod_dim)\n",
    "            #hht = HilbertHuangTransformSVD(encoding_dim=encod_dim, sound_shape =encod_dim , units=32)(input_signal)\n",
    "            \n",
    "            '''\n",
    "            hht = HilbertHuangTransformSVD(max_imf = 5)(input_signal)\n",
    "            #hht = HilbertHuangTransformAttention(max_imfs=vec)(input_signal)\n",
    "            #hht = tf.keras.layers.Reshape((-1, vec))(hht)  # Add Reshape layer to remove extra dimension\n",
    "            #conv1 = tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(hht)\n",
    "            #maxpool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
    "            #conv2 = tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(maxpool1)\n",
    "            #maxpool2 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
    "            hht = tf.squeeze(hht, axis=2)\n",
    "            gap = tf.keras.layers.GlobalAveragePooling1D()(hht)\n",
    "            dense = tf.keras.layers.Dense(64, activation='relu')(gap)\n",
    "            output = tf.keras.layers.Dense(2, activation='softmax')(dense)\n",
    "\n",
    "            model = keras.Model(inputs=input_signal, outputs=output)\n",
    "            '''\n",
    "            #model = tcn(input_shape=input_signal.shape, num_classes=2, nb_filters=2, kernel_size=21, nb_stacks=1, max_blocks=4) \n",
    "            #model = build_tdnn((220500, 1), 2)\n",
    "            input_shape = (220500, 1)\n",
    "            model = build_samplecnn(input_shape, 2)\n",
    "\n",
    "\n",
    "            #model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy','AUC'])\n",
    "            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                          loss=\"categorical_crossentropy\",\n",
    "                           metrics=['accuracy','AUC'])\n",
    "      \n",
    "      \n",
    "      history = model.fit(X_train,y_train, epochs=100, batch_size=8,  validation_data = (X_test,y_test), \n",
    "                                callbacks=[model_checkpoint_callback], verbose=2)\n",
    "      model2 = model\n",
    "          \n",
    "          \n",
    "          \n",
    "      if model2 != None:\n",
    "        model2.load_weights('vision_transformer'+str(i)+'.h5')\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        \n",
    "        new_pred = y_pred\n",
    "        new_y_test = y_test\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "        aa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "        aucs.append(roc_auc)\n",
    "        # Plot non-normalized confusion matrix\n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "\n",
    "\n",
    "\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl-BWlxmT0d1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMJ2LUiIiYmH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZCWd4x1X2ne"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VkeuiOoT0d4",
    "outputId": "3bc88bb0-01e2-4436-9c38-56c681946fe6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5aGfwzXnxM7z"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "rand = random.Random(42)\n",
    "#Dentamaro et al.\n",
    "def inter_patient_scheme(X,lbls,filenames, test_size = 0.2):\n",
    "  people_index = {}\n",
    "  people_class = {}\n",
    "  X = np.asarray(X)\n",
    "  \n",
    "  for i in range(len(filenames)):\n",
    "        \n",
    "      usercode = filenames[i]\n",
    "\n",
    "      if not usercode in people_class:\n",
    "        people_class[usercode] = lbls[i]\n",
    "      if usercode in people_index:\n",
    "        people_index[usercode].append(i)\n",
    "      else:\n",
    "        people_index[usercode] = []\n",
    "        people_index[usercode].append(i)\n",
    "\n",
    "  keys = list(people_index.keys())\n",
    "  rand.shuffle(keys)\n",
    "\n",
    "  peoples_in_train = math.floor(len(keys)*(1.-test_size)) #len(keys) * 80% = 80% training \n",
    "  people_in_test = len(keys)-peoples_in_train #len(keys) - 80%\n",
    "  temp_classes = []\n",
    "  j = 0\n",
    "  for k in keys:\n",
    "    if j < peoples_in_train:\n",
    "      temp_classes.append(people_class[k]) #808 di 1 e 0 a seconda che vengano processate chiavi HC o PD\n",
    "      #print(\"temp_classes: \" + str(temp_classes))\n",
    "    j += 1\n",
    "\n",
    "  unique, counts = np.unique(temp_classes, return_counts=True) \n",
    "  min_index = np.where(counts == np.min(counts))\n",
    "  min_people = np.min(counts)\n",
    "  min_class = unique[min_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  #print(peoples_in_train)\n",
    "  training_items = []\n",
    "  testing_items = []\n",
    "\n",
    "  class_counter = {}\n",
    "\n",
    "  train_usercodes = []\n",
    "  test_usercodes = []\n",
    "  #per people balance \n",
    "  for j in range(peoples_in_train):\n",
    "    index = people_index[keys[j]]\n",
    "    \n",
    "    this_class = people_class[keys[j]]\n",
    "\n",
    "\n",
    "    if not this_class in class_counter:\n",
    "      class_counter[this_class] = 0\n",
    "    \n",
    "    if this_class != min_class and class_counter[this_class] < min_people:      \n",
    "      for h in index:\n",
    "        training_items.append(h)\n",
    "        train_usercodes.append(keys[j])\n",
    "      class_counter[this_class] += 1\n",
    "    elif this_class != min_class and class_counter[this_class] >= min_people :\n",
    "       for h in index:\n",
    "          pass\n",
    "          #testing_items.append(h)\n",
    "       #class_counter[this_class] += 1\n",
    "    else:\n",
    "      for h in index:\n",
    "        training_items.append(h)\n",
    "        train_usercodes.append(keys[j])\n",
    "      class_counter[this_class] += 1\n",
    "  \n",
    "  temp_classes = []\n",
    "  j = 0\n",
    "  for k in keys:\n",
    "    if j >= peoples_in_train:\n",
    "      temp_classes.append(people_class[k]) #da 808 in poi di 0 e 1\n",
    "    j += 1\n",
    "\n",
    "  class_counter = {}\n",
    "  unique, counts = np.unique(temp_classes, return_counts=True)\n",
    "  min_index = np.where(counts == np.min(counts))\n",
    "  min_people = np.min(counts)\n",
    "  min_class = unique[min_index]\n",
    "\n",
    "\n",
    "\n",
    "  for j in range(peoples_in_train, len(keys)):\n",
    "    index = people_index[keys[j]]\n",
    "    \n",
    "    this_class = people_class[keys[j]]\n",
    "    \n",
    "\n",
    "    if not this_class in class_counter:\n",
    "      class_counter[this_class] = 0\n",
    "    \n",
    "    if this_class != min_class[0] and class_counter[this_class] < min_people:      \n",
    "      for h in index:\n",
    "        testing_items.append(h)\n",
    "        test_usercodes.append(keys[j])\n",
    "        #print('Negative index --> '+str(h))\n",
    "      \n",
    "      class_counter[this_class] += 1\n",
    "    elif this_class == min_class[0]:\n",
    "      for h in index:\n",
    "        testing_items.append(h)\n",
    "        test_usercodes.append(keys[j])\n",
    "        #print('Positive index --> '+str(h))\n",
    "    \n",
    "  \n",
    "\n",
    "  \n",
    "  testing_items = np.asarray(testing_items)\n",
    "  training_items = np.asarray(training_items)\n",
    "  #lbls = np.asarray(lbls)\n",
    "  yy = to_categorical(lbls)\n",
    "  X_train = X[training_items,:]\n",
    "  y_train = yy[training_items,:]\n",
    "  X_test = X[testing_items,:]\n",
    "  y_test = yy[testing_items,:]\n",
    "  #print(y_test)\n",
    "  ffn = np.asarray(filenames)[training_items]\n",
    "\n",
    "  #for j in range(len(lbls)):\n",
    "    #print(str(yy[j])+ ' --> '+str(lbls[j]))\n",
    "\n",
    "  return X_train, X_test, y_train, y_test,train_usercodes, test_usercodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Layer\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "def hilbert_transform(tensor):\n",
    "    N = tensor.shape[-2]\n",
    "    tensor_fft = tf.signal.fft(tf.cast(tensor, tf.complex64))\n",
    "    h = tf.concat([tf.ones((N + 1) // 2, dtype=tf.complex64), tf.zeros(N // 2, dtype=tf.complex64)], axis=0)\n",
    "    return tf.signal.ifft(tensor_fft * h)\n",
    "\n",
    "class HilbertHuangTransform(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_imfs=5, units=32,**kwargs):\n",
    "        super(HilbertHuangTransform, self).__init__(**kwargs)\n",
    "        self.max_imfs = max_imfs\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(HilbertHuangTransform, self).build(input_shape)\n",
    "        \n",
    "    def sifting(self, tensor, max_iters=100, threshold=1e-4):\n",
    "        tensor = tf.expand_dims(tensor, axis=1)\n",
    "        for _ in tf.range(max_iters):\n",
    "            local_min = tf.keras.layers.AveragePooling1D(3, strides=1, padding='same')(tensor)\n",
    "            local_max = tf.keras.layers.MaxPooling1D(3, strides=1, padding='same')(tensor)\n",
    "\n",
    "            env_mean = (local_min + local_max) / 2\n",
    "            deviation = tf.reduce_mean(tf.abs(env_mean - tensor))\n",
    "\n",
    "            if deviation < threshold:\n",
    "                break\n",
    "\n",
    "            tensor = tensor - env_mean\n",
    "        tensor = tf.squeeze(tensor, axis=1)\n",
    "        return tensor\n",
    "\n",
    "    def emd(self, tensor):\n",
    "        imfs = []\n",
    "        residual = tensor\n",
    "\n",
    "        for _ in range(self.max_imfs):\n",
    "            imf = self.sifting(residual)\n",
    "            residual = residual - imf\n",
    "            imfs.append(imf)\n",
    "\n",
    "        return tf.stack(imfs, axis=-1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        imfs = tf.map_fn(self.emd, x, fn_output_signature=tf.TensorSpec(shape=(None, None, self.max_imfs), dtype=tf.float32))\n",
    "            #q = self.W1(imfs)\n",
    "        #k = self.W2(imfs)\n",
    "        \n",
    "        # Compute the score using the dot product\n",
    "        #score = tf.matmul(q, k, transpose_b=True)\n",
    "        #attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        \n",
    "        # Compute the attended IMFs\n",
    "        #attended_imfs = tf.matmul(attention_weights, imfs)\n",
    "        analytic_signal = hilbert_transform(imfs)#hilbert_transform(attended_imfs)\n",
    "        amplitude = tf.abs(analytic_signal)\n",
    "        return amplitude \n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (*input_shape[:-1], self.max_imfs)\n",
    "    \n",
    "    \n",
    "\n",
    "class HilbertHuangTransformAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_imfs=5, units=32,**kwargs):\n",
    "        super(HilbertHuangTransformAttention, self).__init__(**kwargs)\n",
    "        self.max_imfs = max_imfs\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(HilbertHuangTransformAttention, self).build(input_shape)\n",
    "\n",
    "\n",
    "   \n",
    "    def sifting(self, tensor, max_iters=100, threshold=1e-4):\n",
    "        tensor = tf.expand_dims(tensor, axis=1)\n",
    "        for _ in tf.range(max_iters):\n",
    "            local_min = tf.keras.layers.AveragePooling1D(3, strides=1, padding='same')(tensor)\n",
    "            local_max = tf.keras.layers.MaxPooling1D(3, strides=1, padding='same')(tensor)\n",
    "\n",
    "            env_mean = (local_min + local_max) / 2\n",
    "            deviation = tf.reduce_mean(tf.abs(env_mean - tensor))\n",
    "\n",
    "            if deviation < threshold:\n",
    "                break\n",
    "\n",
    "            tensor = tensor - env_mean\n",
    "        tensor = tf.squeeze(tensor, axis=1)\n",
    "        return tensor\n",
    "\n",
    "    def emd(self, tensor):\n",
    "        imfs = []\n",
    "        residual = tensor\n",
    "\n",
    "        for _ in range(self.max_imfs):\n",
    "            imf = self.sifting(residual)\n",
    "            residual = residual - imf\n",
    "            imfs.append(imf)\n",
    "\n",
    "        return tf.stack(imfs, axis=-1)\n",
    "    def call(self, x):\n",
    "        imfs = tf.map_fn(self.emd, x, fn_output_signature=tf.TensorSpec(shape=(None, None, self.max_imfs), dtype=tf.float32))\n",
    "        q = self.W1(imfs)\n",
    "        k = self.W2(imfs)\n",
    "        \n",
    "        # Compute the score using the dot product\n",
    "        score = tf.matmul(q, k, transpose_b=True)\n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        \n",
    "        # Compute the attended IMFs\n",
    "        attended_imfs = tf.matmul(attention_weights, imfs)\n",
    "        analytic_signal = hilbert_transform(attended_imfs)\n",
    "        amplitude = tf.abs(analytic_signal)\n",
    "        return amplitude \n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (*input_shape[:-1], self.max_imfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class HilbertHuangTransformSVD(Layer):\n",
    "    def __init__(self, num_vectors, units=32, **kwargs):\n",
    "        super(HilbertHuangTransformSVD, self).__init__(**kwargs)\n",
    "        self.num_vectors = num_vectors\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        svd_signal = self.svd(x)\n",
    "        #q = self.W1(svd_signal)\n",
    "        #k = self.W2(svd_signal)\n",
    "        \n",
    "        # Compute the score using the dot product\n",
    "        #score = tf.matmul(q, k, transpose_b=True)\n",
    "        #attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "         \n",
    "        #attended_svds = tf.matmul(attention_weights, svd_signal)\n",
    "        analytic_signal = self.hilbert_transform(svd_signal)\n",
    "        magnitude = tf.abs(analytic_signal)\n",
    "        return magnitude\n",
    "\n",
    "    def svd(self, x):\n",
    "        s, u, v = tf.linalg.svd(x, compute_uv=True, full_matrices=False)\n",
    "        svd_signal = tf.matmul(u[:, :, :self.num_vectors], tf.linalg.diag(s[:, :self.num_vectors]))\n",
    "        return svd_signal\n",
    "\n",
    "    def hilbert_transform(self, x):\n",
    "        x = tf.squeeze(x, axis=-1)\n",
    "        fft_x = tf.signal.fft(tf.cast(x, tf.complex64))\n",
    "        h = tf.zeros_like(fft_x)\n",
    "        h_len = tf.shape(h)[-1] // 2\n",
    "        h = tf.concat([tf.ones(h_len), tf.zeros(1), tf.zeros(h_len - 1)], axis=0)\n",
    "        hilbert_x = tf.signal.ifft(fft_x * tf.cast(h, tf.complex64))\n",
    "        analytic_signal = tf.expand_dims(hilbert_x, axis=-1)\n",
    "        return analytic_signal\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(HilbertHuangTransformSVD, self).get_config()\n",
    "        config.update({'num_vectors': self.num_vectors})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, Conv2D, Conv1D, Add, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "def attach_attention_module(net, attention_module, activation=Activation('relu'), ratio = 8):\n",
    "  if attention_module == 'se_block': # SE_block\n",
    "    net = se_block(net, activation=activation, ratio=ratio)\n",
    "  elif attention_module == 'cbam_block': # CBAM_block\n",
    "    net = cbam_block(net, activation=activation, ratio=ratio)\n",
    "  elif attention_module == 'dbam_block': # CBAM_block\n",
    "    net = dbam_block(net, activation=activation)\n",
    "  elif attention_module == 'eca_block': # CBAM_block\n",
    "    net = ecanet(net)\n",
    "  else:\n",
    "    pass\n",
    "  return net\n",
    "\n",
    "def se_block(input_feature, ratio=8, activation='relu'):\n",
    "\t\"\"\"Contains the implementation of Squeeze-and-Excitation(SE) block.\n",
    "\tAs described in https://arxiv.org/abs/1709.01507.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\tchannel = input_feature.shape[channel_axis]\n",
    "\n",
    "\tse_feature = GlobalAveragePooling2D()(input_feature)\n",
    "\tse_feature = Reshape((1, 1, channel))(se_feature)\n",
    "\tassert se_feature.shape[1:] == (1,1,channel)\n",
    "\n",
    "  \n",
    "\tse_feature = Dense(channel // ratio,\n",
    "\t\t\t\t\t   kernel_initializer='he_normal',\n",
    "\t\t\t\t\t   use_bias=True,\n",
    "\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n",
    "\tse_feature  = Activation(activation)(se_feature)\n",
    "\n",
    "\n",
    "\t#se_feature = SinusodialRepresentationDense(channel // ratio,activation='sine', w0=1.0)(se_feature)#72 auc\n",
    "\tassert se_feature.shape[1:] == (1,1,channel//ratio)\n",
    "\tse_feature = Dense(channel,\n",
    "\t\t\t\t\t   activation='sigmoid',\n",
    "\t\t\t\t\t   kernel_initializer='he_normal',\n",
    "\t\t\t\t\t   use_bias=True,\n",
    "\t\t\t\t\t   bias_initializer='zeros')(se_feature)\n",
    "\tassert se_feature.shape[1:] == (1,1,channel)\n",
    "\tif K.image_data_format() == 'channels_first':\n",
    "\t\tse_feature = Permute((3, 1, 2))(se_feature)\n",
    "\n",
    "\tse_feature = multiply([input_feature, se_feature])\n",
    "\treturn se_feature\n",
    "def dbam_block(cbam_feature, ratio=8, activation='relu'):\n",
    "\n",
    "\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "\tAs described in https://arxiv.org/abs/1807.06521.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tcbam_feature = se_block(cbam_feature, ratio)#channel_attention(cbam_feature, ratio)\n",
    "\tcbam_feature = spatial_attention(cbam_feature)\n",
    "\treturn cbam_feature\n",
    "\t \n",
    "def cbam_block(cbam_feature, ratio=8, activation='relu'):\n",
    "\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "\tAs described in https://arxiv.org/abs/1807.06521.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tcbam_feature = channel_attention(cbam_feature, ratio)\n",
    "\tcbam_feature = spatial_attention(cbam_feature)\n",
    "\treturn cbam_feature\n",
    "\t \n",
    "\n",
    "def ecanet(input_feature,gamma=2,b=1,):\n",
    "  channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "  channels = input_feature.shape[channel_axis]\n",
    "  t = int(abs((math.log(channels,2)+b)/gamma))\n",
    "  k = t if t%2 else t+1\n",
    "  x_global_avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "  x = Reshape((channels,1))(x_global_avg_pool)\n",
    "  x = Conv1D(1,kernel_size=k,padding=\"same\")(x)\n",
    "  x = Activation('sigmoid')(x)  #shape=[batch,chnnels,1]\n",
    "  x = Reshape((1, 1, channels))(x)\n",
    "  output = multiply([input_feature,x])\n",
    "  return output\n",
    "\n",
    "\n",
    "def channel_attention(input_feature, ratio=8,activation='relu'):\n",
    "\t\n",
    "\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\tchannel = input_feature.shape[channel_axis]\n",
    "\t\n",
    "\tshared_layer_one = Dense(channel//ratio,\n",
    "\t\t\t\t\t\t\t activation=activation,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\tshared_layer_two = Dense(channel,\n",
    "\t\t\t\t\t\t\t kernel_initializer='he_normal',\n",
    "\t\t\t\t\t\t\t use_bias=True,\n",
    "\t\t\t\t\t\t\t bias_initializer='zeros')\n",
    "\t\n",
    "\tavg_pool = GlobalAveragePooling2D()(input_feature)    \n",
    "\tavg_pool = Reshape((1,1,channel))(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\tavg_pool = shared_layer_one(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tavg_pool = shared_layer_two(avg_pool)\n",
    "\tassert avg_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tmax_pool = GlobalMaxPooling2D()(input_feature)\n",
    "\tmax_pool = Reshape((1,1,channel))(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\tmax_pool = shared_layer_one(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n",
    "\tmax_pool = shared_layer_two(max_pool)\n",
    "\tassert max_pool.shape[1:] == (1,1,channel)\n",
    "\t\n",
    "\tcbam_feature = Add()([avg_pool,max_pool])\n",
    "\tcbam_feature = Activation('sigmoid')(cbam_feature)\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\n",
    "\treturn multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention(input_feature,activation='relu'):\n",
    "\tkernel_size = 7\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tchannel = input_feature.shape[1]\n",
    "\t\tcbam_feature = Permute((2,3,1))(input_feature)\n",
    "\telse:\n",
    "\t\tchannel = input_feature.shape[-1]\n",
    "\t\tcbam_feature = input_feature\n",
    "\t\n",
    "\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert avg_pool.shape[-1] == 1\n",
    "\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "\tassert max_pool.shape[-1] == 1\n",
    "\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n",
    "\tassert concat.shape[-1] == 2\n",
    "\tcbam_feature = Conv2D(filters = 1,\n",
    "\t\t\t\t\tkernel_size=kernel_size,\n",
    "\t\t\t\t\tstrides=1,\n",
    "\t\t\t\t\tpadding='same',\n",
    "\t\t\t\t\tactivation='sigmoid',\n",
    "\t\t\t\t\tkernel_initializer='he_normal',\n",
    "\t\t\t\t\tuse_bias=False)(concat)\t\n",
    "\tassert cbam_feature.shape[-1] == 1\n",
    "\t\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n",
    "\t\t\n",
    "\treturn multiply([input_feature, cbam_feature])\n",
    "\t\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Backend operations of Kapre.\n",
    "\n",
    "This module summarizes operations and functions that are used in Kapre layers.\n",
    "\n",
    "Attributes:\n",
    "    _CH_FIRST_STR (str): 'channels_first', a pre-defined string.\n",
    "    _CH_LAST_STR (str): 'channels_last', a pre-defined string.\n",
    "    _CH_DEFAULT_STR (str): 'default', a pre-defined string.\n",
    "\n",
    "\"\"\"\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow\n",
    "#tensorflow.random.set_seed(42)\n",
    "\n",
    "_CH_FIRST_STR = 'channels_first'\n",
    "_CH_LAST_STR = 'channels_last'\n",
    "_CH_DEFAULT_STR = 'default'\n",
    "\n",
    "\n",
    "def get_window_fn(window_name=None):\n",
    "    \"\"\"Return a window function given its name.\n",
    "    This function is used inside layers such as `STFT` to get a window function.\n",
    "\n",
    "    Args:\n",
    "        window_name (None or str): name of window function. On Tensorflow 2.3, there are five windows available in\n",
    "        `tf.signal` (`hamming_window`, `hann_window`, `kaiser_bessel_derived_window`, `kaiser_window`, `vorbis_window`).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if window_name is None:\n",
    "        return tf.signal.hann_window\n",
    "\n",
    "    available_windows = {\n",
    "        'hamming_window': tf.signal.hamming_window,\n",
    "        'hann_window': tf.signal.hann_window,\n",
    "    }\n",
    "    if hasattr(tf.signal, 'kaiser_bessel_derived_window'):\n",
    "        available_windows['kaiser_bessel_derived_window'] = tf.signal.kaiser_bessel_derived_window\n",
    "    if hasattr(tf.signal, 'kaiser_window'):\n",
    "        available_windows['kaiser_window'] = tf.signal.kaiser_window\n",
    "    if hasattr(tf.signal, 'vorbis_window'):\n",
    "        available_windows['vorbis_window'] = tf.signal.vorbis_window\n",
    "\n",
    "    if window_name not in available_windows:\n",
    "        raise NotImplementedError(\n",
    "            'Window name %s is not supported now. Currently, %d windows are'\n",
    "            'supported - %s'\n",
    "            % (\n",
    "                window_name,\n",
    "                len(available_windows),\n",
    "                ', '.join([k for k in available_windows.keys()]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return available_windows[window_name]\n",
    "\n",
    "\n",
    "def validate_data_format_str(data_format):\n",
    "    \"\"\"A function that validates the data format string.\"\"\"\n",
    "    if data_format not in (_CH_DEFAULT_STR, _CH_FIRST_STR, _CH_LAST_STR):\n",
    "        raise ValueError(\n",
    "            'data_format should be one of {}'.format(\n",
    "                str([_CH_FIRST_STR, _CH_LAST_STR, _CH_DEFAULT_STR])\n",
    "            )\n",
    "            + ' but we received {}'.format(data_format)\n",
    "        )\n",
    "\n",
    "\n",
    "def magnitude_to_decibel(x, ref_value=1.0, amin=1e-5, dynamic_range=80.0):\n",
    "    \"\"\"A function that converts magnitude to decibel scaling.\n",
    "    In essence, it runs `10 * log10(x)`, but with some other utility operations.\n",
    "\n",
    "    Similar to `librosa.amplitude_to_db` with `ref=1.0` and `top_db=dynamic_range`\n",
    "\n",
    "    Args:\n",
    "        x (`Tensor`): float tensor. Can be batch or not. Something like magnitude of STFT.\n",
    "        ref_value (`float`): an input value that would become 0 dB in the result.\n",
    "            For spectrogram magnitudes, ref_value=1.0 usually make the decibel-scaled output to be around zero\n",
    "            if the input audio was in [-1, 1].\n",
    "        amin (`float`): the noise floor of the input. An input that is smaller than `amin`, it's converted to `amin`.\n",
    "        dynamic_range (`float`): range of the resulting value. E.g., if the maximum magnitude is 30 dB,\n",
    "            the noise floor of the output would become (30 - dynamic_range) dB\n",
    "\n",
    "    Returns:\n",
    "        log_spec (`Tensor`): a decibel-scaled version of `x`.\n",
    "\n",
    "    Note:\n",
    "        In many deep learning based application, the input spectrogram magnitudes (e.g., abs(STFT)) are decibel-scaled\n",
    "        (=logarithmically mapped) for a better performance.\n",
    "\n",
    "    Example:\n",
    "        ::\n",
    "\n",
    "            input_shape = (2048, 1)  # mono signal\n",
    "            model = Sequential()\n",
    "            model.add(kapre.Frame(frame_length=1024, hop_length=512, input_shape=input_shape))\n",
    "            # now the shape is (batch, n_frame=3, frame_length=1024, ch=1)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def _log10(x):\n",
    "        return tf.math.log(x) / tf.math.log(tf.constant(10, dtype=x.dtype))\n",
    "\n",
    "    if K.ndim(x) > 1:  # we assume x is batch in this case\n",
    "        max_axis = tuple(range(K.ndim(x))[1:])\n",
    "    else:\n",
    "        max_axis = None\n",
    "\n",
    "    if amin is None:\n",
    "        amin = 1e-5\n",
    "\n",
    "    log_spec = 10.0 * _log10(tf.math.maximum(x, amin))\n",
    "    log_spec = log_spec - 10.0 * _log10(tf.math.maximum(amin, ref_value))\n",
    "\n",
    "    log_spec = tf.math.maximum(\n",
    "        log_spec, tf.math.reduce_max(log_spec, axis=max_axis, keepdims=True) - dynamic_range\n",
    "    )\n",
    "\n",
    "    return log_spec\n",
    "\n",
    "\n",
    "def filterbank_mel(\n",
    "    sample_rate, n_freq, n_mels=128, f_min=0.0, f_max=None, htk=False, norm='slaney',trainable=False, num_classes=2\n",
    "):\n",
    "    \"\"\"A wrapper for librosa.filters.mel that additionally does transpose and tensor conversion\n",
    "\n",
    "    Args:\n",
    "        sample_rate (`int`): sample rate of the input audio\n",
    "        n_freq (`int`): number of frequency bins in the input STFT magnitude.\n",
    "        n_mels (`int`): the number of mel bands\n",
    "        f_min (`float`): lowest frequency that is going to be included in the mel filterbank (Hertz)\n",
    "        f_max (`float`): highest frequency that is going to be included in the mel filterbank (Hertz)\n",
    "        htk (bool): whether to use `htk` formula or not\n",
    "        norm: The default, 'slaney', would normalize the the mel weights by the width of the mel band.\n",
    "\n",
    "    Returns:\n",
    "        (`Tensor`): mel filterbanks. Shape=`(n_freq, n_mels)`\n",
    "    \"\"\"\n",
    "\n",
    "    filterbank = librosa.filters.mel(\n",
    "        sr=sample_rate,\n",
    "        n_fft=(n_freq - 1) * 2,\n",
    "        n_mels=n_mels,\n",
    "        fmin=f_min,\n",
    "        fmax=f_max,\n",
    "        htk=htk,\n",
    "        norm=norm,\n",
    "    ).astype(K.floatx())\n",
    "\n",
    "    ff = filterbank.T\n",
    "    print('FF shape',ff.shape)\n",
    "    \n",
    "    if trainable:\n",
    "      variables = []\n",
    "      for i in range(num_classes):\n",
    "        #variables.append(tf.Variable(tf.ones(shape=(ff.shape[0],ff.shape[1]), dtype=tf.float32),trainable=True, name='kernel_variable_'+str(i))*tf.Variable(ff,trainable=False))\n",
    "        variables.append(tf.Variable(ff,trainable=True))\n",
    "\n",
    "      \n",
    "      ff = tf.add_n(variables)# / num_classes #* tf.Variable(tf.convert_to_tensor(ff),trainable=False)\n",
    "      \n",
    "\n",
    "    print('Trainable mel spectrogram is '+str(trainable))\n",
    "    return ff\n",
    "\n",
    "\n",
    "def filterbank_log(sample_rate, n_freq, n_bins=84, bins_per_octave=12, f_min=None, spread=0.125, trainable = False):\n",
    "    \"\"\"A function that returns a approximation of constant-Q filter banks for a fixed-window STFT.\n",
    "    Each filter is a log-normal window centered at the corresponding frequency.\n",
    "\n",
    "    Args:\n",
    "        sample_rate (`int`): audio sampling rate\n",
    "        n_freq (`int`): number of the input frequency bins. E.g., `n_fft / 2 + 1`\n",
    "        n_bins (`int`): number of the resulting log-frequency bins.  Defaults to 84 (7 octaves).\n",
    "        bins_per_octave (`int`): number of bins per octave. Defaults to 12 (semitones).\n",
    "        f_min (`float`): lowest frequency that is going to be included in the log filterbank. Defaults to `C1 ~= 32.70`\n",
    "        spread (`float`): spread of each filter, as a fraction of a bin.\n",
    "\n",
    "    Returns:\n",
    "        (`Tensor`): log-frequency filterbanks. Shape=`(n_freq, n_bins)`\n",
    "\n",
    "    Note:\n",
    "        The code is originally from `logfrequency` in librosa 0.4 (deprecated) and copy-and-pasted.\n",
    "        `tuning` parameter was removed and we use `n_freq` instead of `n_fft`.\n",
    "    \"\"\"\n",
    "\n",
    "    if f_min is None:\n",
    "        f_min = 32.70319566\n",
    "\n",
    "    f_max = f_min * 2 ** (n_bins / bins_per_octave)\n",
    "    if f_max > sample_rate // 2:\n",
    "        raise RuntimeError(\n",
    "            'Maximum frequency of log filterbank should be lower or equal to the maximum'\n",
    "            'frequency of the input (defined by its sample rate), '\n",
    "            'but f_max=%f and maximum frequency is %f. \\n'\n",
    "            'Fix it by reducing n_bins, increasing bins_per_octave and/or reducing f_min.\\n'\n",
    "            'You can also do it by increasing sample_rate but it means you need to upsample'\n",
    "            'the input audio data, too.' % (f_max, sample_rate)\n",
    "        )\n",
    "\n",
    "    # What's the shape parameter for our log-normal filters?\n",
    "    sigma = float(spread) / bins_per_octave\n",
    "\n",
    "    # Construct the output matrix\n",
    "    basis = np.zeros((n_bins, n_freq))\n",
    "\n",
    "    # Get log frequencies of bins\n",
    "    log_freqs = np.log2(librosa.fft_frequencies(sample_rate, (n_freq - 1) * 2)[1:])\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        # What's the center (median) frequency of this filter?\n",
    "        c_freq = f_min * (2.0 ** (float(i) / bins_per_octave))\n",
    "\n",
    "        # Place a log-normal window around c_freq\n",
    "        basis[i, 1:] = np.exp(\n",
    "            -0.5 * ((log_freqs - np.log2(c_freq)) / sigma) ** 2 - np.log2(sigma) - log_freqs\n",
    "        )\n",
    "\n",
    "    # Normalize the filters\n",
    "    basis = librosa.util.normalize(basis, norm=1, axis=1)\n",
    "    basis = basis.astype(K.floatx())\n",
    "    print('Trainable mel spectrogram is '+str(trainable))\n",
    "    return tf.Variable(tf.convert_to_tensor(basis.T), trainable=trainable)\n",
    "\n",
    "\n",
    "def mu_law_encoding(signal, quantization_channels):\n",
    "    \"\"\"Encode signal based on mu-law companding. Also called mu-law compressing.\n",
    "\n",
    "    This algorithm assumes the signal has been scaled to between -1 and 1 and returns a signal encoded\n",
    "    with values from 0 to quantization_channels - 1.\n",
    "    See `Wikipedia <https://en.wikipedia.org/wiki/Μ-law_algorithm>`_ for more details.\n",
    "\n",
    "    Args:\n",
    "        signal (float `Tensor`): audio signal to encode\n",
    "        quantization_channels (positive int): Number of channels. For 8-bit encoding, use 256.\n",
    "\n",
    "    Returns:\n",
    "        signal_mu (int `Tensor`): mu-encoded signal\n",
    "    \"\"\"\n",
    "    mu = quantization_channels - 1.0\n",
    "    signal_mu = tf.math.sign(signal) * tf.math.log1p(mu * tf.math.abs(signal)) / tf.math.log1p(mu)\n",
    "    signal_mu = tf.cast(((signal_mu + 1) / 2.0 * mu + 0.5), tf.int32)\n",
    "    return signal_mu\n",
    "\n",
    "\n",
    "def mu_law_decoding(signal_mu, quantization_channels):\n",
    "    \"\"\"Decode mu-law encoded signals based on mu-law companding. Also called mu-law expanding.\n",
    "\n",
    "    See `Wikipedia <https://en.wikipedia.org/wiki/Μ-law_algorithm>`_ for more details.\n",
    "\n",
    "    Args:\n",
    "        signal_mu (int `Tensor`): mu-encoded signal to decode\n",
    "        quantization_channels (positive int): Number of channels. For 8-bit encoding, use 256.\n",
    "\n",
    "    Returns:\n",
    "        signal (float `Tensor`): decoded audio signal\n",
    "    \"\"\"\n",
    "    mu = quantization_channels - 1.0\n",
    "    signal_mu = K.cast_to_floatx(signal_mu)\n",
    "\n",
    "    signal = (signal_mu / mu) * 2 - 1.0\n",
    "    signal = (\n",
    "        tf.math.sign(signal) * (tf.math.exp(tf.math.abs(signal) * tf.math.log1p(mu)) - 1.0) / mu\n",
    "    )\n",
    "    return signal\n",
    "\n",
    "\n",
    "\n",
    "class ApplyFilterbank(tensorflow.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Apply a filterbank to the input spectrograms.\n",
    "    Args:\n",
    "        filterbank (`Tensor`): filterbank tensor in a shape of (n_freq, n_filterbanks)\n",
    "        data_format (`str`): specifies the data format of batch input/output\n",
    "        **kwargs: Keyword args for the parent keras layer (e.g., `name`)\n",
    "    Example:\n",
    "        ::\n",
    "            input_shape = (2048, 1)  # mono signal\n",
    "            n_fft = 1024\n",
    "            n_hop = n_fft // 2\n",
    "            kwargs = {\n",
    "                'sample_rate': 22050,\n",
    "                'n_freq': n_fft // 2 + 1,\n",
    "                'n_mels': 128,\n",
    "                'f_min': 0.0,\n",
    "                'f_max': 8000,\n",
    "            }\n",
    "            model = Sequential()\n",
    "            model.add(kapre.STFT(n_fft=n_fft, hop_length=n_hop, input_shape=input_shape))\n",
    "            model.add(Magnitude())\n",
    "            # (batch, n_frame=3, n_freq=n_fft // 2 + 1, ch=1) and dtype is float\n",
    "            model.add(ApplyFilterbank(type='mel', filterbank_kwargs=kwargs))\n",
    "            # (batch, n_frame=3, n_mels=128, ch=1)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, type, filterbank_kwargs, data_format='default', **kwargs,\n",
    "    ):\n",
    "\n",
    "        kapre.backend.validate_data_format_str(data_format)\n",
    "\n",
    "        self.type = type\n",
    "        self.filterbank_kwargs = filterbank_kwargs\n",
    "\n",
    "        if type == 'log':\n",
    "            self.filterbank = _log_filterbank = filterbank_log(**filterbank_kwargs)\n",
    "        elif type == 'mel':\n",
    "            self.filterbank = _mel_filterbank = filterbank_mel(**filterbank_kwargs)\n",
    "\n",
    "        if data_format == _CH_DEFAULT_STR:\n",
    "            self.data_format = K.image_data_format()\n",
    "        else:\n",
    "            self.data_format = data_format\n",
    "\n",
    "        if self.data_format == _CH_FIRST_STR:\n",
    "            self.freq_axis = 3\n",
    "        else:\n",
    "            self.freq_axis = 2\n",
    "        super(ApplyFilterbank, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Apply filterbank to `x`.\n",
    "        Args:\n",
    "            x (`Tensor`): float tensor in 2D batch shape.\n",
    "        \"\"\"\n",
    "\n",
    "        # x: 2d batch input. (b, t, fr, ch) or (b, ch, t, fr)\n",
    "        output = tf.tensordot(x, self.filterbank, axes=(self.freq_axis, 0))\n",
    "        # ch_last -> (b, t, ch, new_fr). ch_first -> (b, ch, t, new_fr)\n",
    "        if self.data_format == _CH_LAST_STR:\n",
    "            output = tf.transpose(output, (0, 1, 3, 2))\n",
    "        return output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ApplyFilterbank, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'type': self.type,\n",
    "                'filterbank_kwargs': self.filterbank_kwargs,\n",
    "                'data_format': self.data_format,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:27:25.770257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.789770: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.789929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.791158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.791298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.791374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.836793: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.836918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.836998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:25.837070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    }
   ],
   "source": [
    "#AUCORESNET V2 \n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Lambda, Activation, Flatten, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import Concatenate, Add\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, LambdaCallback, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from kapre.time_frequency import (\n",
    "    STFT,\n",
    "    InverseSTFT,\n",
    "    Phase,\n",
    "    MagnitudeToDecibel, \n",
    "    ConcatenateFrequencyMap,\n",
    "    Magnitude\n",
    ")\n",
    "import kapre\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "#from spela.melspectrogram import Melspectrogram, Spectrogram\n",
    "\n",
    "import math\n",
    "\n",
    "class MagnitudeTR(Layer):\n",
    "\n",
    "  def __init__(self, trainable, **kwargs):\n",
    "    super(MagnitudeTR, self).__init__(**kwargs)\n",
    "    self.trainable = trainable\n",
    "\n",
    "    \"\"\"Compute the magnitude of the complex input, resulting in a float tensor\n",
    "    Example:\n",
    "        ::\n",
    "            input_shape = (2048, 1)  # mono signal\n",
    "            model = Sequential()\n",
    "            model.add(kapre.STFT(n_fft=1024, hop_length=512, input_shape=input_shape))\n",
    "            mode.add(Magnitude())\n",
    "            # now the shape is (batch, n_frame=3, n_freq=513, ch=1) and dtype is float\n",
    "    \"\"\"\n",
    "  def build(self, input_shape):\n",
    "        \n",
    "        self.u = self.add_weight(  shape=(input_shape[3], 1), initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        #self.kernel = self.add_weight(name='kernel',  initializer=tf.keras.initializers.GlorotUniform(), \n",
    "        #                               trainable=True,\n",
    "                                      #shape=(input_shape[-1], input_shape[-2]))\n",
    "        #                              shape=( input_shape[3], input_shape[2]))\n",
    "        super(MagnitudeTR, self).build(input_shape)\n",
    "\n",
    "  def call(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (complex `Tensor`): input complex tensor\n",
    "        Returns:\n",
    "            (float `Tensor`): magnitude of `x`\n",
    "        \"\"\"\n",
    "        xr = tf.math.real(x)\n",
    "        #xr = tf.reshape(xr,(tf.shape(xr)[0],tf.shape(xr)[1]))\n",
    "        if self.trainable:\n",
    "          xr = K.dot(xr,self.u)\n",
    "          #xr = tf.reshape(xr,(tf.shape(xr)[1],tf.shape(xr)[0], 1))\n",
    "\n",
    "        #tf.shape(xr)\n",
    "        #xr = xr.numpy()\n",
    "        xi = tf.math.imag(x)\n",
    "        #xr1 = tf.Variable(xr,trainable=self.trainable)\n",
    "        xb = tf.complex(xr,xi)\n",
    "        #x = tf.Variable(lambda:tf.math.abs(x),trainable=self.trainable)\n",
    "        \n",
    "        return tf.abs(xb)\n",
    "        #return tf.abs(x)\n",
    "#from tensorflow.keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "#get_custom_objects().update({'custom_activation': SineReLU()})\n",
    "def sinc(x):\n",
    "    tf.keras.activations.swish(x)\n",
    "    #return  K.exp(-K.pow(x,2))\n",
    "    #x = tf.where(tf.abs(x) < 1e-20, 1e-20 * tf.ones_like(x), x)\n",
    "    #return tf.sin(x) / x\n",
    "\n",
    "class AUCOResNetV2:\n",
    "    def __init__(self, att='att2', gmode='concat', compatibilityfunction='pc', datasetname=\"covid\", input_shape=(1,64000),\n",
    "                 outputclasses=100, weight_decay=0.0005, optimizer=SGD(lr=0.01, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy', 'AUC'],\n",
    "                 runs = [1, 8, 3, 5, 4], n_fft=1024,sample_rate=22050,n_mels=128, win_length =160, hop_length=344, \n",
    "                 return_decibel=True,input_data_format='channels_first', sinusoidal = False, trainable = True, pers_act = 'elu', attention_type='cbam_block',subsample_initial_block = True,strides=(2,2) , \n",
    "                 filters = 64, initial_kernel = (7, 7),debug=False):\n",
    "        \n",
    "        inputs = Input(shape=input_shape) #batch*x*y*3\n",
    "        self.history = None\n",
    "\n",
    "        #Layer 1\n",
    "        '''\n",
    "        if trainable:\n",
    "          fft_base_2 = pow(2, math.ceil(math.log(n_fft)/math.log(2)));\n",
    "\n",
    "          x = Melspectrogram(sr=sample_rate, n_mels=n_mels,n_dft=fft_base_2,  n_hop=hop_length, input_shape=input_shape,return_decibel_melgram=True, trainable_kernel=False,  trainable_fb=True) (inputs)\n",
    "          #x = Spectrogram( n_dft=fft_base_2, n_hop=hop_length, input_shape=(input_shape), win_length=win_length, return_decibel_spectrogram=True, power_spectrogram=2.0, trainable_kernel=True, name='static_stft') (inputs)\n",
    "          #x = Normalization2D(str_axis='freq')(x)\n",
    "        else:\n",
    "        '''\n",
    "        x = self.get_melspectrogram_layer(name='mel',n_fft=n_fft,sample_rate=sample_rate,n_mels=n_mels, hop_length=hop_length, return_decibel=return_decibel,input_data_format=input_data_format,  trainable = trainable, num_classes=outputclasses) (inputs)      \n",
    "        \n",
    "        if debug:\n",
    "          x = Conv2D(128,(1,1),  name='conv2dfirst')(x)\n",
    "        #x2 = get_log_frequency_spectrogram_layer(n_fft=2048,log_n_bins=84, sample_rate=16000,hop_length=344,input_data_format='channels_first',return_decibel=True)(inputs)\n",
    "\n",
    "        #x = keras.layers.Concatenate(axis=2)([x1,x2])#,x4])\n",
    "       \n",
    "        regularizer = keras.regularizers.l2(weight_decay)\n",
    "        self.datasetname = datasetname\n",
    "        self.outputclasses=outputclasses\n",
    "        #x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "        \n",
    "        if sinusoidal == False:\n",
    "            activ = pers_act\n",
    "        else:\n",
    "            print('ERROR --> Not implemented Sine Attention')\n",
    "            activ = 'relu'\n",
    "\n",
    "\n",
    "        if subsample_initial_block:\n",
    "          \n",
    "          initial_strides = strides\n",
    "        else:\n",
    "          \n",
    "          initial_strides = (1, 1)\n",
    "\n",
    "        x = Conv2D(filters, initial_kernel, kernel_initializer='he_normal', padding='same',\n",
    "               strides=initial_strides, use_bias=False, kernel_regularizer=regularizer)(x)\n",
    "        '''\n",
    "        if subsample_initial_block:\n",
    "          x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "          if sinusoidal == False:\n",
    "            x = Activation(pers_act)(x)\n",
    "          else:\n",
    "            x =Dentamaro(trainable=True)(x)\n",
    "          x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "        '''\n",
    "        x = attach_attention_module(x,'cbam_block',activation=activ, ratio = 2)\n",
    "        #END LAYER 1\n",
    "\n",
    "        #Layer 2\n",
    "        #block1, out batch*(x)*(y)*16\n",
    "\n",
    "        for i in range(0,runs[0]):\n",
    "          #if i == 0:\n",
    "          #   identity = Conv2D(filters,(2,2), padding='same', kernel_regularizer=regularizer, name='id1')(x)\n",
    "          x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer)(x)\n",
    "          x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "          if sinusoidal == False:\n",
    "            x = Activation(pers_act)(x)\n",
    "          else:\n",
    "            x =Dentamaro(trainable=True)(x)\n",
    "          #x = attach_attention_module(x,attention_type)\n",
    "          x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer)(x) #batch*x*y*16\n",
    "          x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "          if sinusoidal == False:\n",
    "            x = Activation(pers_act)(x)\n",
    "          else:\n",
    "            x =Dentamaro(trainable=True)(x)\n",
    "          #x = Add()([identity,x])\n",
    "        x = attach_attention_module(x,attention_type,activation=activ)\n",
    "\n",
    "        #x = Add()([identity,x])\n",
    "        #END Layer 2\n",
    "        \n",
    "        #Layer 3\n",
    "        #block2, out batch*(x/2)*(y/2)*64\n",
    "        for i in range(0,runs[1]):#was 18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters,(2,2), padding='same', kernel_regularizer=regularizer, name='block2dimchangeconv')(identity)\n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block2resblock'+str((i+1))+'conv1')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (3, 3), padding='same', kernel_regularizer=regularizer, name='block2resblock'+str((i+1))+'conv2')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer, name='block2resblock'+str((i+1))+'conv3')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "        \n",
    "        l1 = x #16 filters, 32x32 resolution\n",
    "        f1 = filters\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block2pool')(x)\n",
    "\n",
    "        #END Layer 3\n",
    "        #Layer 4\n",
    "\n",
    "        filters *= 2\n",
    "\n",
    "        #block3, out batch*(x/4)*(y/4)*128\n",
    "        for i in range(0,runs[2]):#was18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters, (2,2), padding='same', kernel_regularizer=regularizer, name='block3dimchangeconv')(identity)            \n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block3resblock'+str((i+1))+'conv1')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block3resblock'+str((i+1))+'conv2')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer, name='block3resblock'+str((i+1))+'conv3')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "        f2 = filters\n",
    "        l2 = x #256 filters, 16x16 resolution\n",
    "        x = MaxPooling2D((2, 2), strides=(2, 2), name='block3pool')(x)\n",
    "        #END Layer 4\n",
    "\n",
    "        #Layer 5\n",
    "        filters *= 2\n",
    "        #block4, out batch*(x/4)*(y/4)*256\n",
    "        for i in range(0,runs[3]):#was18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters, (2,2), padding='same', kernel_regularizer=regularizer, name='block4dimchangeconv')(identity)            \n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer, name='block4resblock'+str((i+1))+'conv1')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (3, 3), padding='same', kernel_regularizer=regularizer, name='block4resblock'+str((i+1))+'conv2')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer, name='block4resblock'+str((i+1))+'conv3')(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "        l3 = x #512 filters, 8x8 resolution\n",
    "        f3 = filters\n",
    "        #END Layer 5\n",
    "        #Layer 6\n",
    "\n",
    "        filters *= 2\n",
    "        #block4, out batch*(x/4)*(y/4)*256\n",
    "        for i in range(0,runs[4]):#was18\n",
    "            identity = x\n",
    "            if i == 0:\n",
    "                identity=Conv2D(filters, (2,2), padding='same', kernel_regularizer=regularizer)(identity)            \n",
    "            x = Conv2D(int(filters/4), (1, 1), padding='same', kernel_regularizer=regularizer)(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(int(filters/4), (3, 3), padding='same', kernel_regularizer=regularizer)(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x)\n",
    "            x = Conv2D(filters, (1, 1), padding='same', kernel_regularizer=regularizer)(x)\n",
    "            x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "            x = attach_attention_module(x,attention_type,activation=activ)\n",
    "            x = Add()([identity,x])\n",
    "            #x = Activation(pers_act)(x)\n",
    "            if sinusoidal == False:\n",
    "              x = Activation(pers_act)(x)\n",
    "            else:\n",
    "              x =Dentamaro(trainable=True)(x) \n",
    "        l4 = x  \n",
    "        f4 = filters\n",
    "        \n",
    "        x = Conv2D(filters, (3, 3), padding='same', kernel_regularizer=regularizer, name='outconv')(x) \n",
    "        x = BatchNormalization(epsilon=1.1e-5)(x)\n",
    "        x = MaxPooling2D((2,2), strides=(2,2), name=\"gpool\")(x)\n",
    "        #x = attach_attention_module(x,'eca_block',activation=activ)\n",
    "        x = attach_attention_module(x,'cbam_block',activation=activ, ratio = 2)\n",
    "\n",
    "        gbase = Flatten(name='pregflatten')(x)\n",
    "        if False:\n",
    "          g64 = SinusodialRepresentationDense(f1, activation='sine', w0=1.0)(gbase)#added now 0.406\n",
    "          g128 = SinusodialRepresentationDense(f2, activation='sine', w0=1.0)(gbase)#added now \n",
    "          g256 = SinusodialRepresentationDense(f3, activation='sine', w0=1.0)(gbase)#added now \n",
    "          g4 = SinusodialRepresentationDense(f4, activation='sine', w0=1.0)(gbase)#added now \n",
    "        else:\n",
    "          g64 = Dense(f1, kernel_regularizer=regularizer, name='globalg64',activation=pers_act)(gbase)\n",
    "          g128 = Dense(f2, kernel_regularizer=regularizer, name='globalg128',activation=pers_act)(gbase)\n",
    "          g256 = Dense(f3, kernel_regularizer=regularizer, name='globalg256',activation=pers_act)(gbase)    \n",
    "          g4 = Dense(f4, kernel_regularizer=regularizer, name='globalg4',activation=pers_act)(gbase)       \n",
    "\n",
    "        #Learnable attention\n",
    "        c1 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc1')([l1, g64])  # batch*x*y\n",
    "        if compatibilityfunction == 'mha':\n",
    "            c1 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l1, g64])\n",
    "        if compatibilityfunction == 'dp':\n",
    "            c1 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp1')([l1, g64])  # batch*x*y\n",
    "        flatc1 = Flatten(name='flatc1')(c1)  # batch*xy\n",
    "        a1 = Activation('softmax', name='softmax1')(flatc1)  # batch*xy\n",
    "        reshaped1 = Reshape((-1,f1), name='reshape1')(l1)  # batch*xy*256.\n",
    "        if compatibilityfunction == 'mha':\n",
    "            g1 = a1\n",
    "        else:\n",
    "            g1 = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g1')([a1, reshaped1])  # batch*256.\n",
    "        \n",
    "        c2 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc2')([l2, g128])\n",
    "        if compatibilityfunction == 'mha':\n",
    "            c2 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l2, g128])\n",
    "        if compatibilityfunction == 'dp':\n",
    "            c2 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp2')([l2, g128])\n",
    "        flatc2 = Flatten(name='flatc2')(c2)\n",
    "        a2 = Activation('softmax', name='softmax2')(flatc2)\n",
    "        reshaped2 =  Reshape((-1,f2), name='reshape2')(l2)\n",
    "        if compatibilityfunction == 'mha':\n",
    "            g2 = a2\n",
    "        else:\n",
    "            g2 = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g2')([a2, reshaped2])\n",
    "\n",
    "        c3 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc3')([l3, g256])\n",
    "        if compatibilityfunction == 'mha':\n",
    "            c3 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l3, g256])\n",
    "        if compatibilityfunction == 'dp':\n",
    "            c3 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp3')([l3, g256])\n",
    "        flatc3 = Flatten(name='flatc3')(c3)\n",
    "        a3 = Activation('softmax', name='softmax3')(flatc3)\n",
    "        reshaped3 = Reshape((-1,f3), name='reshape3')(l3)\n",
    "        if compatibilityfunction == 'mha':\n",
    "            g3 = a3\n",
    "        else:\n",
    "            g3 = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g3')([a3, reshaped3])\n",
    "        \n",
    "        if runs[4] > 0:\n",
    "          c4 = ParametrisedCompatibility(kernel_regularizer=regularizer, name='cpc4')([l4, g4])\n",
    "          if compatibilityfunction == 'mha':\n",
    "              c4 =  tfa.layers.MultiHeadAttention(head_size=64, num_heads=12)([l4, g4])\n",
    "          if compatibilityfunction == 'dp':\n",
    "              c4 = Lambda(lambda lam: K.squeeze(K.map_fn(lambda xy: K.dot(xy[0], xy[1]), elems=(lam[0], K.expand_dims(lam[1], -1)), dtype='float32'), 3), name='cdp4')([l4, g4])\n",
    "          flatc4 = Flatten(name='flatc4')(c4)\n",
    "          a4 = Activation('softmax', name='softmax4')(flatc4)\n",
    "          reshaped4 = Reshape((-1,f4), name='reshape4')(l4)\n",
    "          if compatibilityfunction == 'mha':\n",
    "              g4_ = a4\n",
    "          else:\n",
    "              g4_ = Lambda(lambda lam: K.squeeze(K.batch_dot(K.expand_dims(lam[0], 1), lam[1]), 1), name='g4')([a4, reshaped4])\n",
    "\n",
    "        out = ''\n",
    "        if gmode == 'concat':\n",
    "            if runs[4] > 0:\n",
    "              glist = [g4_, g3, g2, g1]\n",
    "            else:\n",
    "              glist = [g3, g2, g1]\n",
    "            predictedG = Concatenate(axis=1, name='ConcatG')(glist)\n",
    "            x = Dense(outputclasses, kernel_regularizer=regularizer, name=str(outputclasses)+'ConcatG')(predictedG)\n",
    "            out = Activation(\"softmax\", name='concatsoftmaxout')(x)\n",
    "            \n",
    "        else:\n",
    "            gd3 = Dense(outputclasses, activation='softmax', name=str(outputclasses)+'indepsoftmaxg3')(g3)\n",
    "            gd4 = Dense(outputclasses, activation='softmax', name=str(outputclasses)+'indepsoftmaxg4')(g4_)\n",
    "            gd2 = Dense(outputclasses, activation='softmax', kernel_regularizer=regularizer, name=str(outputclasses)+'indepsoftmaxg2')(g2)\n",
    "            gd1 = Dense(outputclasses, activation='softmax', kernel_regularizer=regularizer, name=str(outputclasses)+'indepsoftmaxg1')(g1)\n",
    "            if runs[4] > 0:\n",
    "              out = Add(name='addg4g3g2g1')([gd1, gd2, gd3, gd4])\n",
    "              out = Lambda(lambda lam: lam/4, name='4average')(out)\n",
    "            else:\n",
    "              out = Add(name='addg4g3g2g1')([gd1, gd2, gd3])\n",
    "              out = Lambda(lambda lam: lam/3, name='4average')(out)\n",
    "\n",
    "        #END Layer 6\n",
    "        model = Model(inputs=inputs, outputs=out)\n",
    "        \n",
    "      \n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)#, run_eagerly=True)\n",
    "        tf.keras.utils.plot_model(\n",
    "            model, to_file='model.png', show_shapes=True, show_dtype=True,\n",
    "            show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
    "        )\n",
    "        name = (\"(RN-\"+att+\")-\"+gmode+\"-\"+compatibilityfunction).replace('att)', 'att1)')\n",
    "        print(\"Generated \"+name)\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "    \n",
    "    def StandardFit(self, datasetname=None, X=[], Y=[],initial_lr=0.01, min_delta=None, patience=3, validation_data=None, lrplateaufactor=None, lrplateaupatience=4, validation_split=0.3,batch_size=16,epochs=100,checkpointcall=None):\n",
    "        #Y = keras.utils.to_categorical(Y,self.outputclasses)\n",
    "        if datasetname==None:\n",
    "            datasetname=self.datasetname\n",
    "        if os.path.isfile(\"weights/\"+self.name+\"-\"+datasetname+\" early.hdf5\"):\n",
    "            print(\"Found early-stopped weights for \"+self.name+\"-\"+datasetname)\n",
    "            return\n",
    "        scheduler = LearningRateScaler([20, 50, 80], 0.2, initial_lr)\n",
    "        \n",
    "        tboardcb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=3, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "        if checkpointcall ==None:\n",
    "            checkpoint = ModelCheckpoint(\"weights/\"+self.name+\"-\"+datasetname+\" {epoch}.hdf5\", \n",
    "                                         save_weights_only=True,monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "        else:\n",
    "            checkpoint = checkpointcall\n",
    "        epochprint = LambdaCallback(on_epoch_end=lambda epoch, logs: print(\"Passed epoch \"+str(epoch)))\n",
    "        \n",
    "        callbackslist = [scheduler, checkpoint, epochprint]#, tboardcb]\n",
    " \n",
    "         \n",
    "        if min_delta != None:\n",
    "              callbackslist.append(EarlyStopping(monitor='val_auc', min_delta=min_delta, patience=patience))\n",
    "        if lrplateaufactor != None:\n",
    "              callbackslist.append(ReduceLROnPlateau(monitor='auc', factor = lrplateaufactor, patience = lrplateaupatience))\n",
    "        if validation_data == None:\n",
    "            self.history = self.model.fit(X, Y,  batch_size=batch_size, epochs=epochs, \n",
    "                                          callbacks=callbackslist, shuffle=True,validation_split=validation_split, verbose=1)    \n",
    "        else:\n",
    "            self.history = self.model.fit(X, Y,  batch_size=batch_size, epochs=epochs, callbacks=callbackslist, shuffle=True,\n",
    "                           validation_data=(validation_data[0],validation_data[1]), verbose=1)    \n",
    "        \n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def save_plot(self, filename, history=None, title='AUCO ResNet Accuracy'):\n",
    "        \n",
    "        if history == None:\n",
    "            history = self.history\n",
    "       \n",
    "        plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "            \n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        #plt.plot(history.history['loss'])\n",
    "        #plt.plot(history.history['val_loss'])\n",
    "        plt.plot(history.history['auc'])\n",
    "        plt.plot(history.history['val_auc'])\n",
    "            \n",
    "\n",
    "        plt.title(title)\n",
    "        plt.ylabel('Accuracy / AUC')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['training accuracy', 'validation accuracy','training AUC','validation AUC'], loc='upper left')\n",
    "        plt.savefig(filename, format=\"svg\", cmap='nipy_spectral')\n",
    "        f = plt.figure()\n",
    "        f.clear()\n",
    "        plt.close(f)\n",
    "        plt.close('all')\n",
    "\n",
    " \n",
    "    def get_melspectrogram_layer(self,\n",
    "        input_shape=None,\n",
    "        n_fft=2048,\n",
    "        win_length=None,\n",
    "        hop_length=None,\n",
    "        window_name=None,\n",
    "        pad_begin=False,\n",
    "        pad_end=False,\n",
    "        sample_rate=22050,\n",
    "        n_mels=128,\n",
    "        mel_f_min=0.0,\n",
    "        mel_f_max=None,\n",
    "        mel_htk=False,\n",
    "        mel_norm='slaney',\n",
    "        return_decibel=False,\n",
    "        db_amin=1e-5,\n",
    "        db_ref_value=1.0,\n",
    "        db_dynamic_range=80.0,\n",
    "        input_data_format='default',\n",
    "        output_data_format='default',\n",
    "        trainable = True,\n",
    "        name='melspectrogram',\n",
    "        num_classes=2,\n",
    "    ):\n",
    "        \"\"\"A function that returns a melspectrogram layer, which is a `keras.Sequential` model consists of\n",
    "        `STFT`, `Magnitude`, `ApplyFilterbank(_mel_filterbank)`, and optionally `MagnitudeToDecibel`.\n",
    "        Args:\n",
    "            input_shape (None or tuple of integers): input shape of the model. Necessary only if this melspectrogram layer is\n",
    "                is the first layer of your model (see `keras.model.Sequential()` for more details)\n",
    "            n_fft (int): number of FFT points in `STFT`\n",
    "            win_length (int): window length of `STFT`\n",
    "            hop_length (int): hop length of `STFT`\n",
    "            window_name (str or None): *Name* of `tf.signal` function that returns a 1D tensor window that is used in analysis.\n",
    "                Defaults to `hann_window` which uses `tf.signal.hann_window`.\n",
    "                Window availability depends on Tensorflow version. More details are at `kapre.backend.get_window()`.\n",
    "            pad_begin (bool): Whether to pad with zeros along time axis (length: win_length - hop_length). Defaults to `False`.\n",
    "            pad_end (bool): whether to pad the input signal at the end in `STFT`.\n",
    "            sample_rate (int): sample rate of the input audio\n",
    "            n_mels (int): number of mel bins in the mel filterbank\n",
    "            mel_f_min (float): lowest frequency of the mel filterbank\n",
    "            mel_f_max (float): highest frequency of the mel filterbank\n",
    "            mel_htk (bool): whether to follow the htk mel filterbank fomula or not\n",
    "            mel_norm ('slaney' or int): normalization policy of the mel filterbank triangles\n",
    "            return_decibel (bool): whether to apply decibel scaling at the end\n",
    "            db_amin (float): noise floor of decibel scaling input. See `MagnitudeToDecibel` for more details.\n",
    "            db_ref_value (float): reference value of decibel scaling. See `MagnitudeToDecibel` for more details.\n",
    "            db_dynamic_range (float): dynamic range of the decibel scaling result.\n",
    "            input_data_format (str): the audio data format of input waveform batch.\n",
    "                `'channels_last'` if it's `(batch, time, channels)`\n",
    "                `'channels_first'` if it's `(batch, channels, time)`\n",
    "                Defaults to the setting of your Keras configuration. (tf.keras.backend.image_data_format())\n",
    "            output_data_format (str): the data format of output melspectrogram.\n",
    "                `'channels_last'` if you want `(batch, time, frequency, channels)`\n",
    "                `'channels_first'` if you want `(batch, channels, time, frequency)`\n",
    "                Defaults to the setting of your Keras configuration. (tf.keras.backend.image_data_format())\n",
    "            name (str): name of the returned layer\n",
    "        Note:\n",
    "            Melspectrogram is originally developed for speech applications and has been *very* widely used for audio signal\n",
    "            analysis including music information retrieval. As its mel-axis is a non-linear compression of (linear)\n",
    "            frequency axis, a melspectrogram can be an efficient choice as an input of a machine learning model.\n",
    "            We recommend to set `return_decibel=True`.\n",
    "            **References**:\n",
    "            `Automatic tagging using deep convolutional neural networks <https://arxiv.org/abs/1606.00298>`_,\n",
    "            `Deep content-based music recommendation <http://papers.nips.cc/paper/5004-deep-content-based-music-recommen>`_,\n",
    "            `CNN Architectures for Large-Scale Audio Classification <https://arxiv.org/abs/1609.09430>`_,\n",
    "            `Multi-label vs. combined single-label sound event detection with deep neural networks <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.711.74&rep=rep1&type=pdf>`_,\n",
    "            `Deep Convolutional Neural Networks and Data Augmentation for Environmental Sound Classification <https://arxiv.org/pdf/1608.04363.pdf>`_,\n",
    "            and way too many speech applications.\n",
    "        Example:\n",
    "            ::\n",
    "                input_shape = (2, 2048)  # stereo signal, audio is channels_first\n",
    "                melgram = get_melspectrogram_layer(input_shape=input_shape, n_fft=1024, return_decibel=True,\n",
    "                    n_mels=96, input_data_format='channels_first', output_data_format='channels_last')\n",
    "                model = Sequential()\n",
    "                model.add(melgram)\n",
    "                # now the shape is (batch, n_frame=3, n_mels=96, n_ch=2) because output_data_format is 'channels_last'\n",
    "                # and the dtype is float\n",
    "        \"\"\"\n",
    "        kapre.backend.validate_data_format_str(input_data_format)\n",
    "        kapre.backend.validate_data_format_str(output_data_format)\n",
    "\n",
    "        stft_kwargs = {}\n",
    "        if input_shape is not None:\n",
    "            stft_kwargs['input_shape'] = input_shape\n",
    "\n",
    "        waveform_to_stft = STFT(\n",
    "            **stft_kwargs,\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            window_name=window_name,\n",
    "            pad_begin=pad_begin,\n",
    "            pad_end=pad_end,\n",
    "            input_data_format=input_data_format,\n",
    "            output_data_format=output_data_format,\n",
    "        )\n",
    "\n",
    "        stft_to_stftm = Magnitude()\n",
    "\n",
    "        kwargs = {\n",
    "            'sample_rate': sample_rate,\n",
    "            'n_freq': n_fft // 2 + 1,\n",
    "            'n_mels': n_mels,\n",
    "            'f_min': mel_f_min,\n",
    "            'f_max': mel_f_max,\n",
    "            'htk': mel_htk,\n",
    "            'trainable': trainable,\n",
    "            'norm': mel_norm,\n",
    "            'num_classes':num_classes,\n",
    "        }\n",
    "        stftm_to_melgram = ApplyFilterbank(\n",
    "            type='mel', filterbank_kwargs=kwargs, data_format=output_data_format\n",
    "        )\n",
    "\n",
    "        \n",
    "        mag_to_decibel = MagnitudeToDecibel(\n",
    "                ref_value=db_ref_value, amin=db_amin, dynamic_range=db_dynamic_range\n",
    "            )\n",
    " \n",
    "         \n",
    "        layers = [ Lambda(lambda x: tf.cast(x, tf.float32)), waveform_to_stft, stft_to_stftm, stftm_to_melgram, mag_to_decibel] \n",
    "        return Sequential(layers, name=name)\n",
    "        \n",
    "\n",
    "class TrainableMel(Layer):\n",
    "\n",
    "    def __init__(self, kernel_regularizer=None, **kwargs):\n",
    "        super(TrainableMel, self).__init__(**kwargs)\n",
    "        if kernel_regularizer == None:\n",
    "          self.regularizer = keras.regularizers.l2(0.0005)#era 0.0005\n",
    "        else:\n",
    "          self.regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel',  initializer=tf.keras.initializers.GlorotUniform(), \n",
    "                                      regularizer = self.regularizer, trainable=True,\n",
    "                                      #shape=(input_shape[-1], input_shape[-2]))\n",
    "                                      shape=(input_shape[1], input_shape[2], input_shape[3]))\n",
    "        super(TrainableMel, self).build(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        \n",
    "        return config\n",
    "\n",
    "    def call(self, x):  \n",
    "        \n",
    "        #Hadamard product\n",
    "        #K.print_tensor(x, message='x = ')\n",
    "        #return x * self.kernel\n",
    "        return x*self.kernel\n",
    "        #return tf.keras.backend.dot(x,self.kernel)\n",
    "\n",
    "\n",
    "class ParametrisedCompatibility(Layer):\n",
    "\n",
    "    def __init__(self, kernel_regularizer=None, **kwargs):\n",
    "        super(ParametrisedCompatibility, self).__init__(**kwargs)\n",
    "        self.regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.u = self.add_weight(name='u', shape=(input_shape[0][3], 1), initializer='uniform',\n",
    "                                 regularizer=self.regularizer, trainable=True)\n",
    "        super(ParametrisedCompatibility, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):  # add l and g. Dot the sum with u.\n",
    "        return K.dot(K.map_fn(lambda lam: (lam[0]+lam[1]),elems=(x),dtype='float32'), self.u)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], input_shape[0][2])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        \n",
    "        return config\n",
    "\n",
    "\n",
    "\n",
    "class Dentamaro(Layer):\n",
    "\n",
    "    def __init__(self, alpha=1.0,  trainable=True, **kwargs):\n",
    "        super(Dentamaro, self).__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.alpha = alpha\n",
    "        self.trainable = trainable\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.alpha_factor = K.variable(self.alpha,\n",
    "                                      dtype=K.floatx(),\n",
    "                                      name='alpha_factor')\n",
    "        if self.trainable:\n",
    "            self._trainable_weights.append(self.alpha_factor)\n",
    "\n",
    "        super(Dentamaro, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = inputs\n",
    "        #x +1 - (cos( 4x)-x/1.5) /(e^(-x/4)) \n",
    "        #t = x-tf.exp(x/self.alpha_factor) * (tf.cos(self.alpha_factor*x)-self.beta_factor*x) +1\n",
    "        #da provare ( sin(5x)/3 -1)+  e^x\n",
    "        #t = (tf.sin(self.alpha_factor*x)/self.beta_factor) -1 + x#tf.math.abs(x)#tf.math.log(1+tf.math.abs(x))#+ 2**x\n",
    "        #t = x + (1 - tf.sin(self.alpha_factor*x) +x/self.beta_factor) / self.alpha_factor\n",
    "        #t = (tf.sin(self.alpha_factor*x)/self.beta_factor)*tf.math.abs(x)+x\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        return tf.sin(self.alpha_factor*x)#(1-x*x)*tf.exp(-self.alpha_factor*x*x)\n",
    "        #or\n",
    "        #return 2.0*tf.sin(tf.pi*x)*x*tf.exp(-self.alpha_factor*x*x)\n",
    "        #\n",
    "        #return tf.sin(x*self.alpha_factor)#x + (1 - tf.cos(2 * self.alpha_factor * x)) / (2 * self.alpha_factor)\n",
    "        #return t\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'alpha': self.get_weights()[0] if self.trainable else self.alpha,\n",
    "                  'trainable': self.trainable}\n",
    "        base_config = super(Dentamaro, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "class TrainedKLDivergence(Layer):\n",
    "    #Dentamaro et al.\n",
    "    def __init__(self, kernel_regularizer=None, **kwargs):\n",
    "        super(TrainedKLDivergence, self).__init__(**kwargs)\n",
    "        self.regularizer = kernel_regularizer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.u = self.add_weight(name='u', shape=(input_shape[0][3], 1), initializer='uniform', regularizer=self.regularizer, trainable=True)\n",
    "        super(TrainedKLDivergence, self).build(input_shape)\n",
    "\n",
    "    '''\n",
    "    ## normalize p, q to probabilities\n",
    "    p, q = p/p.sum(), q/q.sum()\n",
    "    m = 1./2*(p + q)\n",
    "    return sp.stats.entropy(p,m, base=base)/2. +  sp.stats.entropy(q, m, base=base)/2.\n",
    "    '''\n",
    "\n",
    "    def call(self, x):\n",
    "        # Kullback-Leibler divergence \n",
    "\n",
    "        #p = x[0] / K.sum(x[0])\n",
    "        #q = x[1] / K.sum(x[1])\n",
    "        \n",
    "        mapping = K.map_fn(lambda lam: (K.pow(2.718,(lam[0]+lam[1]))),elems=(x),dtype='float32')\n",
    "        \n",
    "        #Dot the sum with u.\n",
    "        return K.dot(mapping, self.u)\n",
    "        #return K.dot(K.map_fn(lambda lam: (lam[0]+lam[1]),elems=(x),dtype='float32'), self.u)\n",
    "\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1], input_shape[0][2])\n",
    "    def logbase(self, x,base):\n",
    "        numerator = K.log(x)\n",
    "        denominator = K.log(base)\n",
    "        return numerator / denominator\n",
    "\n",
    "       \n",
    "class LearningRateScaler(Callback):\n",
    "    \n",
    "    def __init__(self, epochs, multiplier, initial_lr=None):\n",
    "        self.multiplier = multiplier\n",
    "        self.epochs = epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.startingepoch = True\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if self.initial_lr == None:\n",
    "            self.initial_lr = K.get_value(self.model.optimizer.lr)\n",
    "        print(\"Initial lr=\"+str(self.initial_lr))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        #print(\"Current lr: \" + str(K.get_value(self.model.optimizer.lr)))\n",
    "        lr = self.initial_lr\n",
    "        #print('epochs')\n",
    "        #print(self.epochs)\n",
    "        if epoch>0 and epoch in self.epochs:\n",
    "                for i in range(0, self.epochs.index(epoch)+1):\n",
    "                    lr = lr * self.multiplier\n",
    "                K.set_value(self.model.optimizer.lr, lr)\n",
    "                #print(\"Updated learning rate to \"+str(lr))    \n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        startingepoch = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "aa = []\n",
    "saucs = []\n",
    "saa = []\n",
    "histories = []\n",
    "confusion_matrix45 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "k-kAqFfkT0d_",
    "outputId": "bdeea9c6-6557-48c4-ed13-85dacc8b5926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n",
      "minority class [1.]\n",
      "minority people 18\n",
      "FF shape (513, 128)\n",
      "Trainable mel spectrogram is True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:27:28.144044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144211: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144286: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-10 10:27:28.144626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144858: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-10 10:27:28.144982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 14251 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/backend.py:7234: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/backend.py:7234: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Generated (RN-att2)-concat-pc\n",
      "FF shape (1025, 150)\n",
      "Trainable mel spectrogram is False\n",
      "DenseNet201\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:27:57.664133: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-09-10 10:27:57.677178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2024-09-10 10:28:00.930189: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x72311c9b1190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-10 10:28:00.930207: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080 Laptop GPU, Compute Capability 8.6\n",
      "2024-09-10 10:28:00.933735: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-10 10:28:01.011802: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 - 90s - loss: 0.5286 - accuracy: 0.8113 - auc: 0.8715 - val_loss: 1398.4254 - val_accuracy: 0.2993 - val_auc: 0.2993 - 90s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "69/69 - 11s - loss: 0.2413 - accuracy: 0.9111 - auc: 0.9653 - val_loss: 95.4590 - val_accuracy: 0.3650 - val_auc: 0.3704 - 11s/epoch - 158ms/step\n",
      "Epoch 3/100\n",
      "69/69 - 11s - loss: 0.2421 - accuracy: 0.9201 - auc: 0.9651 - val_loss: 57.3716 - val_accuracy: 0.3139 - val_auc: 0.3272 - 11s/epoch - 152ms/step\n",
      "Epoch 4/100\n",
      "69/69 - 11s - loss: 0.2163 - accuracy: 0.9238 - auc: 0.9713 - val_loss: 48.9943 - val_accuracy: 0.3796 - val_auc: 0.3717 - 11s/epoch - 159ms/step\n",
      "Epoch 5/100\n",
      "69/69 - 11s - loss: 0.2239 - accuracy: 0.9292 - auc: 0.9688 - val_loss: 5.5052 - val_accuracy: 0.5401 - val_auc: 0.4871 - 11s/epoch - 160ms/step\n",
      "Epoch 6/100\n",
      "69/69 - 11s - loss: 0.1374 - accuracy: 0.9510 - auc: 0.9881 - val_loss: 60.1367 - val_accuracy: 0.3285 - val_auc: 0.3252 - 11s/epoch - 154ms/step\n",
      "Epoch 7/100\n",
      "69/69 - 11s - loss: 0.1172 - accuracy: 0.9474 - auc: 0.9920 - val_loss: 8.1770 - val_accuracy: 0.4599 - val_auc: 0.4205 - 11s/epoch - 154ms/step\n",
      "Epoch 8/100\n",
      "69/69 - 11s - loss: 0.1054 - accuracy: 0.9655 - auc: 0.9917 - val_loss: 17.3590 - val_accuracy: 0.5328 - val_auc: 0.4806 - 11s/epoch - 155ms/step\n",
      "Epoch 9/100\n",
      "69/69 - 11s - loss: 0.0321 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.6147 - val_accuracy: 0.7518 - val_auc: 0.8764 - 11s/epoch - 161ms/step\n",
      "Epoch 10/100\n",
      "69/69 - 11s - loss: 0.0452 - accuracy: 0.9819 - auc: 0.9970 - val_loss: 1.1158 - val_accuracy: 0.5182 - val_auc: 0.6802 - 11s/epoch - 155ms/step\n",
      "Epoch 11/100\n",
      "69/69 - 11s - loss: 0.0399 - accuracy: 0.9964 - auc: 0.9977 - val_loss: 0.0249 - val_accuracy: 0.9927 - val_auc: 0.9999 - 11s/epoch - 162ms/step\n",
      "Epoch 12/100\n",
      "69/69 - 11s - loss: 0.0912 - accuracy: 0.9764 - auc: 0.9915 - val_loss: 2.4843 - val_accuracy: 0.6277 - val_auc: 0.6809 - 11s/epoch - 156ms/step\n",
      "Epoch 13/100\n",
      "69/69 - 11s - loss: 0.0562 - accuracy: 0.9855 - auc: 0.9948 - val_loss: 0.1057 - val_accuracy: 0.9708 - val_auc: 0.9874 - 11s/epoch - 156ms/step\n",
      "Epoch 14/100\n",
      "69/69 - 11s - loss: 0.0520 - accuracy: 0.9800 - auc: 0.9985 - val_loss: 0.0865 - val_accuracy: 0.9781 - val_auc: 0.9973 - 11s/epoch - 156ms/step\n",
      "Epoch 15/100\n",
      "69/69 - 11s - loss: 0.1404 - accuracy: 0.9510 - auc: 0.9863 - val_loss: 0.3758 - val_accuracy: 0.8759 - val_auc: 0.9424 - 11s/epoch - 157ms/step\n",
      "Epoch 16/100\n",
      "69/69 - 11s - loss: 0.1449 - accuracy: 0.9528 - auc: 0.9880 - val_loss: 0.6132 - val_accuracy: 0.8613 - val_auc: 0.9207 - 11s/epoch - 157ms/step\n",
      "Epoch 17/100\n",
      "69/69 - 11s - loss: 0.1386 - accuracy: 0.9583 - auc: 0.9850 - val_loss: 0.7085 - val_accuracy: 0.7956 - val_auc: 0.8612 - 11s/epoch - 157ms/step\n",
      "Epoch 18/100\n",
      "69/69 - 11s - loss: 0.0546 - accuracy: 0.9764 - auc: 0.9983 - val_loss: 0.0051 - val_accuracy: 1.0000 - val_auc: 1.0000 - 11s/epoch - 164ms/step\n",
      "Epoch 19/100\n",
      "69/69 - 11s - loss: 0.0780 - accuracy: 0.9800 - auc: 0.9940 - val_loss: 3.0778 - val_accuracy: 0.7007 - val_auc: 0.6474 - 11s/epoch - 158ms/step\n",
      "Epoch 20/100\n",
      "69/69 - 11s - loss: 0.0568 - accuracy: 0.9764 - auc: 0.9982 - val_loss: 0.0280 - val_accuracy: 0.9927 - val_auc: 0.9999 - 11s/epoch - 158ms/step\n",
      "Epoch 21/100\n",
      "69/69 - 11s - loss: 0.0174 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.0131 - val_accuracy: 0.9927 - val_auc: 0.9999 - 11s/epoch - 158ms/step\n",
      "Epoch 22/100\n",
      "69/69 - 11s - loss: 0.0182 - accuracy: 0.9964 - auc: 0.9998 - val_loss: 0.0022 - val_accuracy: 1.0000 - val_auc: 1.0000 - 11s/epoch - 165ms/step\n",
      "Epoch 23/100\n",
      "69/69 - 11s - loss: 0.0397 - accuracy: 0.9891 - auc: 0.9988 - val_loss: 0.2374 - val_accuracy: 0.8978 - val_auc: 0.9670 - 11s/epoch - 158ms/step\n",
      "Epoch 24/100\n",
      "69/69 - 11s - loss: 0.0575 - accuracy: 0.9873 - auc: 0.9967 - val_loss: 0.0304 - val_accuracy: 0.9927 - val_auc: 0.9994 - 11s/epoch - 159ms/step\n",
      "Epoch 25/100\n",
      "69/69 - 11s - loss: 0.0484 - accuracy: 0.9800 - auc: 0.9986 - val_loss: 0.0138 - val_accuracy: 0.9927 - val_auc: 0.9999 - 11s/epoch - 162ms/step\n",
      "Epoch 26/100\n",
      "69/69 - 11s - loss: 0.0096 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9270 - val_auc: 0.9694 - 11s/epoch - 167ms/step\n",
      "Epoch 27/100\n",
      "69/69 - 12s - loss: 0.0218 - accuracy: 0.9927 - auc: 0.9997 - val_loss: 1.3615 - val_accuracy: 0.6131 - val_auc: 0.7273 - 12s/epoch - 167ms/step\n",
      "Epoch 28/100\n",
      "69/69 - 12s - loss: 0.0938 - accuracy: 0.9710 - auc: 0.9908 - val_loss: 7.0494 - val_accuracy: 0.2993 - val_auc: 0.3233 - 12s/epoch - 170ms/step\n",
      "Epoch 29/100\n",
      "69/69 - 12s - loss: 0.0273 - accuracy: 0.9946 - auc: 0.9977 - val_loss: 0.0243 - val_accuracy: 0.9927 - val_auc: 0.9998 - 12s/epoch - 171ms/step\n",
      "Epoch 30/100\n",
      "69/69 - 12s - loss: 0.0086 - accuracy: 0.9946 - auc: 1.0000 - val_loss: 1.3022 - val_accuracy: 0.7153 - val_auc: 0.8341 - 12s/epoch - 171ms/step\n",
      "Epoch 31/100\n",
      "69/69 - 12s - loss: 0.1117 - accuracy: 0.9637 - auc: 0.9892 - val_loss: 0.1269 - val_accuracy: 0.9562 - val_auc: 0.9895 - 12s/epoch - 171ms/step\n",
      "Epoch 32/100\n",
      "69/69 - 12s - loss: 0.0940 - accuracy: 0.9637 - auc: 0.9947 - val_loss: 0.0123 - val_accuracy: 0.9927 - val_auc: 0.9999 - 12s/epoch - 172ms/step\n",
      "Epoch 33/100\n",
      "69/69 - 12s - loss: 0.0936 - accuracy: 0.9691 - auc: 0.9947 - val_loss: 0.0925 - val_accuracy: 0.9927 - val_auc: 0.9913 - 12s/epoch - 175ms/step\n",
      "Epoch 34/100\n",
      "69/69 - 12s - loss: 0.0919 - accuracy: 0.9746 - auc: 0.9947 - val_loss: 0.2979 - val_accuracy: 0.8905 - val_auc: 0.9543 - 12s/epoch - 175ms/step\n",
      "Epoch 35/100\n",
      "69/69 - 12s - loss: 0.0441 - accuracy: 0.9855 - auc: 0.9987 - val_loss: 0.0232 - val_accuracy: 0.9927 - val_auc: 0.9998 - 12s/epoch - 175ms/step\n",
      "Epoch 36/100\n",
      "69/69 - 12s - loss: 0.0087 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9781 - val_auc: 0.9987 - 12s/epoch - 175ms/step\n",
      "Epoch 37/100\n",
      "69/69 - 12s - loss: 0.0121 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9781 - val_auc: 0.9995 - 12s/epoch - 175ms/step\n",
      "Epoch 38/100\n",
      "69/69 - 12s - loss: 0.0326 - accuracy: 0.9891 - auc: 0.9994 - val_loss: 0.0257 - val_accuracy: 0.9927 - val_auc: 0.9998 - 12s/epoch - 178ms/step\n",
      "Epoch 39/100\n",
      "69/69 - 12s - loss: 0.0078 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9489 - val_auc: 0.9896 - 12s/epoch - 179ms/step\n",
      "Epoch 40/100\n",
      "69/69 - 12s - loss: 0.0094 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.8905 - val_auc: 0.9685 - 12s/epoch - 181ms/step\n",
      "Epoch 41/100\n",
      "69/69 - 13s - loss: 0.0071 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 182ms/step\n",
      "Epoch 42/100\n",
      "69/69 - 13s - loss: 0.0094 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9927 - val_auc: 0.9992 - 13s/epoch - 181ms/step\n",
      "Epoch 43/100\n",
      "69/69 - 13s - loss: 0.0118 - accuracy: 0.9982 - auc: 0.9981 - val_loss: 0.0355 - val_accuracy: 0.9854 - val_auc: 0.9997 - 13s/epoch - 181ms/step\n",
      "Epoch 44/100\n",
      "69/69 - 13s - loss: 0.0381 - accuracy: 0.9909 - auc: 0.9986 - val_loss: 0.0989 - val_accuracy: 0.9635 - val_auc: 0.9932 - 13s/epoch - 182ms/step\n",
      "Epoch 45/100\n",
      "69/69 - 13s - loss: 0.0250 - accuracy: 0.9927 - auc: 0.9997 - val_loss: 0.0149 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 182ms/step\n",
      "Epoch 46/100\n",
      "69/69 - 13s - loss: 0.0052 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 182ms/step\n",
      "Epoch 47/100\n",
      "69/69 - 13s - loss: 0.0137 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0424 - val_accuracy: 0.9927 - val_auc: 0.9989 - 13s/epoch - 182ms/step\n",
      "Epoch 48/100\n",
      "69/69 - 13s - loss: 0.0172 - accuracy: 0.9946 - auc: 0.9997 - val_loss: 0.3630 - val_accuracy: 0.8832 - val_auc: 0.9506 - 13s/epoch - 183ms/step\n",
      "Epoch 49/100\n",
      "69/69 - 13s - loss: 0.0344 - accuracy: 0.9855 - auc: 0.9994 - val_loss: 4.4182 - val_accuracy: 0.5328 - val_auc: 0.5975 - 13s/epoch - 182ms/step\n",
      "Epoch 50/100\n",
      "69/69 - 13s - loss: 0.0387 - accuracy: 0.9891 - auc: 0.9989 - val_loss: 0.3847 - val_accuracy: 0.9343 - val_auc: 0.9711 - 13s/epoch - 184ms/step\n",
      "Epoch 51/100\n",
      "69/69 - 13s - loss: 0.0482 - accuracy: 0.9837 - auc: 0.9987 - val_loss: 0.6020 - val_accuracy: 0.8686 - val_auc: 0.9534 - 13s/epoch - 184ms/step\n",
      "Epoch 52/100\n",
      "69/69 - 13s - loss: 0.0129 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0785 - val_accuracy: 0.9854 - val_auc: 0.9918 - 13s/epoch - 184ms/step\n",
      "Epoch 53/100\n",
      "69/69 - 13s - loss: 0.0066 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 54/100\n",
      "69/69 - 13s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.7710e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 55/100\n",
      "69/69 - 13s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 56/100\n",
      "69/69 - 13s - loss: 0.0063 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9416 - val_auc: 0.9905 - 13s/epoch - 184ms/step\n",
      "Epoch 57/100\n",
      "69/69 - 13s - loss: 0.0101 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0163 - val_accuracy: 0.9927 - val_auc: 0.9999 - 13s/epoch - 184ms/step\n",
      "Epoch 58/100\n",
      "69/69 - 13s - loss: 0.0154 - accuracy: 0.9927 - auc: 0.9998 - val_loss: 0.3346 - val_accuracy: 0.8686 - val_auc: 0.9446 - 13s/epoch - 184ms/step\n",
      "Epoch 59/100\n",
      "69/69 - 13s - loss: 0.0178 - accuracy: 0.9946 - auc: 0.9980 - val_loss: 0.0964 - val_accuracy: 0.9781 - val_auc: 0.9918 - 13s/epoch - 184ms/step\n",
      "Epoch 60/100\n",
      "69/69 - 13s - loss: 0.0295 - accuracy: 0.9873 - auc: 0.9978 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 61/100\n",
      "69/69 - 13s - loss: 0.0280 - accuracy: 0.9909 - auc: 0.9979 - val_loss: 0.3288 - val_accuracy: 0.9343 - val_auc: 0.9711 - 13s/epoch - 184ms/step\n",
      "Epoch 62/100\n",
      "69/69 - 13s - loss: 0.1052 - accuracy: 0.9746 - auc: 0.9887 - val_loss: 5.5029 - val_accuracy: 0.5401 - val_auc: 0.5504 - 13s/epoch - 184ms/step\n",
      "Epoch 63/100\n",
      "69/69 - 13s - loss: 0.0253 - accuracy: 0.9927 - auc: 0.9996 - val_loss: 0.1067 - val_accuracy: 0.9781 - val_auc: 0.9891 - 13s/epoch - 184ms/step\n",
      "Epoch 64/100\n",
      "69/69 - 13s - loss: 0.0078 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9927 - val_auc: 0.9998 - 13s/epoch - 184ms/step\n",
      "Epoch 65/100\n",
      "69/69 - 13s - loss: 0.0052 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 66/100\n",
      "69/69 - 13s - loss: 9.3473e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 67/100\n",
      "69/69 - 13s - loss: 6.5322e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 7.2472e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 68/100\n",
      "69/69 - 13s - loss: 8.8965e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 7.9580e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 69/100\n",
      "69/69 - 13s - loss: 3.8324e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.1933e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 70/100\n",
      "69/69 - 13s - loss: 3.1067e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.0283e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 71/100\n",
      "69/69 - 13s - loss: 6.4571e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.1682e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 72/100\n",
      "69/69 - 13s - loss: 3.5846e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.0338e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 73/100\n",
      "69/69 - 13s - loss: 6.0742e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.5724e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 74/100\n",
      "69/69 - 13s - loss: 3.6348e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.0556e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 184ms/step\n",
      "Epoch 75/100\n",
      "69/69 - 13s - loss: 2.0577e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.6179e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 76/100\n",
      "69/69 - 13s - loss: 0.1203 - accuracy: 0.9673 - auc: 0.9905 - val_loss: 0.2547 - val_accuracy: 0.9270 - val_auc: 0.9681 - 13s/epoch - 184ms/step\n",
      "Epoch 77/100\n",
      "69/69 - 13s - loss: 0.1214 - accuracy: 0.9710 - auc: 0.9876 - val_loss: 3.1926 - val_accuracy: 0.3869 - val_auc: 0.4681 - 13s/epoch - 185ms/step\n",
      "Epoch 78/100\n",
      "69/69 - 13s - loss: 0.0725 - accuracy: 0.9800 - auc: 0.9944 - val_loss: 0.1916 - val_accuracy: 0.8905 - val_auc: 0.9760 - 13s/epoch - 188ms/step\n",
      "Epoch 79/100\n",
      "69/69 - 13s - loss: 0.0485 - accuracy: 0.9819 - auc: 0.9986 - val_loss: 3.1805 - val_accuracy: 0.6715 - val_auc: 0.6715 - 13s/epoch - 188ms/step\n",
      "Epoch 80/100\n",
      "69/69 - 13s - loss: 0.0239 - accuracy: 0.9927 - auc: 0.9979 - val_loss: 0.0751 - val_accuracy: 0.9927 - val_auc: 0.9913 - 13s/epoch - 194ms/step\n",
      "Epoch 81/100\n",
      "69/69 - 14s - loss: 0.0150 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 201ms/step\n",
      "Epoch 82/100\n",
      "69/69 - 13s - loss: 0.0083 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 188ms/step\n",
      "Epoch 83/100\n",
      "69/69 - 13s - loss: 0.0082 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9927 - val_auc: 0.9999 - 13s/epoch - 188ms/step\n",
      "Epoch 84/100\n",
      "69/69 - 13s - loss: 0.0195 - accuracy: 0.9927 - auc: 0.9998 - val_loss: 0.4839 - val_accuracy: 0.8102 - val_auc: 0.9204 - 13s/epoch - 192ms/step\n",
      "Epoch 85/100\n",
      "69/69 - 13s - loss: 0.0140 - accuracy: 0.9982 - auc: 0.9999 - val_loss: 0.0182 - val_accuracy: 0.9927 - val_auc: 0.9998 - 13s/epoch - 193ms/step\n",
      "Epoch 86/100\n",
      "69/69 - 13s - loss: 0.0132 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.0703 - val_accuracy: 0.9854 - val_auc: 0.9994 - 13s/epoch - 193ms/step\n",
      "Epoch 87/100\n",
      "69/69 - 13s - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.1271 - val_accuracy: 0.7007 - val_auc: 0.7007 - 13s/epoch - 193ms/step\n",
      "Epoch 88/100\n",
      "69/69 - 13s - loss: 0.0249 - accuracy: 0.9927 - auc: 0.9979 - val_loss: 0.3352 - val_accuracy: 0.8248 - val_auc: 0.9448 - 13s/epoch - 192ms/step\n",
      "Epoch 89/100\n",
      "69/69 - 13s - loss: 0.0508 - accuracy: 0.9873 - auc: 0.9973 - val_loss: 0.0448 - val_accuracy: 0.9854 - val_auc: 0.9997 - 13s/epoch - 196ms/step\n",
      "Epoch 90/100\n",
      "69/69 - 14s - loss: 0.0110 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.0041 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 198ms/step\n",
      "Epoch 91/100\n",
      "69/69 - 14s - loss: 0.0096 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 198ms/step\n",
      "Epoch 92/100\n",
      "69/69 - 14s - loss: 0.0045 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 198ms/step\n",
      "Epoch 93/100\n",
      "69/69 - 14s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 198ms/step\n",
      "Epoch 94/100\n",
      "69/69 - 14s - loss: 0.0027 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.5242e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 197ms/step\n",
      "Epoch 95/100\n",
      "69/69 - 14s - loss: 8.6666e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.9070e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 198ms/step\n",
      "Epoch 96/100\n",
      "69/69 - 15s - loss: 9.8779e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 210ms/step\n",
      "Epoch 97/100\n",
      "69/69 - 13s - loss: 4.1633e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.5254e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 194ms/step\n",
      "Epoch 98/100\n",
      "69/69 - 14s - loss: 3.1903e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5818e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 198ms/step\n",
      "Epoch 99/100\n",
      "69/69 - 14s - loss: 4.8235e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4009e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 197ms/step\n",
      "Epoch 100/100\n",
      "69/69 - 14s - loss: 5.9794e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 9.1268e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 198ms/step\n",
      "5/5 [==============================] - 4s 193ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n",
      "Roc 1.0\n",
      "[[41  0]\n",
      " [ 0 96]]\n",
      "FF shape (513, 128)\n",
      "Trainable mel spectrogram is True\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Generated (RN-att2)-concat-pc\n",
      "FF shape (1025, 150)\n",
      "Trainable mel spectrogram is False\n",
      "DenseNet201\n",
      "Epoch 1/100\n",
      "69/69 - 79s - loss: 0.6179 - accuracy: 0.7877 - auc: 0.8313 - val_loss: 3.0164 - val_accuracy: 0.3942 - val_auc: 0.3847 - 79s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "69/69 - 11s - loss: 0.3460 - accuracy: 0.8639 - auc: 0.9326 - val_loss: 35.1305 - val_accuracy: 0.3212 - val_auc: 0.3333 - 11s/epoch - 158ms/step\n",
      "Epoch 3/100\n",
      "69/69 - 11s - loss: 0.2721 - accuracy: 0.9020 - auc: 0.9572 - val_loss: 213.7231 - val_accuracy: 0.2993 - val_auc: 0.2993 - 11s/epoch - 161ms/step\n",
      "Epoch 4/100\n",
      "69/69 - 12s - loss: 0.2006 - accuracy: 0.9310 - auc: 0.9753 - val_loss: 59.5542 - val_accuracy: 0.3066 - val_auc: 0.3081 - 12s/epoch - 168ms/step\n",
      "Epoch 5/100\n",
      "69/69 - 12s - loss: 0.2287 - accuracy: 0.9201 - auc: 0.9687 - val_loss: 43.2034 - val_accuracy: 0.3650 - val_auc: 0.3681 - 12s/epoch - 180ms/step\n",
      "Epoch 6/100\n",
      "69/69 - 13s - loss: 0.0941 - accuracy: 0.9728 - auc: 0.9938 - val_loss: 5.5290 - val_accuracy: 0.6058 - val_auc: 0.5854 - 13s/epoch - 189ms/step\n",
      "Epoch 7/100\n",
      "69/69 - 13s - loss: 0.0479 - accuracy: 0.9855 - auc: 0.9990 - val_loss: 1.6851 - val_accuracy: 0.5912 - val_auc: 0.6636 - 13s/epoch - 190ms/step\n",
      "Epoch 8/100\n",
      "69/69 - 13s - loss: 0.0492 - accuracy: 0.9819 - auc: 0.9984 - val_loss: 15.2602 - val_accuracy: 0.4161 - val_auc: 0.4113 - 13s/epoch - 185ms/step\n",
      "Epoch 9/100\n",
      "69/69 - 13s - loss: 0.0940 - accuracy: 0.9655 - auc: 0.9941 - val_loss: 2.0930 - val_accuracy: 0.6642 - val_auc: 0.7138 - 13s/epoch - 191ms/step\n",
      "Epoch 10/100\n",
      "69/69 - 13s - loss: 0.0482 - accuracy: 0.9855 - auc: 0.9970 - val_loss: 0.0247 - val_accuracy: 0.9927 - val_auc: 0.9996 - 13s/epoch - 191ms/step\n",
      "Epoch 11/100\n",
      "69/69 - 13s - loss: 0.1995 - accuracy: 0.9347 - auc: 0.9798 - val_loss: 15.6885 - val_accuracy: 0.4453 - val_auc: 0.4075 - 13s/epoch - 185ms/step\n",
      "Epoch 12/100\n",
      "69/69 - 13s - loss: 0.1226 - accuracy: 0.9546 - auc: 0.9890 - val_loss: 13.5917 - val_accuracy: 0.4891 - val_auc: 0.4678 - 13s/epoch - 185ms/step\n",
      "Epoch 13/100\n",
      "69/69 - 13s - loss: 0.1056 - accuracy: 0.9619 - auc: 0.9920 - val_loss: 0.0903 - val_accuracy: 0.9854 - val_auc: 0.9892 - 13s/epoch - 185ms/step\n",
      "Epoch 14/100\n",
      "69/69 - 13s - loss: 0.0597 - accuracy: 0.9764 - auc: 0.9977 - val_loss: 0.0357 - val_accuracy: 0.9927 - val_auc: 0.9993 - 13s/epoch - 185ms/step\n",
      "Epoch 15/100\n",
      "69/69 - 13s - loss: 0.0280 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.0984 - val_accuracy: 0.9854 - val_auc: 0.9921 - 13s/epoch - 185ms/step\n",
      "Epoch 16/100\n",
      "69/69 - 13s - loss: 0.1141 - accuracy: 0.9710 - auc: 0.9925 - val_loss: 21.4945 - val_accuracy: 0.4891 - val_auc: 0.4628 - 13s/epoch - 185ms/step\n",
      "Epoch 17/100\n",
      "69/69 - 13s - loss: 0.1329 - accuracy: 0.9456 - auc: 0.9880 - val_loss: 34.6310 - val_accuracy: 0.3066 - val_auc: 0.3037 - 13s/epoch - 185ms/step\n",
      "Epoch 18/100\n",
      "69/69 - 13s - loss: 0.0678 - accuracy: 0.9764 - auc: 0.9968 - val_loss: 6.1274 - val_accuracy: 0.6131 - val_auc: 0.6154 - 13s/epoch - 190ms/step\n",
      "Epoch 19/100\n",
      "69/69 - 13s - loss: 0.0443 - accuracy: 0.9855 - auc: 0.9985 - val_loss: 7.9374 - val_accuracy: 0.6058 - val_auc: 0.6063 - 13s/epoch - 193ms/step\n",
      "Epoch 20/100\n",
      "69/69 - 13s - loss: 0.0528 - accuracy: 0.9782 - auc: 0.9984 - val_loss: 1.2354 - val_accuracy: 0.7956 - val_auc: 0.8458 - 13s/epoch - 193ms/step\n",
      "Epoch 21/100\n",
      "69/69 - 13s - loss: 0.0575 - accuracy: 0.9819 - auc: 0.9952 - val_loss: 5.3776 - val_accuracy: 0.5401 - val_auc: 0.5294 - 13s/epoch - 193ms/step\n",
      "Epoch 22/100\n",
      "69/69 - 14s - loss: 0.0435 - accuracy: 0.9819 - auc: 0.9991 - val_loss: 0.0127 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 204ms/step\n",
      "Epoch 23/100\n",
      "69/69 - 13s - loss: 0.0606 - accuracy: 0.9855 - auc: 0.9961 - val_loss: 0.2424 - val_accuracy: 0.9197 - val_auc: 0.9737 - 13s/epoch - 194ms/step\n",
      "Epoch 24/100\n",
      "69/69 - 14s - loss: 0.0340 - accuracy: 0.9891 - auc: 0.9993 - val_loss: 0.0135 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 199ms/step\n",
      "Epoch 25/100\n",
      "69/69 - 14s - loss: 0.0371 - accuracy: 0.9909 - auc: 0.9991 - val_loss: 0.3478 - val_accuracy: 0.8248 - val_auc: 0.9483 - 14s/epoch - 209ms/step\n",
      "Epoch 26/100\n",
      "69/69 - 14s - loss: 0.0035 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 206ms/step\n",
      "Epoch 27/100\n",
      "69/69 - 13s - loss: 0.0042 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9635 - val_auc: 0.9940 - 13s/epoch - 193ms/step\n",
      "Epoch 28/100\n",
      "69/69 - 14s - loss: 0.0053 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 207ms/step\n",
      "Epoch 29/100\n",
      "69/69 - 14s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 198ms/step\n",
      "Epoch 30/100\n",
      "69/69 - 14s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 31/100\n",
      "69/69 - 14s - loss: 0.0728 - accuracy: 0.9728 - auc: 0.9963 - val_loss: 2.6323 - val_accuracy: 0.7153 - val_auc: 0.7549 - 14s/epoch - 202ms/step\n",
      "Epoch 32/100\n",
      "69/69 - 14s - loss: 0.1558 - accuracy: 0.9601 - auc: 0.9857 - val_loss: 2.5803 - val_accuracy: 0.7883 - val_auc: 0.8461 - 14s/epoch - 202ms/step\n",
      "Epoch 33/100\n",
      "69/69 - 14s - loss: 0.1585 - accuracy: 0.9383 - auc: 0.9850 - val_loss: 9.2394 - val_accuracy: 0.4672 - val_auc: 0.4442 - 14s/epoch - 201ms/step\n",
      "Epoch 34/100\n",
      "69/69 - 14s - loss: 0.1016 - accuracy: 0.9619 - auc: 0.9928 - val_loss: 1.0189 - val_accuracy: 0.6934 - val_auc: 0.7955 - 14s/epoch - 201ms/step\n",
      "Epoch 35/100\n",
      "69/69 - 14s - loss: 0.0600 - accuracy: 0.9764 - auc: 0.9979 - val_loss: 0.1688 - val_accuracy: 0.9124 - val_auc: 0.9821 - 14s/epoch - 201ms/step\n",
      "Epoch 36/100\n",
      "69/69 - 14s - loss: 0.0314 - accuracy: 0.9927 - auc: 0.9993 - val_loss: 0.2061 - val_accuracy: 0.9124 - val_auc: 0.9778 - 14s/epoch - 202ms/step\n",
      "Epoch 37/100\n",
      "69/69 - 14s - loss: 0.0403 - accuracy: 0.9873 - auc: 0.9975 - val_loss: 0.0298 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 38/100\n",
      "69/69 - 14s - loss: 0.0472 - accuracy: 0.9855 - auc: 0.9987 - val_loss: 5.9756 - val_accuracy: 0.6204 - val_auc: 0.5960 - 14s/epoch - 202ms/step\n",
      "Epoch 39/100\n",
      "69/69 - 14s - loss: 0.0160 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.0341 - val_accuracy: 0.9927 - val_auc: 0.9990 - 14s/epoch - 202ms/step\n",
      "Epoch 40/100\n",
      "69/69 - 14s - loss: 0.0573 - accuracy: 0.9837 - auc: 0.9976 - val_loss: 0.2625 - val_accuracy: 0.8759 - val_auc: 0.9611 - 14s/epoch - 202ms/step\n",
      "Epoch 41/100\n",
      "69/69 - 14s - loss: 0.0767 - accuracy: 0.9728 - auc: 0.9949 - val_loss: 0.1260 - val_accuracy: 0.9635 - val_auc: 0.9902 - 14s/epoch - 202ms/step\n",
      "Epoch 42/100\n",
      "69/69 - 14s - loss: 0.0431 - accuracy: 0.9891 - auc: 0.9975 - val_loss: 0.0044 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 43/100\n",
      "69/69 - 14s - loss: 0.0165 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0038 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 44/100\n",
      "69/69 - 14s - loss: 0.0262 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.0839 - val_accuracy: 0.9708 - val_auc: 0.9946 - 14s/epoch - 202ms/step\n",
      "Epoch 45/100\n",
      "69/69 - 14s - loss: 0.0108 - accuracy: 0.9946 - auc: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 46/100\n",
      "69/69 - 14s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.2017e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 47/100\n",
      "69/69 - 14s - loss: 0.0057 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 1.5176e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 48/100\n",
      "69/69 - 14s - loss: 0.0102 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 203ms/step\n",
      "Epoch 49/100\n",
      "69/69 - 14s - loss: 0.0065 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 203ms/step\n",
      "Epoch 50/100\n",
      "69/69 - 14s - loss: 0.0150 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0696 - val_accuracy: 0.9708 - val_auc: 0.9970 - 14s/epoch - 203ms/step\n",
      "Epoch 51/100\n",
      "69/69 - 14s - loss: 0.0371 - accuracy: 0.9909 - auc: 0.9970 - val_loss: 0.0562 - val_accuracy: 0.9781 - val_auc: 0.9979 - 14s/epoch - 202ms/step\n",
      "Epoch 52/100\n",
      "69/69 - 14s - loss: 0.0069 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 53/100\n",
      "69/69 - 15s - loss: 0.0505 - accuracy: 0.9891 - auc: 0.9973 - val_loss: 3.6484 - val_accuracy: 0.7007 - val_auc: 0.7365 - 15s/epoch - 212ms/step\n",
      "Epoch 54/100\n",
      "69/69 - 15s - loss: 0.0649 - accuracy: 0.9800 - auc: 0.9974 - val_loss: 3.0595 - val_accuracy: 0.5036 - val_auc: 0.5759 - 15s/epoch - 212ms/step\n",
      "Epoch 55/100\n",
      "69/69 - 15s - loss: 0.0225 - accuracy: 0.9873 - auc: 0.9998 - val_loss: 0.1813 - val_accuracy: 0.9343 - val_auc: 0.9819 - 15s/epoch - 212ms/step\n",
      "Epoch 56/100\n",
      "69/69 - 14s - loss: 0.0246 - accuracy: 0.9927 - auc: 0.9980 - val_loss: 0.1240 - val_accuracy: 0.9416 - val_auc: 0.9899 - 14s/epoch - 201ms/step\n",
      "Epoch 57/100\n",
      "69/69 - 14s - loss: 0.0199 - accuracy: 0.9946 - auc: 0.9997 - val_loss: 0.1179 - val_accuracy: 0.9635 - val_auc: 0.9911 - 14s/epoch - 205ms/step\n",
      "Epoch 58/100\n",
      "69/69 - 14s - loss: 0.0060 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 210ms/step\n",
      "Epoch 59/100\n",
      "69/69 - 14s - loss: 0.0103 - accuracy: 0.9982 - auc: 0.9999 - val_loss: 1.6399 - val_accuracy: 0.7153 - val_auc: 0.7992 - 14s/epoch - 209ms/step\n",
      "Epoch 60/100\n",
      "69/69 - 14s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.1216e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 209ms/step\n",
      "Epoch 61/100\n",
      "69/69 - 14s - loss: 0.0053 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 209ms/step\n",
      "Epoch 62/100\n",
      "69/69 - 14s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.8139e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 209ms/step\n",
      "Epoch 63/100\n",
      "69/69 - 14s - loss: 5.5273e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2579e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 209ms/step\n",
      "Epoch 64/100\n",
      "69/69 - 14s - loss: 0.0096 - accuracy: 0.9982 - auc: 0.9999 - val_loss: 0.5623 - val_accuracy: 0.8248 - val_auc: 0.9307 - 14s/epoch - 210ms/step\n",
      "Epoch 65/100\n",
      "69/69 - 15s - loss: 0.0211 - accuracy: 0.9909 - auc: 0.9997 - val_loss: 0.7507 - val_accuracy: 0.7445 - val_auc: 0.8558 - 15s/epoch - 210ms/step\n",
      "Epoch 66/100\n",
      "69/69 - 14s - loss: 0.0100 - accuracy: 0.9946 - auc: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 210ms/step\n",
      "Epoch 67/100\n",
      "69/69 - 14s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 209ms/step\n",
      "Epoch 68/100\n",
      "69/69 - 15s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 9.4727e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 69/100\n",
      "69/69 - 13s - loss: 0.0049 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 193ms/step\n",
      "Epoch 70/100\n",
      "69/69 - 14s - loss: 0.0895 - accuracy: 0.9764 - auc: 0.9944 - val_loss: 1.9094 - val_accuracy: 0.7299 - val_auc: 0.7535 - 14s/epoch - 201ms/step\n",
      "Epoch 71/100\n",
      "69/69 - 14s - loss: 0.0167 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.0955 - val_accuracy: 0.9562 - val_auc: 0.9946 - 14s/epoch - 204ms/step\n",
      "Epoch 72/100\n",
      "69/69 - 14s - loss: 0.0229 - accuracy: 0.9909 - auc: 0.9997 - val_loss: 1.2689 - val_accuracy: 0.7299 - val_auc: 0.8423 - 14s/epoch - 203ms/step\n",
      "Epoch 73/100\n",
      "69/69 - 14s - loss: 0.0441 - accuracy: 0.9819 - auc: 0.9988 - val_loss: 0.0148 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 204ms/step\n",
      "Epoch 74/100\n",
      "69/69 - 14s - loss: 0.0332 - accuracy: 0.9855 - auc: 0.9993 - val_loss: 1.3678 - val_accuracy: 0.8467 - val_auc: 0.8789 - 14s/epoch - 204ms/step\n",
      "Epoch 75/100\n",
      "69/69 - 14s - loss: 0.0160 - accuracy: 0.9964 - auc: 0.9998 - val_loss: 0.0015 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 76/100\n",
      "69/69 - 14s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 77/100\n",
      "69/69 - 14s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 9.4946e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 78/100\n",
      "69/69 - 14s - loss: 9.9634e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.9994e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 79/100\n",
      "69/69 - 14s - loss: 0.0154 - accuracy: 0.9964 - auc: 0.9998 - val_loss: 1.4118 - val_accuracy: 0.8394 - val_auc: 0.8656 - 14s/epoch - 204ms/step\n",
      "Epoch 80/100\n",
      "69/69 - 14s - loss: 0.0054 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9927 - val_auc: 0.9998 - 14s/epoch - 204ms/step\n",
      "Epoch 81/100\n",
      "69/69 - 14s - loss: 0.0150 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0155 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 82/100\n",
      "69/69 - 14s - loss: 0.0059 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 83/100\n",
      "69/69 - 14s - loss: 0.0047 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 84/100\n",
      "69/69 - 14s - loss: 8.5515e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.3002e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 85/100\n",
      "69/69 - 14s - loss: 3.5825e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.2839e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 86/100\n",
      "69/69 - 14s - loss: 3.4272e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.0810e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 87/100\n",
      "69/69 - 15s - loss: 1.3018e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.7247e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 215ms/step\n",
      "Epoch 88/100\n",
      "69/69 - 14s - loss: 5.9201e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.3587e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 89/100\n",
      "69/69 - 15s - loss: 1.4437e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 7.3217e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 90/100\n",
      "69/69 - 15s - loss: 1.8846e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.1669e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 91/100\n",
      "69/69 - 15s - loss: 1.2238e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.2095e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 92/100\n",
      "69/69 - 15s - loss: 8.4280e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.6454e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 212ms/step\n",
      "Epoch 93/100\n",
      "69/69 - 15s - loss: 3.1232e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.8954e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 94/100\n",
      "69/69 - 15s - loss: 1.3997e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.8783e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 210ms/step\n",
      "Epoch 95/100\n",
      "69/69 - 14s - loss: 9.2522e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.1522e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 210ms/step\n",
      "Epoch 96/100\n",
      "69/69 - 14s - loss: 6.1640e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.2742e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 97/100\n",
      "69/69 - 15s - loss: 4.6763e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.8223e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 216ms/step\n",
      "Epoch 98/100\n",
      "69/69 - 15s - loss: 5.7924e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4648e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 216ms/step\n",
      "Epoch 99/100\n",
      "69/69 - 14s - loss: 4.1460e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.2895e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 100/100\n",
      "69/69 - 15s - loss: 1.2088e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.4455e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "5/5 [==============================] - 3s 150ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n",
      "Roc 1.0\n",
      "[[41  0]\n",
      " [ 0 96]]\n",
      "FF shape (513, 128)\n",
      "Trainable mel spectrogram is True\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Generated (RN-att2)-concat-pc\n",
      "FF shape (1025, 150)\n",
      "Trainable mel spectrogram is False\n",
      "DenseNet201\n",
      "Epoch 1/100\n",
      "69/69 - 80s - loss: 0.5456 - accuracy: 0.8113 - auc: 0.8631 - val_loss: 54.3076 - val_accuracy: 0.2993 - val_auc: 0.3102 - 80s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "69/69 - 11s - loss: 0.2695 - accuracy: 0.9129 - auc: 0.9541 - val_loss: 142.9267 - val_accuracy: 0.3066 - val_auc: 0.3037 - 11s/epoch - 158ms/step\n",
      "Epoch 3/100\n",
      "69/69 - 12s - loss: 0.3185 - accuracy: 0.8802 - auc: 0.9437 - val_loss: 36.6785 - val_accuracy: 0.3358 - val_auc: 0.3287 - 12s/epoch - 168ms/step\n",
      "Epoch 4/100\n",
      "69/69 - 12s - loss: 0.1780 - accuracy: 0.9328 - auc: 0.9794 - val_loss: 1.9010 - val_accuracy: 0.6788 - val_auc: 0.7218 - 12s/epoch - 178ms/step\n",
      "Epoch 5/100\n",
      "69/69 - 12s - loss: 0.1710 - accuracy: 0.9365 - auc: 0.9812 - val_loss: 8.3828 - val_accuracy: 0.5985 - val_auc: 0.6067 - 12s/epoch - 180ms/step\n",
      "Epoch 6/100\n",
      "69/69 - 13s - loss: 0.1511 - accuracy: 0.9383 - auc: 0.9859 - val_loss: 0.3369 - val_accuracy: 0.8905 - val_auc: 0.9486 - 13s/epoch - 189ms/step\n",
      "Epoch 7/100\n",
      "69/69 - 13s - loss: 0.1216 - accuracy: 0.9492 - auc: 0.9912 - val_loss: 0.2106 - val_accuracy: 0.9562 - val_auc: 0.9875 - 13s/epoch - 190ms/step\n",
      "Epoch 8/100\n",
      "69/69 - 13s - loss: 0.0904 - accuracy: 0.9637 - auc: 0.9951 - val_loss: 0.2496 - val_accuracy: 0.9416 - val_auc: 0.9780 - 13s/epoch - 184ms/step\n",
      "Epoch 9/100\n",
      "69/69 - 13s - loss: 0.0955 - accuracy: 0.9691 - auc: 0.9932 - val_loss: 0.3652 - val_accuracy: 0.8540 - val_auc: 0.9457 - 13s/epoch - 184ms/step\n",
      "Epoch 10/100\n",
      "69/69 - 13s - loss: 0.0869 - accuracy: 0.9710 - auc: 0.9938 - val_loss: 0.0803 - val_accuracy: 0.9708 - val_auc: 0.9907 - 13s/epoch - 191ms/step\n",
      "Epoch 11/100\n",
      "69/69 - 13s - loss: 0.1183 - accuracy: 0.9601 - auc: 0.9897 - val_loss: 0.0333 - val_accuracy: 0.9781 - val_auc: 0.9995 - 13s/epoch - 191ms/step\n",
      "Epoch 12/100\n",
      "69/69 - 13s - loss: 0.1144 - accuracy: 0.9564 - auc: 0.9910 - val_loss: 0.7287 - val_accuracy: 0.8394 - val_auc: 0.8847 - 13s/epoch - 184ms/step\n",
      "Epoch 13/100\n",
      "69/69 - 13s - loss: 0.1255 - accuracy: 0.9601 - auc: 0.9894 - val_loss: 2.1845 - val_accuracy: 0.5985 - val_auc: 0.6636 - 13s/epoch - 185ms/step\n",
      "Epoch 14/100\n",
      "69/69 - 13s - loss: 0.1089 - accuracy: 0.9474 - auc: 0.9932 - val_loss: 12.6123 - val_accuracy: 0.5839 - val_auc: 0.5811 - 13s/epoch - 185ms/step\n",
      "Epoch 15/100\n",
      "69/69 - 13s - loss: 0.0718 - accuracy: 0.9819 - auc: 0.9953 - val_loss: 0.1797 - val_accuracy: 0.9562 - val_auc: 0.9774 - 13s/epoch - 191ms/step\n",
      "Epoch 16/100\n",
      "69/69 - 14s - loss: 0.1320 - accuracy: 0.9492 - auc: 0.9905 - val_loss: 2.1080 - val_accuracy: 0.7007 - val_auc: 0.7621 - 14s/epoch - 200ms/step\n",
      "Epoch 17/100\n",
      "69/69 - 14s - loss: 0.0910 - accuracy: 0.9691 - auc: 0.9950 - val_loss: 0.2895 - val_accuracy: 0.9343 - val_auc: 0.9731 - 14s/epoch - 198ms/step\n",
      "Epoch 18/100\n",
      "69/69 - 14s - loss: 0.0927 - accuracy: 0.9673 - auc: 0.9945 - val_loss: 0.0129 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 206ms/step\n",
      "Epoch 19/100\n",
      "69/69 - 14s - loss: 0.0689 - accuracy: 0.9764 - auc: 0.9955 - val_loss: 12.1835 - val_accuracy: 0.5547 - val_auc: 0.5506 - 14s/epoch - 196ms/step\n",
      "Epoch 20/100\n",
      "69/69 - 14s - loss: 0.0871 - accuracy: 0.9655 - auc: 0.9943 - val_loss: 0.0705 - val_accuracy: 0.9927 - val_auc: 0.9898 - 14s/epoch - 200ms/step\n",
      "Epoch 21/100\n",
      "69/69 - 14s - loss: 0.0627 - accuracy: 0.9728 - auc: 0.9963 - val_loss: 0.2245 - val_accuracy: 0.9124 - val_auc: 0.9707 - 14s/epoch - 201ms/step\n",
      "Epoch 22/100\n",
      "69/69 - 14s - loss: 0.0543 - accuracy: 0.9855 - auc: 0.9980 - val_loss: 0.3269 - val_accuracy: 0.9124 - val_auc: 0.9600 - 14s/epoch - 201ms/step\n",
      "Epoch 23/100\n",
      "69/69 - 14s - loss: 0.0423 - accuracy: 0.9873 - auc: 0.9989 - val_loss: 0.3268 - val_accuracy: 0.9051 - val_auc: 0.9519 - 14s/epoch - 201ms/step\n",
      "Epoch 24/100\n",
      "69/69 - 14s - loss: 0.0482 - accuracy: 0.9819 - auc: 0.9987 - val_loss: 1.0538 - val_accuracy: 0.8102 - val_auc: 0.8881 - 14s/epoch - 201ms/step\n",
      "Epoch 25/100\n",
      "69/69 - 14s - loss: 0.1065 - accuracy: 0.9673 - auc: 0.9924 - val_loss: 0.0427 - val_accuracy: 0.9927 - val_auc: 0.9983 - 14s/epoch - 201ms/step\n",
      "Epoch 26/100\n",
      "69/69 - 14s - loss: 0.0351 - accuracy: 0.9855 - auc: 0.9994 - val_loss: 0.4786 - val_accuracy: 0.8175 - val_auc: 0.9116 - 14s/epoch - 202ms/step\n",
      "Epoch 27/100\n",
      "69/69 - 14s - loss: 0.0362 - accuracy: 0.9909 - auc: 0.9992 - val_loss: 0.0242 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 203ms/step\n",
      "Epoch 28/100\n",
      "69/69 - 14s - loss: 0.0618 - accuracy: 0.9728 - auc: 0.9977 - val_loss: 0.0154 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 205ms/step\n",
      "Epoch 29/100\n",
      "69/69 - 14s - loss: 0.0525 - accuracy: 0.9800 - auc: 0.9967 - val_loss: 1.9097 - val_accuracy: 0.7153 - val_auc: 0.7575 - 14s/epoch - 208ms/step\n",
      "Epoch 30/100\n",
      "69/69 - 14s - loss: 0.0196 - accuracy: 0.9927 - auc: 0.9998 - val_loss: 0.0685 - val_accuracy: 0.9708 - val_auc: 0.9974 - 14s/epoch - 208ms/step\n",
      "Epoch 31/100\n",
      "69/69 - 14s - loss: 0.0321 - accuracy: 0.9873 - auc: 0.9994 - val_loss: 0.2229 - val_accuracy: 0.9051 - val_auc: 0.9771 - 14s/epoch - 208ms/step\n",
      "Epoch 32/100\n",
      "69/69 - 14s - loss: 0.0275 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.4989 - val_accuracy: 0.8832 - val_auc: 0.9406 - 14s/epoch - 208ms/step\n",
      "Epoch 33/100\n",
      "69/69 - 14s - loss: 0.0507 - accuracy: 0.9782 - auc: 0.9987 - val_loss: 0.0476 - val_accuracy: 0.9781 - val_auc: 0.9990 - 14s/epoch - 208ms/step\n",
      "Epoch 34/100\n",
      "69/69 - 14s - loss: 0.1137 - accuracy: 0.9564 - auc: 0.9929 - val_loss: 1.8410 - val_accuracy: 0.7153 - val_auc: 0.7728 - 14s/epoch - 209ms/step\n",
      "Epoch 35/100\n",
      "69/69 - 14s - loss: 0.0460 - accuracy: 0.9837 - auc: 0.9987 - val_loss: 0.4339 - val_accuracy: 0.8613 - val_auc: 0.9479 - 14s/epoch - 208ms/step\n",
      "Epoch 36/100\n",
      "69/69 - 14s - loss: 0.0121 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 208ms/step\n",
      "Epoch 37/100\n",
      "69/69 - 14s - loss: 0.0121 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 38/100\n",
      "69/69 - 14s - loss: 0.0119 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9927 - val_auc: 0.9916 - 14s/epoch - 208ms/step\n",
      "Epoch 39/100\n",
      "69/69 - 14s - loss: 0.0064 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 40/100\n",
      "69/69 - 14s - loss: 0.0031 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 41/100\n",
      "69/69 - 14s - loss: 0.0153 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.2013 - val_accuracy: 0.9270 - val_auc: 0.9771 - 14s/epoch - 208ms/step\n",
      "Epoch 42/100\n",
      "69/69 - 14s - loss: 0.0235 - accuracy: 0.9909 - auc: 0.9997 - val_loss: 0.3202 - val_accuracy: 0.8613 - val_auc: 0.9514 - 14s/epoch - 208ms/step\n",
      "Epoch 43/100\n",
      "69/69 - 14s - loss: 0.0074 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.7518 - val_auc: 0.8876 - 14s/epoch - 208ms/step\n",
      "Epoch 44/100\n",
      "69/69 - 14s - loss: 0.0080 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.9991e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 45/100\n",
      "69/69 - 14s - loss: 0.0053 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9343 - val_auc: 0.9908 - 14s/epoch - 208ms/step\n",
      "Epoch 46/100\n",
      "69/69 - 14s - loss: 0.0836 - accuracy: 0.9764 - auc: 0.9925 - val_loss: 1.6291 - val_accuracy: 0.7518 - val_auc: 0.7910 - 14s/epoch - 208ms/step\n",
      "Epoch 47/100\n",
      "69/69 - 14s - loss: 0.0181 - accuracy: 0.9946 - auc: 0.9998 - val_loss: 0.0099 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 208ms/step\n",
      "Epoch 48/100\n",
      "69/69 - 14s - loss: 0.0383 - accuracy: 0.9873 - auc: 0.9990 - val_loss: 0.0033 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 49/100\n",
      "69/69 - 14s - loss: 0.0153 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0277 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 207ms/step\n",
      "Epoch 50/100\n",
      "69/69 - 14s - loss: 0.0420 - accuracy: 0.9873 - auc: 0.9990 - val_loss: 3.6447 - val_accuracy: 0.7007 - val_auc: 0.7058 - 14s/epoch - 208ms/step\n",
      "Epoch 51/100\n",
      "69/69 - 14s - loss: 0.0163 - accuracy: 0.9982 - auc: 0.9980 - val_loss: 0.0335 - val_accuracy: 0.9927 - val_auc: 0.9998 - 14s/epoch - 209ms/step\n",
      "Epoch 52/100\n",
      "69/69 - 14s - loss: 0.0056 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9854 - val_auc: 0.9964 - 14s/epoch - 208ms/step\n",
      "Epoch 53/100\n",
      "69/69 - 14s - loss: 0.0448 - accuracy: 0.9855 - auc: 0.9975 - val_loss: 0.2917 - val_accuracy: 0.8686 - val_auc: 0.9655 - 14s/epoch - 208ms/step\n",
      "Epoch 54/100\n",
      "69/69 - 14s - loss: 0.0788 - accuracy: 0.9655 - auc: 0.9966 - val_loss: 0.0434 - val_accuracy: 0.9927 - val_auc: 0.9996 - 14s/epoch - 207ms/step\n",
      "Epoch 55/100\n",
      "69/69 - 14s - loss: 0.0482 - accuracy: 0.9909 - auc: 0.9968 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 56/100\n",
      "69/69 - 14s - loss: 0.0561 - accuracy: 0.9800 - auc: 0.9965 - val_loss: 0.0161 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 209ms/step\n",
      "Epoch 57/100\n",
      "69/69 - 14s - loss: 0.0159 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 2.9312 - val_accuracy: 0.7007 - val_auc: 0.7161 - 14s/epoch - 210ms/step\n",
      "Epoch 58/100\n",
      "69/69 - 15s - loss: 0.0062 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9416 - val_auc: 0.9931 - 15s/epoch - 216ms/step\n",
      "Epoch 59/100\n",
      "69/69 - 15s - loss: 0.0259 - accuracy: 0.9927 - auc: 0.9995 - val_loss: 0.7109 - val_accuracy: 0.8613 - val_auc: 0.9068 - 15s/epoch - 216ms/step\n",
      "Epoch 60/100\n",
      "69/69 - 15s - loss: 0.0432 - accuracy: 0.9873 - auc: 0.9989 - val_loss: 1.1016 - val_accuracy: 0.7299 - val_auc: 0.8348 - 15s/epoch - 216ms/step\n",
      "Epoch 61/100\n",
      "69/69 - 15s - loss: 0.0496 - accuracy: 0.9819 - auc: 0.9971 - val_loss: 0.0710 - val_accuracy: 0.9781 - val_auc: 0.9975 - 15s/epoch - 215ms/step\n",
      "Epoch 62/100\n",
      "69/69 - 15s - loss: 0.0160 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0149 - val_accuracy: 0.9927 - val_auc: 0.9999 - 15s/epoch - 218ms/step\n",
      "Epoch 63/100\n",
      "69/69 - 14s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.2290e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 64/100\n",
      "69/69 - 14s - loss: 0.0124 - accuracy: 0.9982 - auc: 0.9999 - val_loss: 0.0794 - val_accuracy: 0.9635 - val_auc: 0.9970 - 14s/epoch - 201ms/step\n",
      "Epoch 65/100\n",
      "69/69 - 14s - loss: 0.0170 - accuracy: 0.9946 - auc: 0.9998 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 66/100\n",
      "69/69 - 14s - loss: 0.0039 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 7.4132e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 204ms/step\n",
      "Epoch 67/100\n",
      "69/69 - 14s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 68/100\n",
      "69/69 - 14s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 206ms/step\n",
      "Epoch 69/100\n",
      "69/69 - 14s - loss: 0.0073 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 5.2364 - val_accuracy: 0.7007 - val_auc: 0.7007 - 14s/epoch - 206ms/step\n",
      "Epoch 70/100\n",
      "69/69 - 14s - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7678 - val_accuracy: 0.7080 - val_auc: 0.7264 - 14s/epoch - 205ms/step\n",
      "Epoch 71/100\n",
      "69/69 - 15s - loss: 7.2858e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 221ms/step\n",
      "Epoch 72/100\n",
      "69/69 - 14s - loss: 7.9909e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 201ms/step\n",
      "Epoch 73/100\n",
      "69/69 - 14s - loss: 0.0140 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.2461 - val_accuracy: 0.9270 - val_auc: 0.9803 - 14s/epoch - 208ms/step\n",
      "Epoch 74/100\n",
      "69/69 - 14s - loss: 0.0958 - accuracy: 0.9746 - auc: 0.9929 - val_loss: 721.9832 - val_accuracy: 0.2993 - val_auc: 0.2993 - 14s/epoch - 208ms/step\n",
      "Epoch 75/100\n",
      "69/69 - 14s - loss: 0.1075 - accuracy: 0.9637 - auc: 0.9903 - val_loss: 16.2577 - val_accuracy: 0.4161 - val_auc: 0.4097 - 14s/epoch - 207ms/step\n",
      "Epoch 76/100\n",
      "69/69 - 14s - loss: 0.0710 - accuracy: 0.9873 - auc: 0.9967 - val_loss: 0.1650 - val_accuracy: 0.9489 - val_auc: 0.9864 - 14s/epoch - 208ms/step\n",
      "Epoch 77/100\n",
      "69/69 - 14s - loss: 0.0309 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.1329 - val_accuracy: 0.9708 - val_auc: 0.9823 - 14s/epoch - 208ms/step\n",
      "Epoch 78/100\n",
      "69/69 - 14s - loss: 0.0745 - accuracy: 0.9764 - auc: 0.9967 - val_loss: 0.4462 - val_accuracy: 0.8905 - val_auc: 0.9619 - 14s/epoch - 208ms/step\n",
      "Epoch 79/100\n",
      "69/69 - 14s - loss: 0.0532 - accuracy: 0.9819 - auc: 0.9969 - val_loss: 3.7238 - val_accuracy: 0.7007 - val_auc: 0.7190 - 14s/epoch - 209ms/step\n",
      "Epoch 80/100\n",
      "69/69 - 14s - loss: 0.0339 - accuracy: 0.9873 - auc: 0.9993 - val_loss: 0.0120 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 209ms/step\n",
      "Epoch 81/100\n",
      "69/69 - 14s - loss: 0.0129 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.0147 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 208ms/step\n",
      "Epoch 82/100\n",
      "69/69 - 14s - loss: 0.0057 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 208ms/step\n",
      "Epoch 83/100\n",
      "69/69 - 14s - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.9577e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 84/100\n",
      "69/69 - 15s - loss: 0.0010 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1153e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 85/100\n",
      "69/69 - 15s - loss: 5.4709e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.6230e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 219ms/step\n",
      "Epoch 86/100\n",
      "69/69 - 15s - loss: 0.0025 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 1.5264e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 218ms/step\n",
      "Epoch 87/100\n",
      "69/69 - 15s - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 222ms/step\n",
      "Epoch 88/100\n",
      "69/69 - 15s - loss: 0.0030 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9927 - val_auc: 0.9998 - 15s/epoch - 212ms/step\n",
      "Epoch 89/100\n",
      "69/69 - 14s - loss: 6.1281e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9927 - val_auc: 0.9998 - 14s/epoch - 201ms/step\n",
      "Epoch 90/100\n",
      "69/69 - 14s - loss: 5.4450e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0129 - val_accuracy: 0.9927 - val_auc: 0.9998 - 14s/epoch - 206ms/step\n",
      "Epoch 91/100\n",
      "69/69 - 14s - loss: 6.7605e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9927 - val_auc: 0.9998 - 14s/epoch - 207ms/step\n",
      "Epoch 92/100\n",
      "69/69 - 14s - loss: 2.7032e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 207ms/step\n",
      "Epoch 93/100\n",
      "69/69 - 14s - loss: 0.0033 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 207ms/step\n",
      "Epoch 94/100\n",
      "69/69 - 14s - loss: 8.4775e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.8832 - val_auc: 0.9681 - 14s/epoch - 207ms/step\n",
      "Epoch 95/100\n",
      "69/69 - 14s - loss: 2.7431e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.9574e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 207ms/step\n",
      "Epoch 96/100\n",
      "69/69 - 14s - loss: 3.6291e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.1732e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 97/100\n",
      "69/69 - 14s - loss: 5.2402e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.3317e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 98/100\n",
      "69/69 - 14s - loss: 2.5783e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.2508e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "Epoch 99/100\n",
      "69/69 - 14s - loss: 5.5230e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.1551e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 209ms/step\n",
      "Epoch 100/100\n",
      "69/69 - 14s - loss: 5.9021e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 7.4462e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 208ms/step\n",
      "5/5 [==============================] - 3s 150ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n",
      "Roc 1.0\n",
      "[[41  0]\n",
      " [ 0 96]]\n",
      "FF shape (513, 128)\n",
      "Trainable mel spectrogram is True\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Generated (RN-att2)-concat-pc\n",
      "FF shape (1025, 150)\n",
      "Trainable mel spectrogram is False\n",
      "DenseNet201\n",
      "Epoch 1/100\n",
      "69/69 - 79s - loss: 0.4799 - accuracy: 0.8076 - auc: 0.8895 - val_loss: 5555.7852 - val_accuracy: 0.2993 - val_auc: 0.2993 - 79s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "69/69 - 11s - loss: 0.2611 - accuracy: 0.8929 - auc: 0.9601 - val_loss: 187.6242 - val_accuracy: 0.3650 - val_auc: 0.3698 - 11s/epoch - 165ms/step\n",
      "Epoch 3/100\n",
      "69/69 - 12s - loss: 0.2254 - accuracy: 0.9129 - auc: 0.9697 - val_loss: 9.3793 - val_accuracy: 0.5182 - val_auc: 0.4527 - 12s/epoch - 170ms/step\n",
      "Epoch 4/100\n",
      "69/69 - 13s - loss: 0.1814 - accuracy: 0.9528 - auc: 0.9827 - val_loss: 4.0961 - val_accuracy: 0.7007 - val_auc: 0.7007 - 13s/epoch - 181ms/step\n",
      "Epoch 5/100\n",
      "69/69 - 13s - loss: 0.2177 - accuracy: 0.9183 - auc: 0.9713 - val_loss: 0.5693 - val_accuracy: 0.8175 - val_auc: 0.8889 - 13s/epoch - 184ms/step\n",
      "Epoch 6/100\n",
      "69/69 - 13s - loss: 0.1576 - accuracy: 0.9528 - auc: 0.9822 - val_loss: 20.2724 - val_accuracy: 0.4599 - val_auc: 0.4428 - 13s/epoch - 184ms/step\n",
      "Epoch 7/100\n",
      "69/69 - 13s - loss: 0.2175 - accuracy: 0.9129 - auc: 0.9718 - val_loss: 0.3370 - val_accuracy: 0.8978 - val_auc: 0.9472 - 13s/epoch - 191ms/step\n",
      "Epoch 8/100\n",
      "69/69 - 13s - loss: 0.1564 - accuracy: 0.9365 - auc: 0.9860 - val_loss: 0.8340 - val_accuracy: 0.7737 - val_auc: 0.8581 - 13s/epoch - 185ms/step\n",
      "Epoch 9/100\n",
      "69/69 - 13s - loss: 0.0994 - accuracy: 0.9691 - auc: 0.9917 - val_loss: 0.5305 - val_accuracy: 0.8394 - val_auc: 0.8850 - 13s/epoch - 185ms/step\n",
      "Epoch 10/100\n",
      "69/69 - 13s - loss: 0.0651 - accuracy: 0.9837 - auc: 0.9959 - val_loss: 0.1584 - val_accuracy: 0.9562 - val_auc: 0.9832 - 13s/epoch - 191ms/step\n",
      "Epoch 11/100\n",
      "69/69 - 13s - loss: 0.1163 - accuracy: 0.9601 - auc: 0.9912 - val_loss: 34.4034 - val_accuracy: 0.4453 - val_auc: 0.4165 - 13s/epoch - 185ms/step\n",
      "Epoch 12/100\n",
      "69/69 - 13s - loss: 0.1967 - accuracy: 0.9347 - auc: 0.9740 - val_loss: 0.8042 - val_accuracy: 0.7810 - val_auc: 0.8260 - 13s/epoch - 185ms/step\n",
      "Epoch 13/100\n",
      "69/69 - 13s - loss: 0.1142 - accuracy: 0.9546 - auc: 0.9922 - val_loss: 0.8329 - val_accuracy: 0.7372 - val_auc: 0.9043 - 13s/epoch - 192ms/step\n",
      "Epoch 14/100\n",
      "69/69 - 14s - loss: 0.0803 - accuracy: 0.9819 - auc: 0.9954 - val_loss: 1.1171 - val_accuracy: 0.7956 - val_auc: 0.8564 - 14s/epoch - 201ms/step\n",
      "Epoch 15/100\n",
      "69/69 - 14s - loss: 0.0503 - accuracy: 0.9819 - auc: 0.9985 - val_loss: 0.1181 - val_accuracy: 0.9854 - val_auc: 0.9909 - 14s/epoch - 206ms/step\n",
      "Epoch 16/100\n",
      "69/69 - 14s - loss: 0.1312 - accuracy: 0.9528 - auc: 0.9909 - val_loss: 1.1548 - val_accuracy: 0.7518 - val_auc: 0.8322 - 14s/epoch - 203ms/step\n",
      "Epoch 17/100\n",
      "69/69 - 14s - loss: 0.0937 - accuracy: 0.9673 - auc: 0.9930 - val_loss: 3.8784 - val_accuracy: 0.7007 - val_auc: 0.7116 - 14s/epoch - 199ms/step\n",
      "Epoch 18/100\n",
      "69/69 - 13s - loss: 0.0697 - accuracy: 0.9782 - auc: 0.9963 - val_loss: 1.1843 - val_accuracy: 0.7445 - val_auc: 0.8455 - 13s/epoch - 195ms/step\n",
      "Epoch 19/100\n",
      "69/69 - 14s - loss: 0.0688 - accuracy: 0.9764 - auc: 0.9965 - val_loss: 0.3788 - val_accuracy: 0.9051 - val_auc: 0.9472 - 14s/epoch - 197ms/step\n",
      "Epoch 20/100\n",
      "69/69 - 14s - loss: 0.0352 - accuracy: 0.9873 - auc: 0.9993 - val_loss: 0.1188 - val_accuracy: 0.9416 - val_auc: 0.9918 - 14s/epoch - 207ms/step\n",
      "Epoch 21/100\n",
      "69/69 - 14s - loss: 0.0530 - accuracy: 0.9837 - auc: 0.9966 - val_loss: 0.0999 - val_accuracy: 0.9781 - val_auc: 0.9936 - 14s/epoch - 207ms/step\n",
      "Epoch 22/100\n",
      "69/69 - 14s - loss: 0.0336 - accuracy: 0.9946 - auc: 0.9987 - val_loss: 0.1336 - val_accuracy: 0.9489 - val_auc: 0.9870 - 14s/epoch - 199ms/step\n",
      "Epoch 23/100\n",
      "69/69 - 14s - loss: 0.0869 - accuracy: 0.9746 - auc: 0.9926 - val_loss: 0.2551 - val_accuracy: 0.9051 - val_auc: 0.9628 - 14s/epoch - 210ms/step\n",
      "Epoch 24/100\n",
      "69/69 - 14s - loss: 0.0424 - accuracy: 0.9819 - auc: 0.9990 - val_loss: 0.1287 - val_accuracy: 0.9562 - val_auc: 0.9889 - 14s/epoch - 208ms/step\n",
      "Epoch 25/100\n",
      "69/69 - 15s - loss: 0.0329 - accuracy: 0.9909 - auc: 0.9994 - val_loss: 0.0520 - val_accuracy: 0.9854 - val_auc: 0.9981 - 15s/epoch - 216ms/step\n",
      "Epoch 26/100\n",
      "69/69 - 14s - loss: 0.0221 - accuracy: 0.9946 - auc: 0.9995 - val_loss: 1.2282 - val_accuracy: 0.6642 - val_auc: 0.7438 - 14s/epoch - 199ms/step\n",
      "Epoch 27/100\n",
      "69/69 - 15s - loss: 0.0223 - accuracy: 0.9946 - auc: 0.9996 - val_loss: 0.0127 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 28/100\n",
      "69/69 - 14s - loss: 0.0127 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.1187 - val_accuracy: 0.9708 - val_auc: 0.9935 - 14s/epoch - 203ms/step\n",
      "Epoch 29/100\n",
      "69/69 - 15s - loss: 0.0164 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.1193 - val_accuracy: 0.9562 - val_auc: 0.9933 - 15s/epoch - 219ms/step\n",
      "Epoch 30/100\n",
      "69/69 - 14s - loss: 0.0184 - accuracy: 0.9946 - auc: 0.9998 - val_loss: 3.1937 - val_accuracy: 0.7080 - val_auc: 0.7472 - 14s/epoch - 205ms/step\n",
      "Epoch 31/100\n",
      "69/69 - 14s - loss: 0.1332 - accuracy: 0.9492 - auc: 0.9874 - val_loss: 0.2870 - val_accuracy: 0.9708 - val_auc: 0.9771 - 14s/epoch - 200ms/step\n",
      "Epoch 32/100\n",
      "69/69 - 14s - loss: 0.0763 - accuracy: 0.9764 - auc: 0.9962 - val_loss: 7.5824 - val_accuracy: 0.7445 - val_auc: 0.7530 - 14s/epoch - 204ms/step\n",
      "Epoch 33/100\n",
      "69/69 - 15s - loss: 0.1454 - accuracy: 0.9456 - auc: 0.9861 - val_loss: 0.6554 - val_accuracy: 0.8540 - val_auc: 0.9171 - 15s/epoch - 215ms/step\n",
      "Epoch 34/100\n",
      "69/69 - 14s - loss: 0.1127 - accuracy: 0.9619 - auc: 0.9924 - val_loss: 0.0827 - val_accuracy: 0.9781 - val_auc: 0.9969 - 14s/epoch - 205ms/step\n",
      "Epoch 35/100\n",
      "69/69 - 15s - loss: 0.0615 - accuracy: 0.9819 - auc: 0.9977 - val_loss: 0.0381 - val_accuracy: 0.9927 - val_auc: 0.9980 - 15s/epoch - 213ms/step\n",
      "Epoch 36/100\n",
      "69/69 - 16s - loss: 0.0359 - accuracy: 0.9909 - auc: 0.9988 - val_loss: 0.0144 - val_accuracy: 1.0000 - val_auc: 1.0000 - 16s/epoch - 226ms/step\n",
      "Epoch 37/100\n",
      "69/69 - 14s - loss: 0.0417 - accuracy: 0.9891 - auc: 0.9974 - val_loss: 5.6910 - val_accuracy: 0.7007 - val_auc: 0.7007 - 14s/epoch - 200ms/step\n",
      "Epoch 38/100\n",
      "69/69 - 14s - loss: 0.0618 - accuracy: 0.9764 - auc: 0.9976 - val_loss: 0.3963 - val_accuracy: 0.9197 - val_auc: 0.9422 - 14s/epoch - 208ms/step\n",
      "Epoch 39/100\n",
      "69/69 - 14s - loss: 0.0677 - accuracy: 0.9837 - auc: 0.9955 - val_loss: 0.1833 - val_accuracy: 0.9270 - val_auc: 0.9776 - 14s/epoch - 208ms/step\n",
      "Epoch 40/100\n",
      "69/69 - 14s - loss: 0.0243 - accuracy: 0.9946 - auc: 0.9996 - val_loss: 0.0287 - val_accuracy: 0.9927 - val_auc: 0.9997 - 14s/epoch - 208ms/step\n",
      "Epoch 41/100\n",
      "69/69 - 14s - loss: 0.0078 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9927 - val_auc: 0.9997 - 14s/epoch - 209ms/step\n",
      "Epoch 42/100\n",
      "69/69 - 14s - loss: 0.0044 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9927 - val_auc: 0.9999 - 14s/epoch - 210ms/step\n",
      "Epoch 43/100\n",
      "69/69 - 15s - loss: 0.0163 - accuracy: 0.9964 - auc: 0.9997 - val_loss: 0.3634 - val_accuracy: 0.8467 - val_auc: 0.9426 - 15s/epoch - 216ms/step\n",
      "Epoch 44/100\n",
      "69/69 - 16s - loss: 0.0371 - accuracy: 0.9873 - auc: 0.9989 - val_loss: 3.4164 - val_accuracy: 0.5839 - val_auc: 0.6248 - 16s/epoch - 228ms/step\n",
      "Epoch 45/100\n",
      "69/69 - 16s - loss: 0.0361 - accuracy: 0.9909 - auc: 0.9989 - val_loss: 0.0460 - val_accuracy: 0.9927 - val_auc: 0.9921 - 16s/epoch - 228ms/step\n",
      "Epoch 46/100\n",
      "69/69 - 16s - loss: 0.0159 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.0148 - val_accuracy: 0.9927 - val_auc: 0.9999 - 16s/epoch - 227ms/step\n",
      "Epoch 47/100\n",
      "69/69 - 16s - loss: 0.0049 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9927 - val_auc: 0.9999 - 16s/epoch - 227ms/step\n",
      "Epoch 48/100\n",
      "69/69 - 16s - loss: 0.0213 - accuracy: 0.9946 - auc: 0.9997 - val_loss: 0.0421 - val_accuracy: 0.9854 - val_auc: 0.9987 - 16s/epoch - 227ms/step\n",
      "Epoch 49/100\n",
      "69/69 - 16s - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0387 - val_accuracy: 0.9854 - val_auc: 0.9993 - 16s/epoch - 227ms/step\n",
      "Epoch 50/100\n",
      "69/69 - 16s - loss: 0.0121 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.1600 - val_accuracy: 0.9124 - val_auc: 0.9867 - 16s/epoch - 226ms/step\n",
      "Epoch 51/100\n",
      "69/69 - 15s - loss: 0.0146 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.0089 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 224ms/step\n",
      "Epoch 52/100\n",
      "69/69 - 16s - loss: 0.0182 - accuracy: 0.9982 - auc: 0.9980 - val_loss: 0.0595 - val_accuracy: 0.9927 - val_auc: 0.9915 - 16s/epoch - 225ms/step\n",
      "Epoch 53/100\n",
      "69/69 - 16s - loss: 0.0088 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.6163 - val_accuracy: 0.7591 - val_auc: 0.9241 - 16s/epoch - 225ms/step\n",
      "Epoch 54/100\n",
      "69/69 - 15s - loss: 0.0157 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.9000 - val_accuracy: 0.8175 - val_auc: 0.8917 - 15s/epoch - 224ms/step\n",
      "Epoch 55/100\n",
      "69/69 - 14s - loss: 0.0174 - accuracy: 0.9927 - auc: 0.9998 - val_loss: 0.0686 - val_accuracy: 0.9854 - val_auc: 0.9971 - 14s/epoch - 200ms/step\n",
      "Epoch 56/100\n",
      "69/69 - 14s - loss: 0.0298 - accuracy: 0.9927 - auc: 0.9979 - val_loss: 0.1579 - val_accuracy: 0.9343 - val_auc: 0.9877 - 14s/epoch - 204ms/step\n",
      "Epoch 57/100\n",
      "69/69 - 15s - loss: 0.0237 - accuracy: 0.9927 - auc: 0.9997 - val_loss: 0.1013 - val_accuracy: 0.9927 - val_auc: 0.9914 - 15s/epoch - 220ms/step\n",
      "Epoch 58/100\n",
      "69/69 - 15s - loss: 0.0142 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.7867 - val_accuracy: 0.7883 - val_auc: 0.8950 - 15s/epoch - 219ms/step\n",
      "Epoch 59/100\n",
      "69/69 - 14s - loss: 0.0085 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 3.5683e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 206ms/step\n",
      "Epoch 60/100\n",
      "69/69 - 15s - loss: 0.0065 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9854 - val_auc: 0.9995 - 15s/epoch - 214ms/step\n",
      "Epoch 61/100\n",
      "69/69 - 15s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9854 - val_auc: 0.9995 - 15s/epoch - 217ms/step\n",
      "Epoch 62/100\n",
      "69/69 - 15s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9927 - val_auc: 0.9997 - 15s/epoch - 216ms/step\n",
      "Epoch 63/100\n",
      "69/69 - 15s - loss: 7.9166e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9927 - val_auc: 0.9997 - 15s/epoch - 216ms/step\n",
      "Epoch 64/100\n",
      "69/69 - 15s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 211ms/step\n",
      "Epoch 65/100\n",
      "69/69 - 15s - loss: 0.0076 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9927 - val_auc: 0.9999 - 15s/epoch - 214ms/step\n",
      "Epoch 66/100\n",
      "69/69 - 15s - loss: 0.0371 - accuracy: 0.9891 - auc: 0.9979 - val_loss: 1.5231 - val_accuracy: 0.7153 - val_auc: 0.7552 - 15s/epoch - 213ms/step\n",
      "Epoch 67/100\n",
      "69/69 - 15s - loss: 0.0128 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.2725 - val_accuracy: 0.9635 - val_auc: 0.9914 - 15s/epoch - 213ms/step\n",
      "Epoch 68/100\n",
      "69/69 - 15s - loss: 0.0692 - accuracy: 0.9837 - auc: 0.9965 - val_loss: 0.1211 - val_accuracy: 0.9781 - val_auc: 0.9922 - 15s/epoch - 213ms/step\n",
      "Epoch 69/100\n",
      "69/69 - 15s - loss: 0.0165 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.1448 - val_accuracy: 0.9708 - val_auc: 0.9869 - 15s/epoch - 219ms/step\n",
      "Epoch 70/100\n",
      "69/69 - 14s - loss: 0.0784 - accuracy: 0.9746 - auc: 0.9953 - val_loss: 1.7361 - val_accuracy: 0.7080 - val_auc: 0.7248 - 14s/epoch - 207ms/step\n",
      "Epoch 71/100\n",
      "69/69 - 15s - loss: 0.0366 - accuracy: 0.9855 - auc: 0.9992 - val_loss: 0.7471 - val_accuracy: 0.8613 - val_auc: 0.9089 - 15s/epoch - 210ms/step\n",
      "Epoch 72/100\n",
      "69/69 - 14s - loss: 0.2095 - accuracy: 0.9510 - auc: 0.9797 - val_loss: 15.3282 - val_accuracy: 0.4161 - val_auc: 0.4170 - 14s/epoch - 204ms/step\n",
      "Epoch 73/100\n",
      "69/69 - 15s - loss: 0.1025 - accuracy: 0.9583 - auc: 0.9940 - val_loss: 0.3775 - val_accuracy: 0.9416 - val_auc: 0.9810 - 15s/epoch - 215ms/step\n",
      "Epoch 74/100\n",
      "69/69 - 15s - loss: 0.0235 - accuracy: 0.9909 - auc: 0.9996 - val_loss: 0.7957 - val_accuracy: 0.8759 - val_auc: 0.8973 - 15s/epoch - 215ms/step\n",
      "Epoch 75/100\n",
      "69/69 - 15s - loss: 0.0152 - accuracy: 0.9964 - auc: 0.9998 - val_loss: 0.0172 - val_accuracy: 0.9927 - val_auc: 0.9998 - 15s/epoch - 214ms/step\n",
      "Epoch 76/100\n",
      "69/69 - 15s - loss: 0.0253 - accuracy: 0.9873 - auc: 0.9997 - val_loss: 0.0253 - val_accuracy: 0.9854 - val_auc: 0.9998 - 15s/epoch - 213ms/step\n",
      "Epoch 77/100\n",
      "69/69 - 15s - loss: 0.0196 - accuracy: 0.9964 - auc: 0.9996 - val_loss: 0.0059 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 214ms/step\n",
      "Epoch 78/100\n",
      "69/69 - 15s - loss: 0.0138 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0037 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 214ms/step\n",
      "Epoch 79/100\n",
      "69/69 - 14s - loss: 0.0038 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 201ms/step\n",
      "Epoch 80/100\n",
      "69/69 - 14s - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 203ms/step\n",
      "Epoch 81/100\n",
      "69/69 - 15s - loss: 0.0024 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 213ms/step\n",
      "Epoch 82/100\n",
      "69/69 - 15s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9854 - val_auc: 0.9998 - 15s/epoch - 213ms/step\n",
      "Epoch 83/100\n",
      "69/69 - 15s - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9854 - val_auc: 0.9998 - 15s/epoch - 213ms/step\n",
      "Epoch 84/100\n",
      "69/69 - 15s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 213ms/step\n",
      "Epoch 85/100\n",
      "69/69 - 15s - loss: 5.3577e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 214ms/step\n",
      "Epoch 86/100\n",
      "69/69 - 15s - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 215ms/step\n",
      "Epoch 87/100\n",
      "69/69 - 15s - loss: 0.0041 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9927 - val_auc: 0.9993 - 15s/epoch - 215ms/step\n",
      "Epoch 88/100\n",
      "69/69 - 15s - loss: 0.0104 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 2.1179 - val_accuracy: 0.7080 - val_auc: 0.7724 - 15s/epoch - 214ms/step\n",
      "Epoch 89/100\n",
      "69/69 - 15s - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1445 - val_accuracy: 0.7372 - val_auc: 0.7722 - 15s/epoch - 215ms/step\n",
      "Epoch 90/100\n",
      "69/69 - 15s - loss: 0.0069 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 1.9677 - val_accuracy: 0.7591 - val_auc: 0.7917 - 15s/epoch - 215ms/step\n",
      "Epoch 91/100\n",
      "69/69 - 15s - loss: 0.0246 - accuracy: 0.9927 - auc: 0.9996 - val_loss: 0.4129 - val_accuracy: 0.9489 - val_auc: 0.9728 - 15s/epoch - 215ms/step\n",
      "Epoch 92/100\n",
      "69/69 - 15s - loss: 0.1010 - accuracy: 0.9728 - auc: 0.9927 - val_loss: 15.2365 - val_accuracy: 0.6423 - val_auc: 0.6486 - 15s/epoch - 214ms/step\n",
      "Epoch 93/100\n",
      "69/69 - 15s - loss: 0.0173 - accuracy: 0.9909 - auc: 0.9999 - val_loss: 0.2646 - val_accuracy: 0.9416 - val_auc: 0.9769 - 15s/epoch - 213ms/step\n",
      "Epoch 94/100\n",
      "69/69 - 15s - loss: 0.0151 - accuracy: 0.9982 - auc: 0.9981 - val_loss: 0.0171 - val_accuracy: 0.9854 - val_auc: 0.9998 - 15s/epoch - 214ms/step\n",
      "Epoch 95/100\n",
      "69/69 - 15s - loss: 0.0032 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9708 - val_auc: 0.9967 - 15s/epoch - 214ms/step\n",
      "Epoch 96/100\n",
      "69/69 - 15s - loss: 0.0050 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9927 - val_auc: 0.9916 - 15s/epoch - 213ms/step\n",
      "Epoch 97/100\n",
      "69/69 - 15s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9927 - val_auc: 0.9998 - 15s/epoch - 213ms/step\n",
      "Epoch 98/100\n",
      "69/69 - 15s - loss: 0.0028 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9927 - val_auc: 0.9997 - 15s/epoch - 213ms/step\n",
      "Epoch 99/100\n",
      "69/69 - 15s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000 - val_auc: 1.0000 - 15s/epoch - 213ms/step\n",
      "Epoch 100/100\n",
      "69/69 - 15s - loss: 0.0052 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.1575 - val_accuracy: 0.9562 - val_auc: 0.9854 - 15s/epoch - 213ms/step\n",
      "5/5 [==============================] - 3s 149ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n",
      "Roc 1.0\n",
      "[[41  0]\n",
      " [ 0 96]]\n",
      "FF shape (513, 128)\n",
      "Trainable mel spectrogram is True\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Generated (RN-att2)-concat-pc\n",
      "FF shape (1025, 150)\n",
      "Trainable mel spectrogram is False\n",
      "DenseNet201\n",
      "Epoch 1/100\n",
      "69/69 - 80s - loss: 0.5207 - accuracy: 0.7967 - auc: 0.8794 - val_loss: 2519.7715 - val_accuracy: 0.2993 - val_auc: 0.2993 - 80s/epoch - 1s/step\n",
      "Epoch 2/100\n",
      "69/69 - 11s - loss: 0.2685 - accuracy: 0.9020 - auc: 0.9601 - val_loss: 20.5588 - val_accuracy: 0.3285 - val_auc: 0.3429 - 11s/epoch - 165ms/step\n",
      "Epoch 3/100\n",
      "69/69 - 11s - loss: 0.1917 - accuracy: 0.9274 - auc: 0.9776 - val_loss: 411.7092 - val_accuracy: 0.2993 - val_auc: 0.2993 - 11s/epoch - 162ms/step\n",
      "Epoch 4/100\n",
      "69/69 - 12s - loss: 0.2031 - accuracy: 0.9310 - auc: 0.9744 - val_loss: 5.7645 - val_accuracy: 0.5109 - val_auc: 0.5238 - 12s/epoch - 177ms/step\n",
      "Epoch 5/100\n",
      "69/69 - 13s - loss: 0.2681 - accuracy: 0.9111 - auc: 0.9589 - val_loss: 26.6922 - val_accuracy: 0.5036 - val_auc: 0.4892 - 13s/epoch - 182ms/step\n",
      "Epoch 6/100\n",
      "69/69 - 13s - loss: 0.1662 - accuracy: 0.9437 - auc: 0.9826 - val_loss: 13.1713 - val_accuracy: 0.5474 - val_auc: 0.5427 - 13s/epoch - 191ms/step\n",
      "Epoch 7/100\n",
      "69/69 - 13s - loss: 0.1184 - accuracy: 0.9456 - auc: 0.9919 - val_loss: 1.1489 - val_accuracy: 0.6861 - val_auc: 0.8000 - 13s/epoch - 191ms/step\n",
      "Epoch 8/100\n",
      "69/69 - 13s - loss: 0.0990 - accuracy: 0.9655 - auc: 0.9929 - val_loss: 0.1411 - val_accuracy: 0.9854 - val_auc: 0.9828 - 13s/epoch - 190ms/step\n",
      "Epoch 9/100\n",
      "69/69 - 13s - loss: 0.0640 - accuracy: 0.9782 - auc: 0.9977 - val_loss: 0.1460 - val_accuracy: 0.9562 - val_auc: 0.9856 - 13s/epoch - 191ms/step\n",
      "Epoch 10/100\n",
      "69/69 - 13s - loss: 0.0766 - accuracy: 0.9710 - auc: 0.9935 - val_loss: 0.1011 - val_accuracy: 0.9854 - val_auc: 0.9901 - 13s/epoch - 191ms/step\n",
      "Epoch 11/100\n",
      "69/69 - 13s - loss: 0.0873 - accuracy: 0.9855 - auc: 0.9946 - val_loss: 0.1222 - val_accuracy: 0.9489 - val_auc: 0.9909 - 13s/epoch - 191ms/step\n",
      "Epoch 12/100\n",
      "69/69 - 13s - loss: 0.0755 - accuracy: 0.9673 - auc: 0.9967 - val_loss: 0.6183 - val_accuracy: 0.7518 - val_auc: 0.8811 - 13s/epoch - 184ms/step\n",
      "Epoch 13/100\n",
      "69/69 - 13s - loss: 0.0939 - accuracy: 0.9673 - auc: 0.9935 - val_loss: 0.2261 - val_accuracy: 0.8832 - val_auc: 0.9797 - 13s/epoch - 185ms/step\n",
      "Epoch 14/100\n",
      "69/69 - 13s - loss: 0.0820 - accuracy: 0.9710 - auc: 0.9956 - val_loss: 0.0479 - val_accuracy: 0.9781 - val_auc: 0.9987 - 13s/epoch - 192ms/step\n",
      "Epoch 15/100\n",
      "69/69 - 13s - loss: 0.0701 - accuracy: 0.9746 - auc: 0.9955 - val_loss: 3.2825 - val_accuracy: 0.6934 - val_auc: 0.7101 - 13s/epoch - 185ms/step\n",
      "Epoch 16/100\n",
      "69/69 - 13s - loss: 0.0886 - accuracy: 0.9691 - auc: 0.9946 - val_loss: 21.2019 - val_accuracy: 0.4526 - val_auc: 0.4371 - 13s/epoch - 185ms/step\n",
      "Epoch 17/100\n",
      "69/69 - 13s - loss: 0.0656 - accuracy: 0.9710 - auc: 0.9974 - val_loss: 1.1717 - val_accuracy: 0.6788 - val_auc: 0.7563 - 13s/epoch - 185ms/step\n",
      "Epoch 18/100\n",
      "69/69 - 14s - loss: 0.0337 - accuracy: 0.9873 - auc: 0.9995 - val_loss: 0.0270 - val_accuracy: 0.9927 - val_auc: 0.9996 - 14s/epoch - 206ms/step\n",
      "Epoch 19/100\n",
      "69/69 - 13s - loss: 0.0441 - accuracy: 0.9873 - auc: 0.9973 - val_loss: 0.3789 - val_accuracy: 0.8029 - val_auc: 0.9198 - 13s/epoch - 191ms/step\n",
      "Epoch 20/100\n",
      "69/69 - 14s - loss: 0.0408 - accuracy: 0.9855 - auc: 0.9974 - val_loss: 30.5703 - val_accuracy: 0.4453 - val_auc: 0.4322 - 14s/epoch - 196ms/step\n",
      "Epoch 21/100\n",
      "69/69 - 14s - loss: 0.0361 - accuracy: 0.9873 - auc: 0.9992 - val_loss: 0.0623 - val_accuracy: 0.9781 - val_auc: 0.9978 - 14s/epoch - 196ms/step\n",
      "Epoch 22/100\n",
      "69/69 - 14s - loss: 0.0374 - accuracy: 0.9855 - auc: 0.9993 - val_loss: 0.0633 - val_accuracy: 0.9854 - val_auc: 0.9965 - 14s/epoch - 197ms/step\n",
      "Epoch 23/100\n",
      "69/69 - 14s - loss: 0.0478 - accuracy: 0.9837 - auc: 0.9972 - val_loss: 0.1664 - val_accuracy: 0.9416 - val_auc: 0.9824 - 14s/epoch - 197ms/step\n",
      "Epoch 24/100\n",
      "69/69 - 13s - loss: 0.1581 - accuracy: 0.9583 - auc: 0.9800 - val_loss: 0.8719 - val_accuracy: 0.8467 - val_auc: 0.9010 - 13s/epoch - 191ms/step\n",
      "Epoch 25/100\n",
      "69/69 - 14s - loss: 0.0629 - accuracy: 0.9782 - auc: 0.9960 - val_loss: 0.0122 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 202ms/step\n",
      "Epoch 26/100\n",
      "69/69 - 14s - loss: 0.0280 - accuracy: 0.9964 - auc: 0.9977 - val_loss: 0.0046 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 203ms/step\n",
      "Epoch 27/100\n",
      "69/69 - 13s - loss: 0.0156 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.1022 - val_accuracy: 0.9781 - val_auc: 0.9883 - 13s/epoch - 189ms/step\n",
      "Epoch 28/100\n",
      "69/69 - 14s - loss: 0.0311 - accuracy: 0.9837 - auc: 0.9995 - val_loss: 0.0614 - val_accuracy: 0.9854 - val_auc: 0.9960 - 14s/epoch - 197ms/step\n",
      "Epoch 29/100\n",
      "69/69 - 14s - loss: 0.0130 - accuracy: 0.9982 - auc: 0.9998 - val_loss: 0.0064 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 199ms/step\n",
      "Epoch 30/100\n",
      "69/69 - 14s - loss: 0.0047 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 205ms/step\n",
      "Epoch 31/100\n",
      "69/69 - 13s - loss: 0.0230 - accuracy: 0.9909 - auc: 0.9997 - val_loss: 0.9690 - val_accuracy: 0.7372 - val_auc: 0.8517 - 13s/epoch - 192ms/step\n",
      "Epoch 32/100\n",
      "69/69 - 14s - loss: 0.0094 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.8978 - val_auc: 0.9811 - 14s/epoch - 197ms/step\n",
      "Epoch 33/100\n",
      "69/69 - 14s - loss: 0.0326 - accuracy: 0.9909 - auc: 0.9977 - val_loss: 1.5363 - val_accuracy: 0.6496 - val_auc: 0.7271 - 14s/epoch - 198ms/step\n",
      "Epoch 34/100\n",
      "69/69 - 14s - loss: 0.1462 - accuracy: 0.9528 - auc: 0.9871 - val_loss: 5.5298 - val_accuracy: 0.5766 - val_auc: 0.5839 - 14s/epoch - 197ms/step\n",
      "Epoch 35/100\n",
      "69/69 - 14s - loss: 0.0717 - accuracy: 0.9764 - auc: 0.9956 - val_loss: 0.0294 - val_accuracy: 0.9854 - val_auc: 0.9998 - 14s/epoch - 197ms/step\n",
      "Epoch 36/100\n",
      "69/69 - 14s - loss: 0.0300 - accuracy: 0.9873 - auc: 0.9994 - val_loss: 0.6165 - val_accuracy: 0.7372 - val_auc: 0.8852 - 14s/epoch - 197ms/step\n",
      "Epoch 37/100\n",
      "69/69 - 14s - loss: 0.0380 - accuracy: 0.9891 - auc: 0.9976 - val_loss: 0.3212 - val_accuracy: 0.8832 - val_auc: 0.9626 - 14s/epoch - 196ms/step\n",
      "Epoch 38/100\n",
      "69/69 - 14s - loss: 0.0515 - accuracy: 0.9837 - auc: 0.9968 - val_loss: 2.4444 - val_accuracy: 0.7591 - val_auc: 0.7786 - 14s/epoch - 197ms/step\n",
      "Epoch 39/100\n",
      "69/69 - 14s - loss: 0.0886 - accuracy: 0.9691 - auc: 0.9936 - val_loss: 6.0736 - val_accuracy: 0.5036 - val_auc: 0.4747 - 14s/epoch - 196ms/step\n",
      "Epoch 40/100\n",
      "69/69 - 14s - loss: 0.0320 - accuracy: 0.9873 - auc: 0.9995 - val_loss: 0.2386 - val_accuracy: 0.8905 - val_auc: 0.9703 - 14s/epoch - 196ms/step\n",
      "Epoch 41/100\n",
      "69/69 - 14s - loss: 0.0141 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 1.5002 - val_accuracy: 0.5693 - val_auc: 0.7401 - 14s/epoch - 196ms/step\n",
      "Epoch 42/100\n",
      "69/69 - 14s - loss: 0.0307 - accuracy: 0.9927 - auc: 0.9978 - val_loss: 0.8732 - val_accuracy: 0.8540 - val_auc: 0.9064 - 14s/epoch - 196ms/step\n",
      "Epoch 43/100\n",
      "69/69 - 14s - loss: 0.0376 - accuracy: 0.9891 - auc: 0.9990 - val_loss: 0.2804 - val_accuracy: 0.8540 - val_auc: 0.9663 - 14s/epoch - 196ms/step\n",
      "Epoch 44/100\n",
      "69/69 - 14s - loss: 0.0227 - accuracy: 0.9891 - auc: 0.9997 - val_loss: 1.4358 - val_accuracy: 0.7445 - val_auc: 0.7705 - 14s/epoch - 196ms/step\n",
      "Epoch 45/100\n",
      "69/69 - 14s - loss: 0.0588 - accuracy: 0.9710 - auc: 0.9981 - val_loss: 0.6275 - val_accuracy: 0.8540 - val_auc: 0.9246 - 14s/epoch - 197ms/step\n",
      "Epoch 46/100\n",
      "69/69 - 14s - loss: 0.0159 - accuracy: 0.9946 - auc: 0.9998 - val_loss: 0.8528 - val_accuracy: 0.7956 - val_auc: 0.9013 - 14s/epoch - 196ms/step\n",
      "Epoch 47/100\n",
      "69/69 - 14s - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9854 - val_auc: 0.9997 - 14s/epoch - 196ms/step\n",
      "Epoch 48/100\n",
      "69/69 - 14s - loss: 0.0154 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0733 - val_accuracy: 0.9635 - val_auc: 0.9966 - 14s/epoch - 196ms/step\n",
      "Epoch 49/100\n",
      "69/69 - 14s - loss: 0.0070 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 197ms/step\n",
      "Epoch 50/100\n",
      "69/69 - 14s - loss: 0.0190 - accuracy: 0.9909 - auc: 0.9998 - val_loss: 0.0040 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 197ms/step\n",
      "Epoch 51/100\n",
      "69/69 - 14s - loss: 0.0025 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.7420e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 197ms/step\n",
      "Epoch 52/100\n",
      "69/69 - 14s - loss: 6.9084e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 196ms/step\n",
      "Epoch 53/100\n",
      "69/69 - 14s - loss: 0.0026 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9124 - val_auc: 0.9768 - 14s/epoch - 197ms/step\n",
      "Epoch 54/100\n",
      "69/69 - 13s - loss: 0.0129 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 11.5059 - val_accuracy: 0.3504 - val_auc: 0.3698 - 13s/epoch - 192ms/step\n",
      "Epoch 55/100\n",
      "69/69 - 13s - loss: 0.0062 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 2.0905 - val_accuracy: 0.5766 - val_auc: 0.6320 - 13s/epoch - 192ms/step\n",
      "Epoch 56/100\n",
      "69/69 - 13s - loss: 0.0230 - accuracy: 0.9927 - auc: 0.9980 - val_loss: 0.0733 - val_accuracy: 0.9781 - val_auc: 0.9973 - 13s/epoch - 192ms/step\n",
      "Epoch 57/100\n",
      "69/69 - 13s - loss: 0.0245 - accuracy: 0.9891 - auc: 0.9996 - val_loss: 0.0889 - val_accuracy: 0.9781 - val_auc: 0.9917 - 13s/epoch - 192ms/step\n",
      "Epoch 58/100\n",
      "69/69 - 13s - loss: 0.0122 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 2.6480 - val_accuracy: 0.7007 - val_auc: 0.7110 - 13s/epoch - 192ms/step\n",
      "Epoch 59/100\n",
      "69/69 - 13s - loss: 0.0069 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 1.7548 - val_accuracy: 0.7007 - val_auc: 0.7775 - 13s/epoch - 196ms/step\n",
      "Epoch 60/100\n",
      "69/69 - 13s - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9927 - val_auc: 0.9999 - 13s/epoch - 192ms/step\n",
      "Epoch 61/100\n",
      "69/69 - 13s - loss: 0.0151 - accuracy: 0.9964 - auc: 0.9998 - val_loss: 0.0203 - val_accuracy: 0.9927 - val_auc: 0.9996 - 13s/epoch - 194ms/step\n",
      "Epoch 62/100\n",
      "69/69 - 14s - loss: 0.0078 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 201ms/step\n",
      "Epoch 63/100\n",
      "69/69 - 13s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.5002e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 191ms/step\n",
      "Epoch 64/100\n",
      "69/69 - 13s - loss: 0.0497 - accuracy: 0.9891 - auc: 0.9975 - val_loss: 0.6835 - val_accuracy: 0.7445 - val_auc: 0.8754 - 13s/epoch - 191ms/step\n",
      "Epoch 65/100\n",
      "69/69 - 14s - loss: 0.2067 - accuracy: 0.9365 - auc: 0.9830 - val_loss: 92.2589 - val_accuracy: 0.2993 - val_auc: 0.2993 - 14s/epoch - 196ms/step\n",
      "Epoch 66/100\n",
      "69/69 - 13s - loss: 0.0527 - accuracy: 0.9819 - auc: 0.9970 - val_loss: 24.4367 - val_accuracy: 0.5036 - val_auc: 0.4877 - 13s/epoch - 193ms/step\n",
      "Epoch 67/100\n",
      "69/69 - 14s - loss: 0.0085 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 1.3153 - val_accuracy: 0.7445 - val_auc: 0.7680 - 14s/epoch - 201ms/step\n",
      "Epoch 68/100\n",
      "69/69 - 14s - loss: 0.0200 - accuracy: 0.9927 - auc: 0.9998 - val_loss: 0.0447 - val_accuracy: 0.9927 - val_auc: 0.9979 - 14s/epoch - 205ms/step\n",
      "Epoch 69/100\n",
      "69/69 - 14s - loss: 0.0261 - accuracy: 0.9909 - auc: 0.9994 - val_loss: 0.2309 - val_accuracy: 0.9197 - val_auc: 0.9720 - 14s/epoch - 204ms/step\n",
      "Epoch 70/100\n",
      "69/69 - 13s - loss: 0.0661 - accuracy: 0.9800 - auc: 0.9943 - val_loss: 0.0098 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 185ms/step\n",
      "Epoch 71/100\n",
      "69/69 - 14s - loss: 0.0128 - accuracy: 0.9964 - auc: 0.9999 - val_loss: 0.0013 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 200ms/step\n",
      "Epoch 72/100\n",
      "69/69 - 13s - loss: 0.0064 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 194ms/step\n",
      "Epoch 73/100\n",
      "69/69 - 13s - loss: 0.0127 - accuracy: 0.9946 - auc: 0.9999 - val_loss: 0.0385 - val_accuracy: 0.9927 - val_auc: 0.9997 - 13s/epoch - 187ms/step\n",
      "Epoch 74/100\n",
      "69/69 - 13s - loss: 0.0058 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 191ms/step\n",
      "Epoch 75/100\n",
      "69/69 - 13s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 191ms/step\n",
      "Epoch 76/100\n",
      "69/69 - 13s - loss: 0.0011 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 9.8041e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 191ms/step\n",
      "Epoch 77/100\n",
      "69/69 - 13s - loss: 0.0069 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 191ms/step\n",
      "Epoch 78/100\n",
      "69/69 - 13s - loss: 0.0610 - accuracy: 0.9764 - auc: 0.9966 - val_loss: 2.6737 - val_accuracy: 0.6934 - val_auc: 0.7539 - 13s/epoch - 191ms/step\n",
      "Epoch 79/100\n",
      "69/69 - 13s - loss: 0.0665 - accuracy: 0.9782 - auc: 0.9980 - val_loss: 1.9152 - val_accuracy: 0.6204 - val_auc: 0.7288 - 13s/epoch - 191ms/step\n",
      "Epoch 80/100\n",
      "69/69 - 13s - loss: 0.1503 - accuracy: 0.9655 - auc: 0.9902 - val_loss: 3.6783 - val_accuracy: 0.7080 - val_auc: 0.6899 - 13s/epoch - 191ms/step\n",
      "Epoch 81/100\n",
      "69/69 - 13s - loss: 0.0342 - accuracy: 0.9909 - auc: 0.9976 - val_loss: 0.1632 - val_accuracy: 0.9562 - val_auc: 0.9851 - 13s/epoch - 190ms/step\n",
      "Epoch 82/100\n",
      "69/69 - 13s - loss: 0.0072 - accuracy: 0.9964 - auc: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 192ms/step\n",
      "Epoch 83/100\n",
      "69/69 - 13s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.0055e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 194ms/step\n",
      "Epoch 84/100\n",
      "69/69 - 13s - loss: 0.0027 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 8.8797e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 193ms/step\n",
      "Epoch 85/100\n",
      "69/69 - 13s - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.9126e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 193ms/step\n",
      "Epoch 86/100\n",
      "69/69 - 13s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.8825e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 193ms/step\n",
      "Epoch 87/100\n",
      "69/69 - 13s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 193ms/step\n",
      "Epoch 88/100\n",
      "69/69 - 13s - loss: 6.8755e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 4.6442e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 193ms/step\n",
      "Epoch 89/100\n",
      "69/69 - 13s - loss: 0.0311 - accuracy: 0.9855 - auc: 0.9994 - val_loss: 0.2045 - val_accuracy: 0.9270 - val_auc: 0.9814 - 13s/epoch - 194ms/step\n",
      "Epoch 90/100\n",
      "69/69 - 13s - loss: 0.0151 - accuracy: 0.9927 - auc: 0.9999 - val_loss: 0.0376 - val_accuracy: 0.9854 - val_auc: 0.9994 - 13s/epoch - 186ms/step\n",
      "Epoch 91/100\n",
      "69/69 - 14s - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000 - val_auc: 1.0000 - 14s/epoch - 196ms/step\n",
      "Epoch 92/100\n",
      "69/69 - 13s - loss: 2.1830e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 7.0119e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 189ms/step\n",
      "Epoch 93/100\n",
      "69/69 - 13s - loss: 5.5023e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.9370e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 189ms/step\n",
      "Epoch 94/100\n",
      "69/69 - 13s - loss: 2.6095e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2400e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 189ms/step\n",
      "Epoch 95/100\n",
      "69/69 - 13s - loss: 1.8591e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 3.7139e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 190ms/step\n",
      "Epoch 96/100\n",
      "69/69 - 13s - loss: 1.4669e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.7046e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 190ms/step\n",
      "Epoch 97/100\n",
      "69/69 - 13s - loss: 2.5447e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1288e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 190ms/step\n",
      "Epoch 98/100\n",
      "69/69 - 13s - loss: 1.8929e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.7656e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 190ms/step\n",
      "Epoch 99/100\n",
      "69/69 - 13s - loss: 1.0834e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 1.6865e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 190ms/step\n",
      "Epoch 100/100\n",
      "69/69 - 13s - loss: 3.1868e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 2.1847e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - 13s/epoch - 191ms/step\n",
      "5/5 [==============================] - 3s 143ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        41\n",
      "           1       1.00      1.00      1.00        96\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n",
      "Roc 1.0\n",
      "[[41  0]\n",
      " [ 0 96]]\n",
      "Metric AUCO\n",
      "aa::[]\n",
      "Mean accuracy nan\n",
      "Mean precision nan\n",
      "Mean recall nan\n",
      "Mean F1 nan\n",
      "None\n",
      "AUC\n",
      "nan\n",
      "Metric other\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 41.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 96.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 41.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 96.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 41.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 96.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 41.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 96.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 41.0}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 96.0}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 137.0}}\n",
      "Mean accuracy 1.0\n",
      "Mean precision 1.0\n",
      "Mean recall 1.0\n",
      "Mean F1 1.0\n",
      "None\n",
      "AUC\n",
      "1.0\n",
      "Mean accuracy nan\n",
      "Mean precision nan\n",
      "Mean recall nan\n",
      "Mean F1 nan\n",
      "None\n",
      "Mean accuracy nan\n",
      "Mean precision nan\n",
      "Mean recall nan\n",
      "Mean F1 nan\n",
      "None\n",
      "Mean accuracy nan\n",
      "Mean precision nan\n",
      "Mean recall nan\n",
      "Mean F1 nan\n",
      "None\n",
      "AUC\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "***********************************************\n",
      "ConfusionMatrix True HC\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "***********************************************\n",
      "ConfusionMatrix True PD\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "***********************************************\n",
      "ConfusionMatrix Falsi PD\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "***********************************************\n",
      "ConfusionMatrix Falsi HC\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/vincenzo/anaconda3/envs/tf/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\na = np.matrix([[true_hc_RFC, false_pd_RFC], [false_hc_RFC, true_pd_RFC]])\\nplot_confusion_matrix2(a, normalize=False, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanRandomForestClassifierConfusionMatrix_False\")\\nplot_confusion_matrix2(a, normalize=True, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanRandomForestClassifierConfusionMatrix_True\")\\n\\na = np.matrix([[true_hc_KNN, false_pd_KNN], [false_hc_KNN, true_pd_KNN]])\\nplot_confusion_matrix2(a, normalize=False, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanKNNConfusionMatrix_False\")\\nplot_confusion_matrix2(a, normalize=True, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanKNNConfusionMatrix_True\")\\n\\na = np.matrix([[true_hc_SVM, false_pd_SVM], [false_hc_SVM, true_pd_SVM]])\\nplot_confusion_matrix2(a, normalize=False, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanSVMConfusionMatrix_False\")\\nplot_confusion_matrix2(a, normalize=True, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanSVMConfusionMatrix_True\")\\n\\n\\n\\n\\ntrue_hc_Inception = np.mean([k[0][0] for k in confusion_matrix45])\\nfalse_pd_Inception = np.mean([k[0][1] for k in confusion_matrix45])\\nfalse_hc_Inception = np.mean([k[1][0] for k in confusion_matrix45])\\ntrue_pd_Inception = np.mean([k[1][1] for k in confusion_matrix45])\\n\\na = np.matrix([[true_hc_Inception, false_pd_Inception], [false_hc_Inception, true_pd_Inception]])\\n#plot_confusion_matrix2(a, normalize=False, target_names=[\\'HC\\', \\'PD\\'], title=\"MeaResNet50ConfusionMatrix_False\")\\n#plot_confusion_matrix2(a, normalize=True, target_names=[\\'HC\\', \\'PD\\'], title=\"MeanResNet50ConfusionMatrix_True\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "#from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "from sklearn import metrics\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "c_r_a = []\n",
    "r_a_a = []\n",
    "cmx_array = []\n",
    "\n",
    "def concilie_per_patient_res(predx, y_test, usercodes):\n",
    "    new_pred = []\n",
    "    new_y_test = []\n",
    "     \n",
    "    #print('Prediced shape')\n",
    "    #print(predx.shape)\n",
    "    \n",
    "    if y_test.shape[-1] < 2:\n",
    "      y_test = to_categorical(y_test)\n",
    "    patient = {}\n",
    "    for i in range(len(y_test)):\n",
    "      if not usercodes[i] in patient:\n",
    "        print(\"patient[usercodes[i]]\")\n",
    "        patient[usercodes[i]] = {}\n",
    "        patient[usercodes[i]]['predicted'] = []\n",
    "        patient[usercodes[i]]['y_test'] = []   \n",
    "        print(patient[usercodes[i]])            \n",
    "      patient[usercodes[i]]['predicted'].append(predx[i])\n",
    "      patient[usercodes[i]]['y_test'].append(y_test[i])\n",
    "      #print(patient[usercodes[i]]['predicted'])\n",
    "    keys = list(patient.keys())\n",
    "    for key in keys:\n",
    "       predi = patient[key]['predicted']\n",
    "       yi = patient[key]['y_test']\n",
    "       mean_pred = np.asarray(predi).mean(axis=0)\n",
    "       mean_y = np.asarray(yi).mean(axis=0)\n",
    "       #print('Mean pred shape '+str(mean_pred.shape))\n",
    "       #print('Mean y shape '+str(mean_y.shape))\n",
    "       new_pred.append(mean_pred)\n",
    "       new_y_test.append(mean_y)\n",
    "\n",
    "    new_pred = np.asarray(new_pred)\n",
    "    #print(new_pred.shape)\n",
    "    new_y_test = np.asarray(new_y_test)\n",
    "    #print(new_y_test.shape)\n",
    "\n",
    "    return new_pred, new_y_test\n",
    "    \n",
    "\n",
    "\n",
    "def get_features(sound):\n",
    "    sr = SAMPLING_RATE \n",
    "    y = sound.reshape(-1,)\n",
    "    mf = librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40)\n",
    "    mf = np.mean(mf.T,axis=0)\n",
    "    #print(mf.shape)\n",
    "    \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    \n",
    "    chroma_stft = np.mean(chroma_stft,axis=0)\n",
    "    #print(chroma_stft.shape)\n",
    " \n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_cent = np.mean(spec_cent,axis=0)\n",
    "    #print(spec_cent.shape)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spec_bw = np.mean(spec_bw,axis=0)\n",
    "    #print(spec_bw.shape)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    rolloff = np.mean(rolloff,axis=0)\n",
    "    #print(rolloff.shape)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    zcr = np.mean(zcr,axis=0)\n",
    "    #print(zcr.shape)\n",
    "    a = np.hstack((mf,chroma_stft,spec_cent,spec_bw,rolloff,zcr))\n",
    "    #print(a.shape)\n",
    "    return a;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def report_standard_algo(X_train, X_test, y_train, y_test,train_usercodes, test_usercodes):\n",
    "    # Test Models and evaluation metric\n",
    "    print('MFCC etc features computation... ')\n",
    "    mfcc = []\n",
    "    for i in range(len(X_train)):\n",
    "        mf = get_features(X_train[i])\n",
    "\n",
    "        mfcc.append(mf)\n",
    "        \n",
    "        \n",
    "    X_train_mfcc =np.array(mfcc) \n",
    "    X_train_mfcc = X_train_mfcc.reshape(X_train_mfcc.shape[0],X_train_mfcc.shape[1])\n",
    "    mfcct = []\n",
    "    for i in range(len(X_test)):\n",
    "        mf = get_features(X_test[i])\n",
    "\n",
    "        mfcct.append(mf)\n",
    "         \n",
    "        \n",
    "    X_test_mfcc =np.array(mfcct) \n",
    "    X_test_mfcc = X_test_mfcc.reshape(X_test_mfcc.shape[0],X_test_mfcc.shape[1])\n",
    "\n",
    "    print(X_train_mfcc.shape)\n",
    "    \n",
    "\n",
    "    print(X_test_mfcc.shape)\n",
    "    \n",
    "    stc = StandardScaler()\n",
    "    X_train_mfcc = stc.fit_transform(X_train_mfcc)\n",
    "    X_test_mfcc = stc.transform(X_test_mfcc)\n",
    "    seed = 42\n",
    "    scoring = 'accuracy' \n",
    "\n",
    "    # Spot Check Algorithms\n",
    "    Mymodels = []\n",
    "    #Mymodels.append(('LogReg', LogisticRegression()))\n",
    "    Mymodels.append(('RandomForestClassifier', RandomForestClassifier(n_estimators=100,max_depth=5 )))\n",
    "    #Mymodels.append(('SGDclassifier', SGDClassifier()))\n",
    "    Mymodels.append(('KNearestNeighbors', KNeighborsClassifier(n_neighbors=11,weights='distance')))\n",
    "    #Mymodels.append(('DecisionTreeClassifier', DecisionTreeClassifier()))\n",
    "    #Mymodels.append(('GaussianNB', GaussianNB()))\n",
    "    Mymodels.append(('SVM', SVC(kernel='linear')))\n",
    "\n",
    "    # Evaluate each model in turn\n",
    "    results = []\n",
    "    names = []\n",
    "    classification_report_array = {}\n",
    "    roc_auc_array = {}\n",
    "    confusion_mtx_array = {}\n",
    "    for name, model in Mymodels:\n",
    "        model.fit(X_train_mfcc,np.argmax(y_train, axis=1))\n",
    "        y_pred = model.predict(X_test_mfcc)\n",
    "         \n",
    "\n",
    "        print('MFCC Model '+str(name))\n",
    "        y_pred = to_categorical(y_pred)\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "        new_pred = y_pred\n",
    "        new_y_test = y_test\n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "\n",
    "        print(\"classification_report: \" + str(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True)))\n",
    "        classification_report_array[name] = classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True)\n",
    "         \n",
    "        roc_auc = roc_auc_score(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),average='weighted')\n",
    "        roc_auc_array[name] = roc_auc\n",
    "        print('MFCC Roc '+ str(roc_auc))\n",
    "         \n",
    "        # Plot non-normalized confusion matrix\n",
    "        \n",
    "        print('Confusion Matrix - classificatori')\n",
    "        confusion_mtx = confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1))\n",
    "              \n",
    "        pickle.dump(np.argmax(new_pred, axis=1), open(\"results_\"+str(name)+\".p\", \"wb\"))\n",
    "\n",
    "        print(confusion_mtx)\n",
    "        #plot_confusion_matrix2(confusion_mtx, normalize=True, target_names=['HC', 'PD'], title=\"ConfusionMatrix_\" + str(name) + \"_NormalizeTrue\" + str(i))\n",
    "        #plot_confusion_matrix2(confusion_mtx, normalize=False, target_names=['HC', 'PD'], title=\"ConfusionMatrix_\" + str(name) + \"_NormalizeFalse\" + str(i))\n",
    "\n",
    "        confusion_mtx_array[name] = confusion_mtx\n",
    "      \n",
    "    cmx_array.append(confusion_mtx_array)  \n",
    "    c_r_a.append(classification_report_array)\n",
    "    r_a_a.append(roc_auc_array)\n",
    "\n",
    "\n",
    "def report_average(reports):\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for report in reports:\n",
    "        print(report)\n",
    "        accuracy.append(report['accuracy'])\n",
    "        precision.append(report['weighted avg']['precision'])\n",
    "        recall.append(report['weighted avg']['recall'])\n",
    "        f1.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "    print('Mean accuracy '+str(np.mean(accuracy)))\n",
    "    print('Mean precision ' + str(np.mean(precision)))\n",
    "    print('Mean recall ' + str(np.mean(recall)))\n",
    "    print('Mean F1 ' + str(np.mean(f1)))\n",
    "\n",
    "\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "def custom_act_dentamaro(x):#inserire formula qui\n",
    "    #x +1 - (cos( 4x)-x/1.5) /(e^(-x/4)) \n",
    "   x = tf.convert_to_tensor(x)\n",
    "   return x + (1 - tf.cos(2*x) +x/5) / 2\n",
    "    #return x + (1 - tf.cos(2 * frequency * x)) / (2 * frequency)\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")\n",
    "          \n",
    "#tf.random.set_seed(42)\n",
    "\n",
    " \n",
    "y_new = np.asarray(y,dtype=np.float32)\n",
    "X_new = np.asarray(X,dtype=np.float32)\n",
    "X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.25 )\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2)\n",
    "\n",
    "for i in range(5): #10\n",
    "    #K.clear_session()#puliamo la ram della GPU \n",
    "    tf.keras.backend.clear_session()\n",
    " \n",
    "    #print(test_usercodes)\n",
    "    #X_train, X_test, y_train, y_test, train_usercodes, test_usercodes = inter_patient_scheme(X_new, y_new, patientids, test_size=0.2 )\n",
    " \n",
    "    input_shape = (1, X_train[0].shape[1])\n",
    "    #report_standard_algo(X_train.copy(),X_test.copy(),y_train.copy(),y_test.copy(),train_usercodes,test_usercodes)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "     \n",
    "\n",
    "    #model.load_weights('best_model_aucoresnetv2_pretrain.h5')\n",
    "    \n",
    "      #class binaria sano malato\n",
    "    #o = keras.layers.Dense(2,activation='softmax')(model.layers[-1].output)\n",
    "\n",
    "    #model2 = keras.Model(inputs=model.input, outputs=[o])\n",
    "    fft = 2048#1792#128 #arriva a 2048\n",
    "    optimizer = 'adam'\n",
    "    #lr = tf.keras.optimizers.schedules.ExponentialDecay(0.01, decay_steps=50, decay_rate=0.9, staircase=False)\n",
    "    #optimizer = tf.keras.optimizers.RMSprop(lr)\n",
    "\n",
    "    subsample = True\n",
    "    test_AUCO = False\n",
    "    for k in range(1):\n",
    "      model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='best_model_aucoresnet_covid_iteration_'+str(i)+'.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "      \n",
    "      k = 2\n",
    "      \n",
    "      pers_act = 'elu'#custom_act_dentamaro\n",
    "      #runs = get_layers(3.)\n",
    "      attention_type='se_block'\n",
    "      kernel_size = (5,5) \n",
    "     \n",
    "     \n",
    "      \n",
    "      #print('Spiking is '+str(spiking))\n",
    "    \n",
    "      if False:\n",
    "            \n",
    "            X_train = X_train.reshape(X_train.shape[0],X_train.shape[2],1)\n",
    "            X_test = X_test.reshape(X_test.shape[0],X_test.shape[2],1)\n",
    "            #Layer 1 =  13% , layer 2 = 11%, Layer 3 17%, Layer 4 10%, Layer 5 26%, Layer 6 22%\n",
    "            #input_shape = (X_train[0].shape[1:]) \n",
    "            input_signal = keras.layers.Input(shape=(X_train[0].shape[0], 1))\n",
    "\n",
    "            #input_signal = keras.layers.Input(input_shape)\n",
    "            #hht = HilbertHuangTransformSVD(num_vectors=10)(input_signal)\n",
    "            vec = 10\n",
    "            hht = HilbertHuangTransformAttention(max_imfs=vec)(input_signal)\n",
    "            hht = tf.keras.layers.Reshape((-1, vec))(hht)  # Add Reshape layer to remove extra dimension\n",
    "            conv1 = tf.keras.layers.Conv1D(16, kernel_size=3, activation='relu', padding='same')(hht)\n",
    "            maxpool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
    "            conv2 = tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(maxpool1)\n",
    "            maxpool2 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
    "            gap = tf.keras.layers.GlobalAveragePooling1D()(maxpool2)\n",
    "\n",
    "\n",
    "            dense = tf.keras.layers.Dense(64, activation='relu')(gap)\n",
    "            output = tf.keras.layers.Dense(2, activation='softmax')(dense)\n",
    "\n",
    "            model = keras.Model(inputs=input_signal, outputs=output)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy','AUC'])\n",
    "\n",
    "            history = model.fit(X_train,y_train, epochs=100, validation_data=(X_test,y_test), batch_size=32,callbacks=[model_checkpoint_callback], verbose=2)\n",
    "            #histories.append(history)\n",
    "           #AUCOResNetV2().save_plot('Iteration_'+str(i)+'_fft_'+str(fft)+'_activation_'+str(pers_act)+'_DenseNet201_'+str(optimizer)+'.svg', history=history, title='DenseNet 201 Accuracy')\n",
    "            model2 = model\n",
    "      else:\n",
    "          \n",
    "          input_shape = (X_train.shape[1:]) \n",
    "          \n",
    "          pre = keras.layers.Input(input_shape)\n",
    "            \n",
    "\n",
    "          pre = AUCOResNetV2().get_melspectrogram_layer(n_fft=fft,sample_rate=SAMPLING_RATE,n_mels=150, \n",
    "                                                        win_length=140, hop_length=344, input_data_format='channels_first',\n",
    "                                                        trainable = False) (pre)# NICOLA QUI\n",
    "\n",
    "          #pre = AUCOResNetV2().get_log_frequency_spectrogram_layer(n_fft=2048,log_n_bins=84, sample_rate=16000,win_length=160,hop_length=344,input_data_format='channels_first',return_decibel=True, trainable=True)(pre)\n",
    "       \n",
    "          if k == 0:\n",
    "              print(\"Resnet 50\")\n",
    "          #concatenate both \n",
    "              x = tensorflow.keras.applications.ResNet50(\n",
    "                  weights=None, input_tensor=pre,\n",
    "                  include_top=False) \n",
    "          if k == 1:\n",
    "              print(\"Inception V3\")\n",
    "              x = tensorflow.keras.applications.InceptionV3(\n",
    "                  weights=None, input_tensor=pre,\n",
    "                  include_top=False) \n",
    "          if k == 2:\n",
    "              print(\"DenseNet201\")\n",
    "              x = tensorflow.keras.applications.DenseNet201(\n",
    "                  weights=None, input_tensor=pre,\n",
    "                  include_top=False) \n",
    "          x.trainable = True\n",
    "\n",
    "          out = keras.layers.GlobalAveragePooling2D()(x.output)\n",
    "          #out = keras.layers.Dense(32,activation=pers_act)(out)\n",
    "          out = keras.layers.Dense(2,activation='softmax')(out)\n",
    "          model = keras.Model(inputs=x.input, outputs=out)\n",
    "\n",
    "          \n",
    "          model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy','AUC'])\n",
    "\n",
    "          history = model.fit(X_train,y_train, epochs=100, validation_data=(X_test,y_test), batch_size=8,callbacks=[model_checkpoint_callback], verbose=2)\n",
    "          histories.append(history)\n",
    "          #AUCOResNetV2().save_plot('Iteration_'+str(i)+'_fft_'+str(fft)+'_activation_'+str(pers_act)+'_DenseNet201_'+str(optimizer)+'.svg', history=history, title='DenseNet 201 Accuracy')\n",
    "          model2 = model\n",
    "        \n",
    "          \n",
    "          \n",
    "      \n",
    "      model2.load_weights('best_model_aucoresnet_covid_iteration_'+str(i)+'.h5')\n",
    "      y_pred = model2.predict(X_test)\n",
    "\n",
    "      #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "      new_pred = y_pred\n",
    "      new_y_test = y_test\n",
    "      pickle.dump(np.argmax(new_y_test, axis=1), open(\"results_test_groundtruth.p\", \"wb\"))\n",
    "      if k == 0:\n",
    "        pickle.dump(np.argmax(new_pred, axis=1), open(\"results_resnet.p\", \"wb\"))\n",
    "      if k == 1:\n",
    "        pickle.dump(np.argmax(new_pred, axis=1), open(\"results_inceptionv3.p\", \"wb\"))\n",
    "      if k == 2:\n",
    "        pickle.dump(np.argmax(new_pred, axis=1), open(\"results_densenet201.p\", \"wb\"))\n",
    "        \n",
    "    \n",
    "      print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "      if test_AUCO == False:\n",
    "          saa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "      else:\n",
    "        aa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "      roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "      print('Roc '+ str(roc_auc))\n",
    "      if test_AUCO == False:\n",
    "        saucs.append(roc_auc)\n",
    "      else:\n",
    "        aucs.append(roc_auc)\n",
    "      # Plot non-normalized confusion matrix\n",
    "      confusion_mtx11 = confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1))\n",
    "      print(confusion_mtx11)\n",
    "      #plot_confusion_matrix2(confusion_mtx11, normalize=True, target_names=['HC', 'PD'], title=\"ConfusionMatrix_Auco_NormalizeTrue\" + str(i))\n",
    "      #plot_confusion_matrix2(confusion_mtx11, normalize=False, target_names=['HC', 'PD'], title=\"ConfusionMatrix_Auco_NormalizeFalse\" + str(i))\n",
    "      confusion_matrix45.append(confusion_mtx11)\n",
    "\n",
    "print('Metric AUCO')\n",
    "\n",
    "print(\"aa::\" + str(aa))\n",
    "print(report_average(aa))\n",
    "print('AUC')\n",
    "print(np.mean(aucs))\n",
    "\n",
    "print('Metric other')\n",
    "\n",
    "print(report_average(saa))\n",
    "print('AUC')\n",
    "print(np.mean(saucs))\n",
    "\n",
    "print(report_average([k[\"RandomForestClassifier\"] for k in c_r_a]))\n",
    "print(report_average([k[\"KNearestNeighbors\"] for k in c_r_a]))\n",
    "print(report_average([k[\"SVM\"] for k in c_r_a]))\n",
    "\n",
    "print('AUC')\n",
    "print(np.mean([k[\"RandomForestClassifier\"] for k in r_a_a]))\n",
    "print(np.mean([k[\"KNearestNeighbors\"] for k in r_a_a]))\n",
    "print(np.mean([k[\"SVM\"] for k in r_a_a]))\n",
    "\n",
    "print('***********************************************')\n",
    "print('ConfusionMatrix True HC')\n",
    "true_hc_RFC = np.mean([k[\"RandomForestClassifier\"][0][0] for k in cmx_array])\n",
    "true_hc_KNN = np.mean([k[\"KNearestNeighbors\"][0][0] for k in cmx_array])\n",
    "true_hc_SVM = np.mean([k[\"SVM\"][0][0] for k in cmx_array])\n",
    "\n",
    "print(np.mean([k[\"RandomForestClassifier\"][0][0] for k in cmx_array]))\n",
    "print(np.mean([k[\"KNearestNeighbors\"][0][0] for k in cmx_array]))\n",
    "print(np.mean([k[\"SVM\"][0][0] for k in cmx_array]))\n",
    "\n",
    "print('***********************************************')\n",
    "print('ConfusionMatrix True PD')\n",
    "true_pd_RFC = np.mean([k[\"RandomForestClassifier\"][1][1] for k in cmx_array])\n",
    "true_pd_KNN = np.mean([k[\"KNearestNeighbors\"][1][1] for k in cmx_array])\n",
    "true_pd_SVM = np.mean([k[\"SVM\"][1][1] for k in cmx_array])\n",
    "\n",
    "print(np.mean([k[\"RandomForestClassifier\"][1][1] for k in cmx_array]))\n",
    "print(np.mean([k[\"KNearestNeighbors\"][1][1] for k in cmx_array]))\n",
    "print(np.mean([k[\"SVM\"][1][1] for k in cmx_array]))\n",
    "\n",
    "print('***********************************************')\n",
    "print('ConfusionMatrix Falsi PD')\n",
    "false_pd_RFC = np.mean([k[\"RandomForestClassifier\"][0][1] for k in cmx_array])\n",
    "false_pd_KNN = np.mean([k[\"KNearestNeighbors\"][0][1] for k in cmx_array])\n",
    "false_pd_SVM = np.mean([k[\"SVM\"][0][1] for k in cmx_array])\n",
    "\n",
    "print(np.mean([k[\"RandomForestClassifier\"][0][1] for k in cmx_array]))\n",
    "print(np.mean([k[\"KNearestNeighbors\"][0][1] for k in cmx_array]))\n",
    "print(np.mean([k[\"SVM\"][0][1] for k in cmx_array]))\n",
    "\n",
    "print('***********************************************')\n",
    "print('ConfusionMatrix Falsi HC')\n",
    "false_hc_RFC = np.mean([k[\"RandomForestClassifier\"][1][0] for k in cmx_array])\n",
    "false_hc_KNN = np.mean([k[\"KNearestNeighbors\"][1][0] for k in cmx_array])\n",
    "false_hc_SVM = np.mean([k[\"SVM\"][1][0] for k in cmx_array])\n",
    "\n",
    "print(np.mean([k[\"RandomForestClassifier\"][1][0] for k in cmx_array]))\n",
    "print(np.mean([k[\"KNearestNeighbors\"][1][0] for k in cmx_array]))\n",
    "print(np.mean([k[\"SVM\"][1][0] for k in cmx_array]))\n",
    "\n",
    "'''\n",
    "\n",
    "a = np.matrix([[true_hc_RFC, false_pd_RFC], [false_hc_RFC, true_pd_RFC]])\n",
    "plot_confusion_matrix2(a, normalize=False, target_names=['HC', 'PD'], title=\"MeanRandomForestClassifierConfusionMatrix_False\")\n",
    "plot_confusion_matrix2(a, normalize=True, target_names=['HC', 'PD'], title=\"MeanRandomForestClassifierConfusionMatrix_True\")\n",
    "\n",
    "a = np.matrix([[true_hc_KNN, false_pd_KNN], [false_hc_KNN, true_pd_KNN]])\n",
    "plot_confusion_matrix2(a, normalize=False, target_names=['HC', 'PD'], title=\"MeanKNNConfusionMatrix_False\")\n",
    "plot_confusion_matrix2(a, normalize=True, target_names=['HC', 'PD'], title=\"MeanKNNConfusionMatrix_True\")\n",
    "\n",
    "a = np.matrix([[true_hc_SVM, false_pd_SVM], [false_hc_SVM, true_pd_SVM]])\n",
    "plot_confusion_matrix2(a, normalize=False, target_names=['HC', 'PD'], title=\"MeanSVMConfusionMatrix_False\")\n",
    "plot_confusion_matrix2(a, normalize=True, target_names=['HC', 'PD'], title=\"MeanSVMConfusionMatrix_True\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "true_hc_Inception = np.mean([k[0][0] for k in confusion_matrix45])\n",
    "false_pd_Inception = np.mean([k[0][1] for k in confusion_matrix45])\n",
    "false_hc_Inception = np.mean([k[1][0] for k in confusion_matrix45])\n",
    "true_pd_Inception = np.mean([k[1][1] for k in confusion_matrix45])\n",
    "\n",
    "a = np.matrix([[true_hc_Inception, false_pd_Inception], [false_hc_Inception, true_pd_Inception]])\n",
    "#plot_confusion_matrix2(a, normalize=False, target_names=['HC', 'PD'], title=\"MeaResNet50ConfusionMatrix_False\")\n",
    "#plot_confusion_matrix2(a, normalize=True, target_names=['HC', 'PD'], title=\"MeanResNet50ConfusionMatrix_True\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "'''\n",
    "\n",
    "with open('X_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('X_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('y_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('y_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(y_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "with open('X_train.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "\n",
    "with open('X_test.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "with open('y_train.pickle', 'rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "\n",
    "with open('y_test.pickle', 'rb') as handle:\n",
    "    y_test = pickle.load(handle)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import tensorflow.keras as keras\n",
    "input_shape = (1, X_train[0].shape[1]) \n",
    "model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='best_model_resnet_audio_parkinson.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "     \n",
    "pre = keras.layers.Input(input_shape)\n",
    "pre = AUCOResNetV2().get_melspectrogram_layer(n_fft=2048,sample_rate=SAMPLING_RATE, n_mels=150, win_length=140, \n",
    "                                              hop_length=344, input_data_format='channels_first',trainable = False) (pre)# NICOLA QUI\n",
    "x = tensorflow.keras.applications.ResNet50(\n",
    "              weights=None, input_tensor=pre,\n",
    "              include_top=False) \n",
    "x.trainable = True\n",
    "out = keras.layers.GlobalAveragePooling2D()(x.output)\n",
    "out = keras.layers.Dense(2,activation='softmax')(out)\n",
    "model2 = keras.Model(inputs=x.input, outputs=out)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','AUC'])\n",
    "model2.fit(X_train,y_train, epochs=150, validation_data=(X_test,y_test), batch_size=32,callbacks=[model_checkpoint_callback])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc \n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error \n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer     \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "if model2 != None:\n",
    "        model2.load_weights('best_model_resnet_audio_parkinson.h5')\n",
    "        y_pred = model2.predict(X_test)\n",
    "\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "        new_pred = y_pred\n",
    "        new_y_test = y_test\n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "        \n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "        \n",
    "        # Plot non-normalized confusion matrix\n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import gc\n",
    "import io\n",
    "import cv2\n",
    "n_mels=150\n",
    "win_length=140\n",
    "hop_length=344\n",
    "\n",
    "def return_melspectogram(data,samplerate,threadid=0):\n",
    "    # Average the stereo signal\n",
    "    \n",
    "    data = np.asarray(data)\n",
    "\n",
    "\n",
    "    # Set up the plot\n",
    "    image_buffer = io.BytesIO()\n",
    "        \n",
    "    image_buffer.seek(0)\n",
    "    fig, axes = plt.subplots() \n",
    "    #fig = plt.figure(figsize=(1,1), dpi=128, frameon=False)\n",
    "    #axes = plt.axes()\n",
    "    axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    axes.get_yaxis().set_visible(False)\n",
    "    #fig.axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    #fig.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    Z = librosa.feature.melspectrogram(y=data,n_fft=2048, sr=samplerate,n_mels=n_mels,hop_length=hop_length)\n",
    "    Z = librosa.power_to_db(Z, ref=np.max)\n",
    "    #plt.imsave('ci.png',Z,format=\"png\", dpi=500)\n",
    "    plt.imsave(str(threadid)+'.bmp',Z,format=\"bmp\")\n",
    "    fig.clear()\n",
    "    #plt.close()\n",
    "    #f = plt.figure()\n",
    "    \n",
    "    plt.close(fig)\n",
    "    #plt.close('all')\n",
    "    im = cv2.imread(str(threadid)+'.bmp')\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    os.remove(str(threadid)+'.bmp')\n",
    "    #print(im.shape)\n",
    "    #im_resized = cv2.resize(im, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    gc.collect()\n",
    "    return im\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "X_train_im = []\n",
    "X_test_im = []\n",
    "\n",
    "\n",
    "for ii in range(len(X_train)):\n",
    "    X_train_im.append(return_melspectogram( X_train[ii].reshape(-1,),SAMPLING_RATE,0))\n",
    "for ii in range(len(X_test)):\n",
    "    X_test_im.append(return_melspectogram( X_test[ii].reshape(-1,),SAMPLING_RATE,0))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "'''\n",
    "with open('X_train_im.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_train_im, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('X_test_im.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_test_im, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "with open('X_train_im.pickle', 'rb') as handle:\n",
    "    X_train_im = pickle.load(handle)\n",
    "\n",
    "with open('X_test_im.pickle', 'rb') as handle:\n",
    "    X_test_im = pickle.load(handle)\n",
    "\n",
    "X_train_im = np.asarray(X_train_im)\n",
    "X_test_im = np.asarray(X_test_im)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ji in range(len(X_train_im)):\n",
    "    # Set up the plot\n",
    "    image_buffer = io.BytesIO()\n",
    "        \n",
    "    image_buffer.seek(0)\n",
    "    fig, axes = plt.subplots() \n",
    "    fig, axes = plt.subplots() \n",
    "    #fig = plt.figure(figsize=(1,1), dpi=128, frameon=False)\n",
    "    #axes = plt.axes()\n",
    "    axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    axes.get_yaxis().set_visible(False)\n",
    "    #fig.axes.get_xaxis().set_visible(False)\n",
    "    cv2.imwrite(r'original\\\\train\\\\'+str(ji)+'.bmp',X_train_im[ji])\n",
    "    fig.clear()\n",
    "    \n",
    "for ji in range(len(X_test_im)):\n",
    "    # Set up the plot\n",
    "    image_buffer = io.BytesIO()\n",
    "        \n",
    "    image_buffer.seek(0)\n",
    "    fig, axes = plt.subplots() \n",
    "    fig, axes = plt.subplots() \n",
    "    #fig = plt.figure(figsize=(1,1), dpi=128, frameon=False)\n",
    "    #axes = plt.axes()\n",
    "    axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    axes.get_yaxis().set_visible(False)\n",
    "    #fig.axes.get_xaxis().set_visible(False)\n",
    "    cv2.imwrite(r'original\\\\test\\\\'+str(ji)+'.bmp',X_test_im[ji])\n",
    "    fig.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "'''\n",
    "X_train_im = []\n",
    "X_test_im = []\n",
    "\n",
    "for ji in range(len(y_train)):\n",
    "    im = cv2.imread('original\\\\train\\\\'+str(ji)+'.bmp')\n",
    "    X_train_im.append(im)\n",
    "for ji in range(len(y_test)):\n",
    "    im = cv2.imread('original\\\\test\\\\'+str(ji)+'.bmp')\n",
    "    X_test_im.append(im)\n",
    "\n",
    "X_train_im = np.asarray(X_train_im)\n",
    "X_test_im = np.asarray(X_test_im)    \n",
    "'''\n",
    "X_train_im_ = X_train_im / 255.\n",
    "X_test_im_ = X_test_im / 255.\n",
    "\n",
    "X_train_im_ = X_train_im_.reshape(X_train_im_.shape[0],X_train_im_.shape[1],X_train_im_.shape[2],1)\n",
    "\n",
    "X_test_im_ = X_test_im_.reshape(X_test_im_.shape[0],X_test_im_.shape[1],X_test_im_.shape[2],1)\n",
    "\n",
    "base_model = tensorflow.keras.applications.resnet50.ResNet50(weights= None, include_top=False, input_shape= X_train_im_[0].shape)\n",
    "\n",
    "base_model.trainable = True\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "#x = Dropout(0.7)(x)\n",
    "predictions = Dense(2, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "#model.trainable = True\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','AUC'])\n",
    "model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "                    filepath='best_model_resnet.h5',\n",
    "                    save_weights_only=True,\n",
    "                    monitor='val_auc',\n",
    "                    mode='max',\n",
    "                    save_best_only=True)\n",
    "\n",
    "\n",
    "#model.summary()\n",
    "gc.collect()\n",
    "history = model.fit(X_train_im_,y_train, epochs=150, validation_data=(X_test_im_,y_test), batch_size=16,callbacks=[model_checkpoint_callback], verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "if model != None:\n",
    "        model.load_weights('best_model_resnet.h5')\n",
    "        y_pred = model.predict(X_test_im_)\n",
    "\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "        new_pred = y_pred\n",
    "        new_y_test = y_test\n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "       \n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "       \n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "index = np.where(np.asarray(y_test[:,1]) == 1)\n",
    "print(index[0][0])\n",
    "a = X_test[2]\n",
    "a_ = return_melspectogram(a.reshape(-1,),SAMPLING_RATE)\n",
    "Audio(a,rate=SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        # store the model, the class index used to measure the class\n",
    "        # activation map, and the layer to be used when visualizing\n",
    "        # the class activation map\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "        # if the layer name is None, attempt to automatically find\n",
    "        # the target output layer\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "\n",
    "    def find_target_layer(self):\n",
    "        # attempt to find the final convolutional layer in the network\n",
    "        # by looping over the layers of the network in reverse order\n",
    "        for layer in reversed(self.model.layers):\n",
    "            # check to see if the layer has a 4D output\n",
    "            if len(layer.output_shape) == 4:\n",
    "                print('Found layer name', layer.name)\n",
    "                return layer.name\n",
    "        # otherwise, we could not find a 4D layer so the GradCAM\n",
    "        # algorithm cannot be applied\n",
    "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        # construct our gradient model by supplying (1) the inputs\n",
    "        # to our pre-trained model, (2) the output of the (presumably)\n",
    "        # final 4D layer in the network, and (3) the output of the\n",
    "        # softmax activations from the model\n",
    "        gradModel = Model(\n",
    "            inputs=[self.model.inputs],\n",
    "            outputs=[self.model.get_layer(self.layerName).output, self.model.output])\n",
    "\n",
    "        # record operations for automatic differentiation\n",
    "        with tf.GradientTape() as tape:\n",
    "            # cast the image tensor to a float-32 data type, pass the\n",
    "            # image through the gradient model, and grab the loss\n",
    "            # associated with the specific class index\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = gradModel(inputs)\n",
    "            \n",
    "            loss = predictions[:, tf.argmax(predictions[0])]\n",
    "    \n",
    "        # use automatic differentiation to compute the gradients\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "\n",
    "        # compute the guided gradients\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "        # the convolution and guided gradients have a batch dimension\n",
    "        # (which we don't need) so let's grab the volume itself and\n",
    "        # discard the batch\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "\n",
    "        # compute the average of the gradient values, and using them\n",
    "        # as weights, compute the ponderation of the filters with\n",
    "        # respect to the weights\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "        # grab the spatial dimensions of the input image and resize\n",
    "        # the output class activation map to match the input image\n",
    "        # dimensions\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "        # normalize the heatmap such that all values lie in the range\n",
    "        # [0, 1], scale the resulting values to the range [0, 255],\n",
    "        # and then convert to an unsigned 8-bit integer\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "        # return the resulting heatmap to the calling function\n",
    "        return heatmap\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
    "                        colormap=cv2.COLORMAP_VIRIDIS):\n",
    "        # apply the supplied color map to the heatmap and then\n",
    "        # overlay the heatmap on the input image\n",
    "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "        # return a 2-tuple of the color mapped heatmap and the output,\n",
    "        # overlaid image\n",
    "        return (heatmap, output)\n",
    "    \n",
    "    \n",
    "\n",
    "#(heatmap, output) = icam.overlay_heatmap(heatmap, a_, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pickle\n",
    "\n",
    "grad_preds = []\n",
    "for ji in range(len(X_test_im)):\n",
    "    gc.collect()\n",
    "    mod = tf.keras.models.clone_model(model)\n",
    "    mod.layers[-1].activation = None\n",
    "    icam = GradCAM(mod, 1,None) \n",
    "    heatmap = icam.compute_heatmap(np.expand_dims(X_test_im[ji]/255., axis=0))\n",
    " \n",
    "    print('heat shape',heatmap.shape)\n",
    "    heat = np.copy(heatmap)\n",
    "    mean_point = np.mean(heat)\n",
    "\n",
    "    heat[heat<= mean_point] = 0 \n",
    "    b = np.copy(X_test_im[ji])\n",
    "    b[heat <= mean_point] = 0\n",
    "    image_buffer = io.BytesIO()\n",
    "        \n",
    "    image_buffer.seek(0)\n",
    "    axes = plt.axes()\n",
    "    axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    axes.get_yaxis().set_visible(False)\n",
    "    cv2.imwrite(r'gradcam\\\\'+str(ji)+'_grad.bmp',b)\n",
    "    plt.close()\n",
    "    m = cv2.imread(r'gradcam\\\\'+str(ji)+'_grad.bmp')\n",
    "    m = cv2.cvtColor(m, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "    grad_preds.append(model.predict(np.expand_dims(m/255.,axis=0)))\n",
    "    with open('grad_preds.pickle', 'wb') as handle:\n",
    "        pickle.dump(grad_preds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_preds = np.asarray(evidence_preds)\n",
    "print(evidence_preds.shape)\n",
    "if model != None:\n",
    "        #model2.load_weights('best_model_aucoresnet_covid_iteration_'+str(i)+'.h5')\n",
    "        #y_pred = model2.predict(X_test)\n",
    "\n",
    "        #new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "        new_pred = evidence_preds\n",
    "        new_y_test = y_test\n",
    "          \n",
    "        print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "        roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "        print('Roc '+ str(roc_auc))\n",
    "        \n",
    "        print('Confusion Matrix')\n",
    "        print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZKL3fjtHjiG"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "HC_parkinson_sounds = pickle.load(open(\"HC_parkinson_sounds.p\", \"rb\"))\n",
    "PD_parkinson_sounds = pickle.load(open(\"PD_parkinson_sounds.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vClbOzY8T0d9"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "patientids_test = []\n",
    "for value in PD_parkinson_sounds:\n",
    "    patientid = value['id']\n",
    "    X_test.append(value['audio'])\n",
    "    y_test.append(1.0)\n",
    "    patientids_test.append(patientid)\n",
    "        \n",
    "for value in HC_parkinson_sounds:\n",
    "    patientid = value['id']\n",
    "    X_test.append(value['audio'])\n",
    "    y_test.append(0.0)\n",
    "    patientids_test.append(patientid)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "_dUZGUd3T0d9",
    "outputId": "dae2b117-6fc7-4b4c-fbbf-f8686a938794"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lunghezze = []\n",
    "for r in X_test:\n",
    "  lunghezze.append(len(r))\n",
    "\n",
    "print('Mean secs')\n",
    "print(np.mean(lunghezze)/16000)\n",
    "print('Max secs')\n",
    "print(np.max(lunghezze)/16000)\n",
    "_ = plt.hist(np.asarray(lunghezze)/16000, bins=50)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram with 'auto' bins\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRaI0N9MT0d-",
    "outputId": "767ec671-08ca-48f3-c565-9173e734d7d4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "max_length = 15.#in secs\n",
    "max_samples =  max_length*22050\n",
    "for i in range(len(X_test)):\n",
    "\n",
    "  temp = X_test[i]\n",
    "  #temp = librosa.resample(temp, 20000, 16000)\n",
    "  temp = np.reshape(temp,(1,temp.shape[0]))  \n",
    "  \n",
    "  if temp.shape[1] < max_samples:\n",
    "    \n",
    "    offset = max_samples - len(temp)\n",
    "\n",
    "    shape = np.shape(temp)\n",
    "    tt = np.zeros((1,int(max_samples)))\n",
    "    tt[:shape[0],:shape[1]] = temp\n",
    "\n",
    "    temp = tt\n",
    "    \n",
    "     \n",
    "  if temp.shape[1] > max_samples:\n",
    "    temp = temp[0,:int((max_samples))]\n",
    "    temp = np.reshape(temp,(1,temp.shape[0]))  \n",
    "  X_test[i] = temp\n",
    "  \n",
    "  print(temp.shape)\n",
    "lens = []\n",
    "for it in X_test:\n",
    "  lens.append(it.shape[1])\n",
    "\n",
    "\n",
    "\n",
    "print('Mean secs')\n",
    "print(np.mean(lens)/16000.)\n",
    "print('Max secs')\n",
    "print(np.max(lens)/16000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9N6T6MFIT0d-"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "!mkdir logs\n",
    "!mkdir logs/scalars\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "log_dir = \"logs/scalars/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gUlc81pT0d_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "mACcu52mT0d_",
    "outputId": "0a227f8e-539f-4515-b1f1-8922c6ad0f28"
   },
   "outputs": [],
   "source": [
    "print(\"y_test: \" + str(y_test))\n",
    "new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred, average='weighted' )\n",
    "print(roc_auc)\n",
    "roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted' )\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model2.load_weights('best_model_aucoresnet_covid_iteration_0.h5')\n",
    "X_new = np.asarray(X_test,dtype=np.float32)\n",
    "\n",
    "y_pred = model2.predict(X_new)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "#new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, test_usercodes)\n",
    "new_pred = y_pred\n",
    "new_y_test = y_test\n",
    "  \n",
    "print(classification_report(new_y_test,new_pred))\n",
    "aa.append(classification_report(new_y_test, new_pred, output_dict=True))\n",
    "roc_auc = roc_auc_score(new_y_test, new_pred, average='weighted')\n",
    "print('Roc '+ str(roc_auc))\n",
    "\n",
    "\n",
    "print('Confusion Matrix')\n",
    "confusion_matrix_test = confusion_matrix(new_y_test, new_pred)\n",
    "print(confusion_matrix_test)\n",
    "plot_confusion_matrix2(confusion_matrix_test, normalize=False, target_names=['HC', 'PD'], title=\"ConfusionMatrixTest\")\n",
    "plot_confusion_matrix2(confusion_matrix_test, normalize=True, target_names=['HC', 'PD'], title=\"ConfusionMatrixTestN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predizione test \n",
    "\n",
    "model2.load_weights('best_model_aucoresnet_covid_iteration_9.h5')\n",
    "\n",
    "# model2.load_weights('best_model_aucoresnet_covid_iteration_0.h5')\n",
    "X_new = np.asarray(X_test,dtype=np.float32)\n",
    "y_new = np.asarray(y_test,dtype=np.float32)\n",
    "\n",
    "y_pred = model2.predict(X_new)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "roc_auc = roc_auc_score(y_new, y_pred, average='weighted')\n",
    "print('Roc '+ str(roc_auc))\n",
    "\n",
    "\n",
    "new_pred, new_y_test = concilie_per_patient_res(y_pred, y_new, patientids_test)\n",
    "\n",
    "a = np.arange(len(new_pred), dtype=float)\n",
    "new_pred_int = np.zeros_like(a)\n",
    "new_pred_int[new_pred > 0.5] = 1\n",
    "\n",
    "\n",
    "print(\"new_pred_int\")\n",
    "print(new_pred_int)\n",
    "print(\"new_pred\")\n",
    "print(new_pred)\n",
    "print(\"new_y_test\")\n",
    "print(new_y_test)\n",
    "        \n",
    "print(classification_report(new_y_test, new_pred_int, target_names=['HC','PD']))\n",
    "aa.append(classification_report(new_y_test, new_pred_int, output_dict=True))\n",
    "roc_auc = roc_auc_score(new_y_test, new_pred_int, average='weighted')\n",
    "print('Roc '+ str(roc_auc))\n",
    "      \n",
    "aucs.append(roc_auc)\n",
    "print('Confusion Matrix')\n",
    "confusion_matrix_test = confusion_matrix(new_y_test, new_pred_int)\n",
    "print(confusion_matrix_test)\n",
    "plot_confusion_matrix2(confusion_matrix_test, normalize=False, target_names=['HC', 'PD'], title=\"ConfusionMatrixTest\")\n",
    "plot_confusion_matrix2(confusion_matrix_test, normalize=True, target_names=['HC', 'PD'], title=\"ConfusionMatrixTestN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "i5YZZ1_ZT0eB",
    "outputId": "edc62a55-748d-4afb-9b04-e4b379d8e63b"
   },
   "outputs": [],
   "source": [
    "model2 = AUCOResNetV2_.model\n",
    "model2.load_weights('best_model_aucoresnet_covid_iteration_0.h5')\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "new_pred, new_y_test = concilie_per_patient_res(y_pred, y_test, patientids_test)\n",
    "\n",
    "         \n",
    "print(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))\n",
    "aa.append(classification_report(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1),output_dict=True))\n",
    "roc_auc = roc_auc_score(new_y_test, new_pred,average='weighted')\n",
    "print('Roc '+ str(roc_auc))\n",
    "      \n",
    "aucs.append(roc_auc)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(np.argmax(new_y_test, axis=1),np.argmax(new_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(new_y_test, new_pred_int,target_names=['HC','PD']))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(new_y_test, new_pred_int)\n",
    "print('AUC')\n",
    "print(metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(new_y_test, new_pred_int)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print(roc_auc[i])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr[1], tpr[1])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.savefig(\"a.svg\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr[1], tpr[1])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.savefig(\"b.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "kesBse1TT0eB",
    "outputId": "3fa2d4a9-9fe8-4f33-c77f-bf729653e078"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "index = np.where(np.asarray(y) == 1)\n",
    "print(index)\n",
    "\n",
    "\n",
    "Audio(X[index[0][0]],rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n8djUzVmT0eB"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMx8l_k-T0eC"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "resnet = pickle.load(open(\"results_resnet.p\", \"rb\"))\n",
    "inceptionv3 = pickle.load(open(\"results_inceptionv3.p\", \"rb\"))\n",
    "svm = pickle.load(open(\"results_SVM.p\", \"rb\"))\n",
    "randomforest = pickle.load(open(\"results_RandomForestClassifier.p\", \"rb\"))\n",
    "knn = pickle.load(open(\"results_KNearestNeighbors.p\", \"rb\"))\n",
    "densenet = pickle.load(open(\"results_densenet201.p\", \"rb\"))\n",
    "test = pickle.load(open(\"results_test_groundtruth.p\", \"rb\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.evaluate import mcnemar_tables\n",
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "\n",
    "\n",
    "tb = mcnemar_tables(test, \n",
    "                    resnet, \n",
    "                    inceptionv3,\n",
    "                    densenet, svm, randomforest, knn)\n",
    "\n",
    "for key, value in tb.items():\n",
    "    print('\\n')\n",
    "    print(key)\n",
    "    chi2, p = mcnemar(ary=value, corrected=True)\n",
    "    print('chi-squared:', chi2)\n",
    "    print('p-value:', p)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "1Parkinson_Task_1_Task_2_GOLD_RETE_GENERICA_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
